{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"If you are not redirected, click here."},{"location":"actions/","title":"Actions","text":"<p>Actions are the atomic units of work that when combined allow one to perform the tasks required by the project.</p> <p>They are defined inside the <code>actions</code> directory in a hierarchical way.</p> <p>There are several types of actions predefined and also new ones can be added.</p> <p>Actions are declared with a configuration file with the name of the action, for instance <code>preprocessor.yaml</code>.</p> <p>Inside this configuration file the action type must be declared using the <code>type</code> setting. For instance:</p> <pre><code>type: python_script\n</code></pre> <p>Alternatively, <code>plpipes</code> can autodetect an action type when it finds a file with the action name and some recognized extension (for example, <code>model_training.py</code>). In that case the configuration file is not required.</p> <p>The list of currently supported action types follows:</p>"},{"location":"actions/#python_script","title":"<code>python_script</code>","text":"<p>Extension: <code>.py</code></p> <p>The python code in the file is executed.</p> <p>The following objects are directly available in the script:</p> <ul> <li> <p><code>plpipes</code>: the main <code>plpipes</code> package.</p> </li> <li> <p><code>cfg</code>: the configuration object.</p> </li> <li> <p><code>action_cfg</code>: the action configuration (read from the action yaml     file or from the global configuration).</p> </li> <li> <p><code>db</code>: a shortcut for the <code>plpipes.database</code> package.</p> </li> </ul>"},{"location":"actions/#sql_script","title":"<code>sql_script</code>","text":"<p>Extension <code>.sql</code></p> <p>Runs the SQL sentences in the action file against the <code>work</code> database.</p> <p>The SQL code is preprocessed using Jinja. That feature can be used to for instance, set values from the configuration:</p> <pre><code>CREATE TABLE foo AS\nSELECT * FROM bar\nWHERE data &gt;= \"{{ cfg[\"data.limits.date.low.cutoff\"] }}\"\n</code></pre> <p>Currently this action type is only supported when <code>work</code> is backed by a SQLite database.</p>"},{"location":"actions/#sql_table_creator","title":"<code>sql_table_creator</code>","text":"<p>Extension <code>.table.sql</code></p> <p>Runs the SQL query in the file and stores the output data frame in a new table with the name of the action.</p> <p>Jinja is also used to preprocess the SQL statement.</p>"},{"location":"actions/#qrql_script","title":"<code>qrql_script</code>","text":"<p>Extension: <code>.prql</code></p> <p>PRQL (Pipelined Relational Query Language) is an alternative query language for relational databases.</p> <p>This action runs the PRQL sentences in the file against the <code>work</code> database.</p> <p>Jinja is used to preprocess the PRQL statement.</p> <p>Currently this action type is only supported when <code>work</code> is backed up by a SQLite database.</p>"},{"location":"actions/#qrql_table_creator","title":"<code>qrql_table_creator</code>","text":"<p>Runs the PRQL query in the file and stores the output data frame in a new table with the name of the action.</p> <p>Jinja is also used to preprocess the PRQL statement.</p>"},{"location":"actions/#quarto","title":"<code>quarto</code>","text":"<p>Extension: <code>.qmd</code></p> <p>Processes the file using quarto.</p> <p>The following configuration options can be used:</p> <ul> <li> <p><code>dest</code>:</p> <ul> <li> <p><code>key</code>: any of <code>work</code>, <code>input</code> or <code>output</code></p> </li> <li> <p><code>dir</code>: destination dir to store the generated files.</p> </li> <li> <p><code>file</code>: destination file name. Defaults to the action name with     the extension associated to the output format.</p> </li> <li> <p><code>format</code>: output format.</p> </li> </ul> </li> </ul> <p>The action configuration can also be included directly in the <code>qmd</code> yaml header, under the <code>plpipes</code> branch.</p>"},{"location":"actions/#sequence","title":"<code>sequence</code>","text":"<p>Runs a set of actions in sequence.</p> <p>The list of actions to be run are declared as an array under the <code>sequence</code> setting.</p> <p>Relative action names (starting by a dot) are also accepted.</p> <p>Example <code>yaml</code> configuration:</p> <pre><code>type: sequence\nsequence:\n    - .bar\n    - miau.gloglo\n</code></pre>"},{"location":"actions/#loop","title":"<code>loop</code>","text":"<p>The <code>loop</code> action is a construct for creating action loops.</p> <p>It runs a set of subactions in sequence repeatedly according to specified iterators, enabling one to perform repetitive operations following several strategies and with varying parameters.</p> <p>The configuration specifies the subactions to be executed in the loop and the iterators that control the iterations. These are the accepted keys:</p> <ul> <li> <p><code>sequence</code>: Specifies the names of the subactions to be executed in     the loop. The subactions will be executed in the order specified.</p> </li> <li> <p><code>iterator</code>: Specifies the iterators to be used for the loop.</p> <p>Each iterator is defined by a key and its corresponding configuration, which includes the type of the iterator and any required parameters.</p> <p>The supported iterator types are:</p> <ul> <li> <p><code>values</code>: Iterates over a list of specific values.</p> </li> <li> <p><code>configkeys</code>: Iterates over the keys of a specific path in the     configuration.</p> </li> </ul> </li> <li> <p><code>ignore_errors</code> (optional): If set to <code>true</code>, any errors that occur     during an iteration will be logged but will not stop the loop. If     not specified or set to <code>false</code>, an error during iteration will     raise an exception and halt the loop.</p> </li> </ul> <p>Sample configuration:</p> <pre><code>loop:\n  sequence:\n    - subaction1\n    - subaction2\n    - subaction3\n\n  iterator:\n    one:\n      type: values\n      values:\n        - value1\n        - value2\n        - value3\n    two:\n      type: configkeys\n      path: my_config.path\n\n  ignore_errors: true\n</code></pre>"},{"location":"aws/","title":"AWS","text":"<p>Not work done, yet :-(</p>"},{"location":"azure/","title":"Azure","text":""},{"location":"azure/#authentication","title":"Authentication","text":"<p>Package <code>plpipes.cloud.azure.auth</code> provides an easy way to manage Azure credentials.</p>"},{"location":"azure/#api","title":"API","text":"<p>Credential objects of type <code>azure.identity.MsalCredential</code> can be retrieved using function <code>credentials</code> as follows:</p> <pre><code>import plpipes.cloud.azure.auth\ncred = plpipes.cloud.azure.auth.credentials(\"predictland\")\n</code></pre>"},{"location":"azure/#configuration","title":"Configuration","text":"<p>Authentication accounts are declared in the configuration files and instantiated by the module on demand (which for some kind of authentication methods may require user interaction).</p> <p>For instance, the following configuration snippet defines the authorization account <code>predictland</code>.</p> <pre><code>cloud:\n  azure:\n    auth:\n      predictland:\n        type: interactive_browser\n        tenant_id: 01234567-89ab-cdef-0123-456789abcdef\n        client_id: 01234567-89ab-cdef-0123-456789abcdef\n        client_secret: super-super-super-super-secret\n        authentication_callback_port: 8283\n        username: elvis@predictland.com\n        scopes:\n          - \"https://graph.microsoft.com/.default\"\n</code></pre> <p>The meaning of every key is as follows:</p> <ul> <li> <p><code>type</code>: indicates the type of authentication to be used. It     defaults to <code>InteractiveBrowserCredential</code>.</p> </li> <li> <p><code>scopes</code>: the list of scopes (groups of permissions) to be     requested. This entry is optional, as most Azure services would re-ask     for the credentials with the scopes they need.</p> </li> </ul> <p>Every driver may also accept and/or require additional configuration entries:</p>"},{"location":"azure/#interactive_browser","title":"<code>interactive_browser</code>","text":"<p>Launches a browser and lets the use authenticate using her account. Credentials are cached when possible.</p> <ul> <li> <p><code>client_id</code> and <code>client_secret</code>: are the application credentials     which must be registered in Azure Active Directory (AAD). See     Register     Application     at MS Learn website.</p> </li> <li> <p><code>tenant_id</code>: the tenant where the application has been registered.</p> </li> <li> <p><code>username</code>: expected user, optional. Note that when Azure shows the     login page to the user, it allows her to login with any account     registered in the tenant AD. When this option is used, the framework     ensures that the user logs with the expected one. Otherwise it throws     an error.</p> </li> <li> <p><code>authentication_callback_port</code>: The framework starts an HTTP server     at the given port in order to receive the data from the user browser     (afterwards it is stopped). The port must be the same used to register     the application in AAD.</p> </li> </ul>"},{"location":"azure/#az_cli","title":"<code>az_cli</code>","text":"<p>Uses Azure command line client (<code>az</code>) for authentication.</p> <p>Accepted entries are as follows:</p> <ul> <li> <p><code>private</code> (defaults to true): whether to use a private <code>az</code>     configuration for this login or the global one for the user.</p> <p>In the later case, the global configuration must be initialized by the user calling <code>az login</code>.</p> </li> </ul>"},{"location":"cloud-intro/","title":"Cloud Overview","text":"<p>The support for cloud services within our PLPipes framework is currently inconsistent.</p> <p>We prioritize services based on our past needs, resulting in varying levels of support across providers. Notably, Azure stands out as having more comprehensive support compared to others.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>The configuration module is one of the core components of PLPipes pervasively used by <code>plpipes</code> itself, so even if you don't want to use it directly in your project it would be used internally by the framework.</p> <p>Configuration data is structured in a global tree-like object which is initialized from data read from several files in sequence and from the command line.</p> <p>Both YAML and JSON files are supported (though, we recommended YAML usage as it is usually easier to read by humans).</p> <p>When the same setting appears in several configuration files, the last one read is the one that prevails.</p>"},{"location":"configuration/#file-structure","title":"File structure","text":"<p>The list of files from with the configuration is read is dynamically calculated based on two settings:</p> <ul> <li> <p>The script \"stem\": It is the name of the script run without the     extension (for instance, the stem for <code>run.py</code> is <code>run</code>).</p> <p>When <code>plpipes</code> is used from a Jupyter notebook, the stem can be passed on the <code>%plpipes</code> line magic:</p> <pre><code>%plpipes foobalizer\n</code></pre> </li> <li> <p>The deployment environment (<code>dev</code>, <code>pre</code>, <code>pro</code>, etc.): this can be     set from the command line or using the environment variable     <code>PLPIPES_ENV</code> (see Environment variables     below). It defaults to <code>dev</code>.</p> </li> </ul> <p>Also, there are two main directories where configuration files are stored:</p> <ul> <li> <p><code>default</code>: This directory should contain configuration files that     are considered defaults and that are not going to be changed by the     project users. We think of it as the place where to place setting     that otherwise would be hard-coded.</p> </li> <li> <p><code>config</code>: This directory contains configuration files which are     editable by the project users or where developers can put temporary     settings they don't want to push into git.</p> </li> </ul> <p>We are currently considering whether this division makes sense or if we should otherwise replace it by something better</p> <p>When PLPipes configuration module is initialized it looks in those two directories for files whose names follow the following rules:</p> <ol> <li> <p>Base name: the base name is taken as <code>common</code> or the stem so that,     for instance, when loading the configuration from <code>run.py</code>, both     <code>common.yaml</code> and <code>run.yaml</code> files would be taken into account.</p> </li> <li> <p>Secrets: files with a <code>-secrets</code> post-fix are also loaded (for     instance, <code>common-secrets.yaml</code> and <code>run-secrets.yaml</code>).</p> </li> <li> <p>Environment: files with the deployment environment attached as a     post-fix are also loaded (<code>run-dev.yaml</code> or <code>run-secrets-dev.yaml</code>).</p> </li> </ol> <p>Additionally two user-specific configuration files are considered. Those are expected to contain global configuration settings which are not project specific as API keys, common database definitions, etc.</p> <pre><code>~/.config/plpipes/plpipes.yaml\n~/.config/plpipes/plpipes-secrets.yaml\n</code></pre> <p>Finally, when using the default runner (See Runner below), the user can request additional configuration files to be loaded.</p> <p>In summary, the full set of files which are consider for instance, when the <code>run.py</code> script is invoked in the <code>dev</code> environment is as follows (and in this particular order):</p> <pre><code>~/.config/plpipes/plpipes.json\n~/.config/plpipes/plpipes.yaml\n~/.config/plpipes/plpipes-secrets.json\n~/.config/plpipes/plpipes-secrets.yaml\ndefault/common.json\ndefault/common.yaml\ndefault/common-dev.json\ndefault/common-dev.yaml\ndefault/common-secrets.json\ndefault/common-secrets.yaml\ndefault/common-secrets-dev.json\ndefault/common-secrets-dev.yaml\ndefault/run.json\ndefault/run.yaml\ndefault/run-dev.json\ndefault/run-dev.yaml\ndefault/run-secrets.json\ndefault/run-secrets.yaml\ndefault/run-secrets-dev.json\ndefault/run-secrets-dev.yaml\nconfig/common.json\nconfig/common.yaml\nconfig/common-dev.json\nconfig/common-dev.yaml\nconfig/common-secrets.json\nconfig/common-secrets.yaml\nconfig/common-secrets-dev.json\nconfig/common-secrets-dev.yaml\nconfig/run.json\nconfig/run.yaml\nconfig/run-dev.json\nconfig/run-dev.yaml\nconfig/run-secrets.json\nconfig/run-secrets.yaml\nconfig/run-secrets-dev.json\nconfig/run-secrets-dev.yaml\n</code></pre>"},{"location":"configuration/#automatic-configuration","title":"Automatic configuration","text":"<p>There are some special settings that are automatically set by the framework when the configuration is initialized:</p> <ul> <li> <p><code>fs</code>: The file system sub-tree, contains entries for the main project     subdirectories (<code>root</code> which points to the project root directory,     <code>bin</code>, <code>lib</code>, <code>config</code>, <code>default</code>, <code>input</code>, <code>work</code>, <code>output</code> and     <code>actions</code>).</p> </li> <li> <p><code>env</code>: The deployment environment</p> </li> <li> <p><code>logging.level</code>: The logging level.</p> </li> </ul> <p>All those entries can be overridden in the configuration files.</p>"},{"location":"configuration/#wildcards","title":"Wildcards","text":"<p>In order to simplify the declaration of similar configuration subtrees, a wildcard mechanism is provided.</p> <p>Entries named <code>*</code> (an asterisk) are copied automatically into sibling configurations.</p> <p>For instance, in the following configuration most of the database connection parameters for <code>input</code> and <code>work</code> instances are obtained from the <code>*</code> entry.</p> <pre><code>db:\n  instance:\n    '*':\n      driver: azure_sql\n      server: example.databse.windows.net\n      user: jtravolta\n      password: grease78\n\n    input:\n      database: data_source\n\n    work:\n      database: tempdb\n</code></pre>"},{"location":"configuration/#python-usage","title":"Python usage","text":"<p>The configuration is exposed through the <code>plpipes.cfg</code> object.</p> <p>It works as a dictionary which accepts dotted entries as keys. For instance:</p> <pre><code>from plpipes import cfg\nprint(f\"Project root dir: {cfg['fs.root']}\")\n</code></pre> <p>A sub-tree view can be created using the <code>cd</code> method:</p> <pre><code>cfs = cfg.cd('fs')\nprint(f\"Project root dir: {cfs['root']}\")\n</code></pre> <p>Most dictionary methods work as expected. For instance it is possible to mutate the configuration or to set defaults:</p> <pre><code>cfg[\"my.conf.key\"] = 7\ncfg.setdefault(\"my.other.conf.key\", 8)\n</code></pre> <p>Though note that configuration changes are not backed to disk.</p>"},{"location":"configuration/#config-initialization","title":"Config Initialization","text":"<p>The method <code>init</code> of the module <code>plpipes.init</code> is the one in charge of populating the <code>cfg</code> object and should be called explicitly in scripts that want to use the configuration module without relying in other parts of the framework.</p> <p><code>plpipes.init.init</code> is where the set of files to be loaded based on the stem and on the deployment environment is calculated and where they are loaded into the configuration object.</p> <p>Automatic configuration is also performed by this method.</p> <p>Note that <code>plpipes.init</code> is a low level package that is not expected to be used directly from user code. Instead you should use the methods provided in <code>plpipes.runner</code> which take care of initializing the environment and also the configuration subsystem.</p>"},{"location":"databases/","title":"Database","text":"<p><code>plpipes</code> provides a simple way to declare and use multiple database connections and a set of shortcuts for simplifying some procedures common in a Data Science context (i.e. running a query and getting back a DataFrame or creating a new table from a DataFrame).</p>"},{"location":"databases/#default-database","title":"Default database","text":"<p>One of the key points of the framework is that a locally stored SQLite database is always available for usage with zero setup work.</p> <p>Also, as most things in PLPipes, that default database (AKA as <code>work</code> database) is also configurable and it can be changed to be, for instance, a PostgreSQL one running in AWS just for the production environment or to use a DuckDB one because of its native polars support or whatever.</p>"},{"location":"databases/#database-configuration","title":"Database configuration","text":"<p>Database configuration goes under the <code>db.instance</code> sub-tree where the different database connections can be defined.</p> <p>For instance, a <code>input</code> database connection backed by a SQL Server database running in Azure can be declared as follows:</p> <pre><code>db:\n  instance:\n    input:\n      driver: azure_sql\n      server: my-sql-server.database.windows.net\n      database: customer-db\n      user: predictland\n</code></pre> <p>The <code>db.instance.*.driver</code> key is used to find out which driver to use to establish the connection.</p> <p>The <code>db.instance.*.backend</code> key is used to stablish the DataFrame library backend used for the database instance. See Database-backends.</p> <p>The remaining configuration entries are driver specific and as follow:</p>"},{"location":"databases/#duckdb-configuration","title":"DuckDB configuration","text":"<ul> <li><code>driver</code>: <code>duckdb</code></li> <li><code>file</code>: name of the database file. Defaults to     <code>{instance_name}.duckdb</code>.</li> </ul> <p>If the instance is named <code>input</code> or <code>output</code>, the database file is placed inside the matching directory (for instance, <code>input/input.duckdb</code>).</p> <p>Otherwise it is placed in the <code>work</code> directory (example: <code>work/other.duckdb</code>).</p>"},{"location":"databases/#sqlite-configuration","title":"SQLite configuration","text":"<ul> <li><code>driver</code>: <code>sqlite</code></li> <li><code>file</code>: database file name.</li> </ul> <p>Works in exactly the same way as DuckDB but using <code>sqlite</code> as the database file extension.</p>"},{"location":"databases/#spatialite-configuration","title":"Spatialite configuration","text":"<p>Spatialite is an extension of SQLite designed to facilitate the manipulation of geographic data.</p> <ul> <li><code>driver</code>: <code>spatialite</code></li> <li><code>file</code>: database file name.</li> </ul> <p>The extension must be installed. If you are using Conda it is available from the <code>conda-forge</code> repository and can be installed as follows:</p> <pre><code>conda install libspatialite -c conda-forge\n</code></pre> <p>Note that Spatialite database files also use the <code>sqlite</code> extension.</p>"},{"location":"databases/#sqlserver-configuration","title":"SQLServer configuration","text":"<ul> <li><code>driver</code>: <code>sql_server</code></li> <li><code>server</code></li> <li><code>database</code></li> <li><code>user</code></li> <li><code>password</code></li> <li><code>encrypt</code>: defaults to <code>true</code>.</li> <li><code>trusted_server_certificate</code>: defaults to <code>true</code>.</li> <li><code>timeout</code>: defaults to 60s.</li> </ul> <p>Also, in order to connect to a SQL-Server database the ODBC driver must be installed. It is available from here.</p>"},{"location":"databases/#azuresql-configuration","title":"AzureSQL configuration","text":"<ul> <li><code>driver</code>: <code>azure_sql</code></li> <li><code>server</code>: full qualified server name. It can be seen at the Summary     page for the database in Azure     Portal. It usually has a name like     <code>foo.database.windows.net</code>).</li> <li><code>database</code>: Database instance name. It is usually (always?) also the     name of the Azure resource.</li> <li><code>credentials</code>: Name of the Azure credential group to be used for     authentication. See the Azure chapter below.</li> </ul> <p>Example:</p> <pre><code>db:\n  instance:\n    input:\n      driver: azure_sql\n      server: foo.database.windows.net\n      database: megadb-2000\n      credentials: bar\n\ncloud:\n  azure:\n    auth:\n      bar:\n        driver: azure_cli\n</code></pre> <p>Again, the SQL-Server ODBC driver must also be installed.</p>"},{"location":"databases/#influxdb","title":"InfluxDB","text":"<p>So far, only InfluxDB version 1 is supported. There is nothing wrong with versions 2 and 3, just that nobody have requested them yet!</p> <ul> <li><code>driver</code>: <code>influxdb1</code></li> <li><code>host</code></li> <li><code>port</code>: defaults to 8086.</li> <li><code>database</code></li> <li><code>user</code></li> <li><code>password</code></li> <li><code>ssl</code>: whether to connect using TLS. Defaults to <code>true</code>.</li> <li><code>verify_ssl</code>: whether to check the remote server TLS certificate. Defaults to <code>true</code>.</li> </ul> <p>Note also that connections to InfluxDB v1 databases are handled in a special way because its python drivers are not compatible with SQLAlchemy. Some functionality may not be available. For instance, only the <code>pandas</code> backend is currently supported.</p>"},{"location":"databases/#spark","title":"Spark","text":"<p>Spark can be used as a regular database through <code>plpipes.database</code> with the following configuration:</p> <ul> <li><code>driver</code>: <code>spark</code></li> <li><code>default_database</code>: name of the default database, usually composed   of a catalog name and a database name joined by a dot (for instance,   <code>my_catalog.my_database</code>).</li> </ul> <p>Besides the database configuration, Spark must be configured on its own. See Spark.</p> <p>Note that Spark database uses a <code>spark</code> backend returning Spark dataframes by default. A <code>pandas</code> backend is also available.</p>"},{"location":"databases/#other-databases-configuration","title":"Other databases configuration","text":"<p>Not implemented yet, but just ask for them!!!</p>"},{"location":"databases/#database-usage","title":"Database usage","text":"<p><code>plpipes.database</code> provides a set of functions for accessing the databases declared in the configuration.</p> <p>Most of the functions provided accept an optional <code>db</code> argument, for selecting the database instance. When <code>db</code> is omitted, <code>work</code> is used as the default.</p> <p>For example:</p> <pre><code>from plpipes.database import query, create_table\n\ndf = query(\"select * from order when date &gt;= :ld\", {'ld': '2018-01-01'}, db='input')\ncreate_table('recent_orders', df, db='output')\n</code></pre> <p>A list of the most commonly used functions from <code>plpipes.database</code> follows:</p>"},{"location":"databases/#query","title":"<code>query</code>","text":"<pre><code>query(sql, parameters=None, db='work')\n</code></pre> <p>Submits the query to the database and returns a pandas dataframe as the result.</p>"},{"location":"databases/#read_table","title":"<code>read_table</code>","text":"<pre><code>read_table(table_name, db=\"work\", columns=None)\n</code></pre> <p>Reads the contents of the table as a dataframe.</p> <p>The columns to be loaded can be specified with the <code>columns</code> optional argument.</p>"},{"location":"databases/#execute","title":"<code>execute</code>","text":"<p><pre><code>execute(sql, parameters=None, db='work')\n</code></pre> Runs a SQL sentence that does not generate a result set.</p>"},{"location":"databases/#execute_script","title":"<code>execute_script</code>","text":"<pre><code>execute_script(sql_script, db='work')\n</code></pre> <p>Runs a sequence of SQL sentences.</p> <p>This method is an unstable state, waiting for a proper implementation to happen :-)</p>"},{"location":"databases/#create_table","title":"<code>create_table</code>","text":"<pre><code>create_table(table_name, df, db=\"work\",\n             if_exists=\"replace\")\n\ncreate_table(table_name, sql,\n             parameters=None,\n             db=\"work\",\n             if_exists=\"replace)\n</code></pre> <p>This method can be used to create a new table both from a dataframe or from a SQL sentence.</p>"},{"location":"databases/#copy_table","title":"<code>copy_table</code>","text":"<p><pre><code>copy_table(source_table_name, dest_table_name=source_table_name,\n           source_db=\"work\", dest_db=\"work\", db=\"work\",\n           if_exists=\"replace\", **kws)\n</code></pre> Copies table <code>source_table_name</code> from database <code>source_db</code> into <code>dest_table_name</code> at database <code>dest_db</code>.</p>"},{"location":"databases/#update_table","title":"<code>update_table</code>","text":"<p><pre><code>update_table(source_table_name, dest_table_name=source_table_name,\n             source_db=\"work\", dest_db=\"work\", db=\"work\",\n             key=None, key_dir=\"&gt;=\")\n</code></pre> Updates table <code>dest_table_name</code> at database <code>dest_db</code> with the missing rows <code>from source_table_name</code> at <code>source_db</code>.</p> <p><code>key</code> points to a column with monotonic values which is used to identify the new rows in the source table.</p> <p><code>key_dir</code> indicates whether the <code>key</code> column monotony is strictly ascending (<code>&gt;</code>), ascending (<code>&gt;=</code>), descending (<code>&lt;=</code>) or strictly descending (<code>&lt;</code>).</p> <p>For instance, for a date column, whose values always increase, but which may have duplicates, the right value is <code>&gt;=</code>. In other words, the operator used answers to the question \"how are the new values in the table?\"</p>"},{"location":"databases/#begin","title":"<code>begin</code>","text":"<pre><code>with begin(db='work') as conn:\n    df = conn.query(sql1)\n    df = conn.execute(sql2)\n    ...\n</code></pre> <p>This method returns a database connection with an open transaction.</p> <p>The transaction is automatically commited when the with block is done unless an exception is raised. In that case, a rollback is performed.</p>"},{"location":"databases/#connection-class","title":"Connection class","text":"<p>The connection class is returned by calling <code>begin</code>.</p> <pre><code>connection(db='work')\n</code></pre> <p>Returns a SQLAlchemy connection (created by <code>begin</code>).</p> <p>Also useful for integrating <code>plpipes</code> with other third party modules or for using other <code>SQLAlchemy</code> methods not directly wrapped by <code>plpipes</code>.</p>"},{"location":"databases/#database-backends","title":"Database backends","text":"<p>Besides pandas, which is the de-facto standard in the Python Data-Science context for representing tabular data, there are other libraries that for certain problems may be more suitable (for instance, geopandas for the manipulation of geo-referenced data).</p> <p>PLPipes has a set of plugable backends controlling how data from the database is serialized/deserialized into the different DataFrame implementations.</p> <p>So far, backends for <code>pandas</code> and <code>geopandas</code> are provided. Others for polars, vaex or dassk will be added as the need arises.</p> <p>A <code>spark</code> backend is also available for Spark databases.</p> <p>In any case, note that changing the backend, usually also requires changing the code that uses the dataframes as every library provides its own similar but incompatible API.</p> <p>Every backend may also accept custom keyword arguments. See Backend specifics bellow.</p>"},{"location":"databases/#picking-the-backend","title":"Picking the backend","text":"<p>For database write operations (i.e. <code>create_table</code>), <code>plpipes</code> can infer which backend to use just looking at the dataframe object type, so as long as the backend is loaded, <code>plpipes</code> will use the right one automatically.</p> <p>The function <code>plpipes.database.load_backend</code> can be used to load a specific backend into a database driver:</p> <pre><code>plpipes.database.load_backend(\"geopandas\", db=\"input\")\n</code></pre> <p>Currently, under the hood, backends are attached to the driver class. Once a backend is loaded, for instance, for a <code>azure_sql</code> database, every other database using such driver will have the backend available for write operations.</p> <p>In the case of read operations, there is no way for <code>plpipes</code> to infer the desired backend and so it must be stated explicitly in one of the following ways:</p> <ol> <li> <p>Passing it as an argument in database read functions     (i.e. <code>read_table</code>, <code>query</code>, <code>query_chunked</code> and     <code>query_group</code>). For instance:</p> <pre><code>df = plpipes.database.query(sql, backend=\"spark\")\n</code></pre> </li> <li> <p>In the database connection configuration. For instance:</p> <pre><code>db:\n  instance:\n    work:\n      backend: polars\n</code></pre> </li> <li> <p>Every database driver can set its own default. For instance,    currently, the <code>spatialite</code> driver sets <code>geopandas</code> as its default    backend.</p> </li> </ol> <p>Read operations transparently call <code>load_backend</code> as needed. The default backend is also loaded automatically when the database is initialized.</p>"},{"location":"databases/#backend-specifics","title":"Backend specifics","text":""},{"location":"databases/#pandas-backend","title":"<code>pandas</code> backend","text":"<p>This is the default backend.</p>"},{"location":"databases/#geopandas-backend","title":"<code>geopandas</code> backend","text":"<p>The <code>geopandas</code> backend can handle both <code>geopandas</code> and regular <code>pandas</code> dataframes.</p> <p>In read operations, the argument <code>geom_col</code> must be used to indicate which column contains the geometric data.</p> <p>If the argument is ommited, the backend returns a regular <code>pandas</code> dataframe.</p> <p>Example:</p> <pre><code>df = db.query(\"select * from countries\", geom_col=\"geometry\")\n</code></pre> <p>In order to read geometric data from the database the backend may mangle the query in order to transform the geometric column values into the right format for <code>geopandas.read_postgis</code> method. Specifically, in the case of Spatialite, it wraps the geometric column in the query as <code>Hex(ST_AsBinary(geom_col))</code>.</p> <p>Alternatively, and in order to avoid such processing, the <code>wkb_geom_col</code> argument can be used instead. In that case, it is the programmer responsability to write a query returning the values in such colum in a format supported by geopandas (<code>wkb</code> stands for Well Known Binary).</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#design","title":"Design","text":"<ul> <li> <p>Why is the database used to pass data between actions? Isn't that     inefficient?</p> <p>Usually it is not.</p> <p>Both SQLite and DuckDB are pretty fast reading and writing data so that the database trip is very rarely the bottleneck.</p> <p>Actually, if you are able to delegate the data transformation tasks to the database (writing SQL code or using some front-end as ibis), they would perform way faster than the equivalent pandas code.</p> <p>Coming back to the why. Using a database has several additional benefits:</p> <ul> <li> <p>It is quite easy to inspect intermediate data, just point your     favorite SQL GUI (for instance, DBeaver)     to the database and look at the tables you want to see.</p> </li> <li> <p>It allows the programmer to easily add pre and post-condition     checking scripts which unintrusively validate the data before and     after every action is run (planed).</p> </li> <li> <p>It allows one to switch between functional-equivalent actions     easily. For instance, in order to add support for some new     algorithm into a project, all that is required is to develop the     new model-training action and to plug it into some pipeline.</p> </li> <li> <p>It becomes easier for new people to get to work into the project,     as they only need to understand the data in the tables where they     are going to work.</p> </li> <li> <p>It is easy to establish guidelines about documenting the     intermediate information structure (something that never happens     for in-process pipelines).</p> </li> </ul> </li> <li> <p>How should I break my program into actions?</p> <p>Well, the truth is we are still learning about what are the best ways to structure data science projects around actions!</p> <p>Typically, there are three clear parts in a Data Science project:</p> <ol> <li>Data preprocessing</li> <li>Model training and validation</li> <li>Predicting</li> </ol> <p>Though, sometimes, it doesn't make sense to split the training and the prediction stages. For instance, when the model needs to be retrained every time as it happens with time series data.</p> <p>Then every one of the actions above may be broken in several sub-actions. For instance, as part of the preprocessing we would have a data-retrieving action (maybe composed of several sub-actions as well). And then two more actions for converting from bronze-quality data first to silver and then to gold (see the Medallion architecture).</p> <p>Then, inside the model training, we could have still some data manipulation actions in order to adapt the generic gold format to the format required by the specific model, then an action that trains and saves the model to disk and finally some action that calculates some KPIs.</p> <p>Otherwise, maybe for that particular algorithm it is easier to do the data preparation, training and evaluation in just one action.</p> <p>Note also, that <code>actions</code> are not the only available abstraction to be used with PLPipes. Code can be organized as regular Python modules inside the <code>lib</code> directory and called from multiple actions.</p> <p>In summary, Common sense should be applied. Actions should not be a straitjacket, but just another element in your tool-set!</p> </li> </ul>"},{"location":"google-cloud/","title":"Google Cloud","text":"<p>Note: This is a work in progress</p>"},{"location":"google-cloud/#authentication","title":"Authentication","text":""},{"location":"google-cloud/#api","title":"API","text":"<p>Credential objects of type <code>google.auth.credentials.Credentials</code> can be retrieved using function <code>credentials</code> as follows:</p> <pre><code>import plpipes.cloud.cloud.auth\ncred = plpipes.cloud.cloud.auth.credentials(\"predictland\")\n</code></pre>"},{"location":"google-cloud/#configuration","title":"Configuration","text":"<p>Authentication accounts are declared in the configuration files and instantiated by the module on demand (which for some kind of authentication methods may require user interaction).</p> <p>For instance, the following configuration snippet defines the authorization account <code>predictland</code>.</p> <pre><code>cloud:\n  azure:\n    auth:\n      predictland:\n        type: oauth2\n        scopes:\n          - \"https://www.googleapis.com/auth/cloud-platform\"\n        ...\n</code></pre> <p>The meaning of every key is as follows:</p> <ul> <li><code>type</code>: name of the authentication backend.</li> <li><code>scopes</code>: list of scope for which access is being requested.</li> </ul> <p>Every backend requires a different set of additional options:</p>"},{"location":"google-cloud/#oauth2","title":"<code>oauth2</code>","text":"<ul> <li> <p><code>installed</code>: the additional entries required by     <code>google_auth_oauthlib.flow.InstalledAppFlow.from_client_config</code>:</p> <ul> <li><code>client_id</code></li> <li><code>project_id</code></li> <li><code>auth_uri</code></li> <li><code>token_uri</code>,</li> <li><code>auth_provider_x509_cert_url</code></li> <li><code>client_secret</code></li> <li><code>redirect_uris</code></li> </ul> <p>Those options can be retrieved from the JSON file generated by GoogleCloud when a new OAuth2 installed applications is registered (GoogleCloud Console \u2192 APIs &amp; Services \u2192 Credentials \u2192 Create Credentials \u2192 OAuth Client ID \u2192 Desktop App \u2192 Download JSON).</p> </li> </ul> <p>Example:</p> <pre><code>google:\n  auth:\n    predictland:\n      type: oauth2\n      installed:\n        client_id: \"...\"\n        project_id: \"predictland\"\n        auth_uri: \"https://accounts.google.com/o/oauth2/auth\"\n        token_uri: \"https://oauth2.googleapis.com/token\"\n        auth_provider_x509_cert_url: \"https://www.googleapis.com/oauth2/v1/certs\"\n        client_secret: \"...\"\n        redirect_uris: [\"http://localhost\"]\n      scopes:\n        - https://www.googleapis.com/auth/cloud-platform\n</code></pre>"},{"location":"install/","title":"Installing <code>plpipes</code>","text":"<p>The Python module <code>plpipes</code> can be installed in two ways:</p>"},{"location":"install/#installing-a-packed-version","title":"Installing a packed version","text":"<p>This is the recommended method for installing the module if you simply want to use it without contributing to its development. </p> <p>You can install <code>plpipes</code> directly from the Python Package Index (PyPI) using pip:</p> <pre><code>pip install plpipes\n</code></pre> <p>This will ensure you have the latest stable version.</p>"},{"location":"install/#installing-from-git","title":"Installing from git","text":"<ol> <li> <p>Clone the repository outside of your project directory and switch to the <code>develop</code> branch:</p> <pre><code>git clone git@github.com:PredictLand/PL-TEC-PLPipes.git\ncd PL-TEC-PLPipes\ngit checkout develop\n</code></pre> </li> <li> <p>Add the <code>src</code> subdirectory to the Python search path:</p> <pre><code># Linux and/or bash:\nexport PYTHONPATH=path/to/.../PL-TEC-PLPipes/src\n# Windows\nset PYTHONPATH=C:\\path\\to\\...\\PL-TEC-PLPipes\\src\n</code></pre> </li> <li> <p>Check that it works:</p> <pre><code>python -m plpipes -c \"print('ok')\"\n</code></pre> </li> </ol> <p>Alternatively, you can modify your project's main script to append the <code>src</code> directory to the module search path so that you don't need to set <code>PYTHONPATH</code> manually each time you start a new session.</p> <p>For example:</p> <pre><code>from pathlib import Path\nimport sys\nsys.path.append(str(Path.cwd().parent.parent.parent / \"PL-TEC-PLPipes/src\"))\n\nfrom plpipes.runner import main\nmain()\n</code></pre> <p>Or you can also set <code>PYTHONPATH</code> from your shell startup script (<code>~/.profile</code>) or in the Windows registry.</p>"},{"location":"install/#packing-plpipes","title":"Packing <code>plpipes</code>","text":"<p>If you would like to create a wheel file for <code>plpipes</code>, you can do so using flit, which can be installed with pip:</p> <pre><code>pip install flit\n</code></pre> <p>To generate a Python wheel file for <code>plpipes</code>, run the following command from inside the <code>plpipes</code> root directory:</p> <pre><code>flit build\n</code></pre> <p>The generated wheel file will be placed in the <code>dist</code> directory. This file is a standard (pure) Python package that can be installed on any operating system as demonstrated above.</p>"},{"location":"intro/","title":"Introduction","text":"<p>PredictLand, the company behind PLPipes, is a consultancy firm specializing in Data Science and related fields (Data Analytics, AI and ML, Big Data, Data Engineering, etc.). Our clientele spans from small businesses with only a handful of employees to large corporations. This diversity demands flexibility in our work methods because the platforms, IT systems, and tools at our disposal can vary significantly from one project to another.</p> <p>In fact, it's not uncommon for us to work on projects where our entire infrastructure consists of nothing more than our laptops! Yes, you read that correctly, no fancy environments like those provided for instance by Databricks or Snowflake; no cloud instances with massive amounts of RAM; no data automation services like Azure Data Factory or DBT; sometimes not even a basic Database server. All we have are our trusty laptops, a Git repository, and perhaps a few Excel files containing the data.</p> <p>So, we initiated <code>PLPipes</code> as an effort to replicate the capabilities of those sophisticated frameworks suitable for our resource-constrained environments. In this context, you can consider PLPipes as a cost-effective Data Science framework, a cheap alternative to solutions like Databricks and similar platforms!</p> <p>However, nowadays, we prefer to view PLPipes as a lean and highly scalable framework. It's a tool that you can use to train models from a few CSVs on your laptop, process terabytes of data on a cloud cluster, integrate into a lambda function, or run models within a Docker container, and much more.</p> <p>So, what is exactly PLPipes?</p> <p>Several things:</p> <ol> <li> <p>It is a thin layer integrating several technologies so that    they can be used easily and efficiently to solve common data    science problems.</p> </li> <li> <p>It is an automation framework for creating data processing    pipelines.</p> </li> <li> <p>It is a programming framework for reducing boilerplate,    enforcing some best-practices and providing support for common    tasks.</p> </li> <li> <p>It is also a mindset and a way to standardize Data Science    project development.</p> </li> <li> <p>It is a very customizable framework with sane defaults, so    that you can start working on your projects right there without    having to perform a complex setup up front.</p> </li> <li> <p>It is a work in process yet! Even if the ideas behind PLPipes    are not new and we have used/implemented them in different forms    and in different projects in the past (or in some cases, just    copied them from other 3rd party projects), the framework is still    very new and most of it should be considered experimental!</p> </li> </ol> <p>In any case, please note that <code>PLPipes</code> is not intended to replace packages like <code>numpy</code>, <code>pandas</code>, <code>polars</code>, <code>dask</code>, <code>pyspark</code>, <code>scikit-learn</code>, <code>tensorflow</code>, <code>pytorch</code>, <code>matplotlib</code>, <code>jupyter</code>, and many other frameworks of that nature. You are expected to continue using those libraries in your code, and PLPipes maintains a neutral stance on which ones you choose to use.</p> <p>Having say that, it is also true that some of those libraries require some integration work not yet done... but well, this is a young project, so, you can just ask for it or even better, get involved in the project and contribute your patches!!!</p>"},{"location":"jupyter/","title":"Jupyter integration","text":"<p>PLPipes includes an IPython extension which exposes the framework functionality in Jupyter notebooks.</p>"},{"location":"jupyter/#initialization","title":"Initialization","text":"<p>The extension is loaded adding the following lines at the beginning of your notebook:</p> <pre><code>%load_ext plpipes.jupyter\n%plpipes {stem}\n</code></pre> <p>Where <code>{stem}</code> is the name used as the main key when looking for configuration files (defaults to <code>jupyter</code>).</p> <p>In order to find the project configuration, the extension looks into the environment variable <code>PLPIPES_ROOT_DIR</code>. If that variable is not defined then it looks for a <code>config</code> directory in the current working directory of the IPython kernel (usually the directory from where <code>jupyter-lab</code> was launched) and walks up the file system until such directory is found.</p> <p>Once the extension is loaded and initialized, the features described in the following sections can be used.</p>"},{"location":"jupyter/#variable-packages-and-method-shortcuts","title":"Variable, packages and method shortcuts","text":"<p>The following variables and methods are made available in the session:</p> <ul> <li> <p><code>cfg</code>: The configuration object</p> </li> <li> <p><code>input_dir</code>, <code>work_dir</code> and <code>output_dir</code>: <code>libpath</code> objects pointing     to the input, work and output directories.</p> <p>For instance: <pre><code>df = pandas.read_csv(input_dir / \"data001.csv\")\n</code></pre></p> </li> <li> <p><code>db</code>: a shortcut for <code>plpipes.database</code></p> </li> <li> <p><code>create_table</code> and <code>query</code>: shortcuts for the functions of the same     name in <code>plpipes.database</code>.</p> </li> </ul>"},{"location":"jupyter/#sql-integration","title":"SQL integration","text":"<p>Note: due to some incompatibility with recent versions of <code>ipython-sql</code> the SQL integration is currently disabled.</p> <p>The IPython SQL extension (see https://pypi.org/project/ipython-sql/) is automatically loaded and the configured PLPipes <code>work</code> database set as the default one.</p> <p>Other databases configured in PLPipes can be selected using a double at sign (<code>@@</code>) followed by the database name.  For instance:</p> <pre><code>%%sql @@input\nselect * from customers\nlimit 100\n</code></pre>"},{"location":"license/","title":"The MIT License","text":"<pre><code>Copyright (c) 2023, 2024, 2025 PredictLand (info@predictland.com)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n</code></pre>"},{"location":"logging/","title":"Logging","text":"<p>Python standard logging framework is instantiated by the framework and can be used directly from actions code.</p> <p>If you need some particular configuration not yet supported, just ask for it!</p> <p>Also, take into account that some python frameworks (for instance, Tensorflow or OpenVINO) unconditionally change or overload python logging on its own.</p>"},{"location":"logging/#automatic-file-logging","title":"Automatic file logging","text":"<p>After initialization <code>plpipes</code> automatically creates a new file logger which saves a copy of the log in the <code>logs</code> directory. Also, on operating systems supporting symbolic links, it also creates a link named <code>logs\\last_log.txt</code>.</p>"},{"location":"msgraph/","title":"MS Graph","text":""},{"location":"msgraph/#microsoft-graph","title":"Microsoft Graph","text":"<p>Interaction with MS Graph API, which provides access to OneDrive, SharePoint and Teams resources, is available through the package <code>plpipes.cloud.azure.graph</code>.</p>"},{"location":"msgraph/#api","title":"API","text":"<ul> <li> <p><code>graph(account_name)</code>: returns an object of class    <code>msgraph.code.GraphClient</code>. Note that the Python Azure SDK is still in    beta, in a state of flush and so, this method may return objects of a    different class in the future.</p> </li> <li> <p><code>fs(account_name)</code>: returns an object that allows to access MS Graph     resources as a file system.</p> </li> </ul>"},{"location":"msgraph/#file-system-view","title":"File-system view","text":"<p>The file system facade class exposes MS Graph resources as a file system.</p> <p>Resources are exposed under different routes as follows:</p> <ul> <li> <p><code>me</code>: Business user OneDrive drive.</p> </li> <li> <p><code>groups</code>: Teams group drives.</p> </li> </ul> <p>The file system objects returned by <code>fs</code> support the following methods:</p> <ul> <li> <p><code>go(path)</code>: You can think of this method as a change dir (<code>cd</code>)     operation with the particularity that it also allows one to descend     into file-like resources.</p> <p>The returned value is a new file system object with the root at <code>path</code>.</p> </li> <li> <p><code>ls(path)</code>: Return a dictionary of file-name and entry pairs     representing the entries under the directory <code>path</code>.</p> </li> <li> <p><code>names(path)</code>: Similar to <code>ls</code> but returns only the names of the     entries.</p> </li> <li> <p><code>is_file()</code> and <code>is_dir()</code>: Determines where the current file system     object is pointing to a file or a directory respectively.</p> </li> <li> <p><code>get(path=\"\", dest=None, dir=None, name=None)</code>: downloads the remote     object pointed by the current file system object.</p> <p>When <code>dest</code> is given it is used as the local destination path.</p> <p>Alternatively, when <code>dest</code> is not given, <code>dir</code> and <code>name</code> values (or their defaults) are used to construct the local destination path. <code>name</code> defaults to the remote file name. <code>dir</code> defaults to the working directory (i.e. <code>cfg['fs.work']</code>).</p> </li> <li> <p><code>rget(path=\"\", dest=None, dir=None, name=None)</code>: recursively downloads     the remote object (typically a directory) to the current file     system.</p> </li> </ul> <p>Example usage:</p> <pre><code>import plpipes.cloud.azure.graph\n\nfs = plpipes.cloud.azure.graph.fs(\"predictland\")\ngroup_drive = fs.go(\"groups/HAL/General\")\ngroup_drive.rget(\"input-data\")\n</code></pre>"},{"location":"msgraph/#configuration","title":"Configuration","text":"<p>Currently, the only supported configuration parameter is <code>credentials</code> with must be the name of an Azure authentication account defined under <code>cloud.azure.auth</code>. When not given, it defaults to the one of the same name.</p> <pre><code>cloud:\n  azure:\n    graph:\n      predictland:\n        credentials: predictland\n</code></pre>"},{"location":"nomenclature/","title":"Nomenclature","text":"<p>We use <code>PLPipes</code> to refer to the framework as a whole (projects, code, conventions, mindset, etc.) and <code>plpipes</code> to refer specifically to the Python package.</p>"},{"location":"openai/","title":"OpenAI (ChatGPT)","text":"<p>PLPipes provides a very thin wrapper for the <code>openai</code> package.</p> <p>Currently, it just automates the authentication side, reading the API key from the configuration and setting it on the client package.</p> <pre><code>import plpipes.cloud.openai as openai\ncompletion = openai.Completion.create(...)\n</code></pre> <p>If used outside actions, if should be taken into account that PLPipes config subsystem must be initialized before importing <code>plpipes.cloud.openai</code>.</p>"},{"location":"openai/#configuration","title":"Configuration","text":"<pre><code>cloud:\n  openai:\n    auth:\n      api_key: YOUR-SECRET-KEY-GOES-HERE\n</code></pre>"},{"location":"other-network/","title":"Network","text":""},{"location":"other-network/#clients","title":"Clients","text":"<p>PLPipes provides a set of easy-to-use network clients for downloading data from several institutions.</p> <p>This is still a work in progress.</p>"},{"location":"other-network/#eurostat","title":"Eurostat","text":""},{"location":"other-network/#us-energy-information-administration-eia","title":"U.S. Energy Information Administration (EIA)","text":"<p>API key must be dowloaded from https://www.eia.gov/opendata/register.php and added into the configuration as <code>net.client.eia.api_key</code>.</p>"},{"location":"other-network/#european-central-bank-ecb","title":"European Central Bank (ECB)","text":""},{"location":"other-network/#us-bureau-of-labor-statistics-bls","title":"U.S. Bureau of Labor Statistics (BLS)","text":"<p>API key must be downloaded from https://data.bls.gov/registrationEngine/ and added into the configuration as <code>net.client.us_bls.api_key</code>.</p>"},{"location":"overview/","title":"Overview","text":"<p><code>PLPipes</code> is a progresive framework in the sense that you are not forced to use all of it in every project. You can just take advantage of some of the subsystems offered and ignore the rest if that suits you better.</p>"},{"location":"overview/#subsystems","title":"Subsystems","text":"<p>So, what are those subsystems?</p> <ul> <li> <p>Configuration: It handles the configuration of     your project (e.g. database credentials, file patchs,     hyperparameter, neural network definitions, etc.) and it is quite     powerful, supporting many features that would help the developer     keep everything tidy.</p> <p>It is the only mandatory component as all the rest build on top of it and use it pervasively.</p> </li> <li> <p>Database: It handles interaction with databases:     connections, transactions, reading and writing tables, integration     with data-frame frameworks as pandas or polars, etc.</p> </li> <li> <p>Actions: like scripts but better!</p> <p>This layer provides support for running several types of tasks as for instace running some python code, running a query in a database and saving the result as a new table, processing a <code>quarto</code> document, etc.</p> </li> <li> <p>Runner: It is a Python script which is used to run the     actions taking care of setting up the configuration, parsing command     line arguments, etc.</p> </li> <li> <p>Cloud: several packages are offered for calling into     common Cloud APIs (Azure, GoogleCloud, AWS, OpenAI, etc.).</p> <p>Some of then, perform basic functionality as authentication, others offer more advanced features as a FS layer which and unified interface for accessing any supported storage service.</p> </li> </ul>"},{"location":"overview/#the-plpipes-mindset","title":"The <code>PLPipes</code> mindset","text":"<p>Even if you can use some of those subsystems independently, in our (quite biased) opinion, it is better when you use all of then together!</p> <p>The big gain is that all of your projects are going to look the same. When somebody in your team gets to work in an already running project, he will not have to ask how to configure the access to the database, or how to get the data, or how to generate that fancy monthly report because it is going to be the same or very similar to its previous <code>PLPipes</code> projects.</p> <p>So, how is the typical <code>PLPipes</code> project?</p>"},{"location":"overview/#the-actions","title":"The Actions","text":"<p><code>PLPipes</code> projects are organized around actions which can be considered as atomic units of work. Examples of actions are downloading a file, transforming some data or training a model.</p> <p>Actions are grouped in sequences to create data processing pipelines. Several pipelines can be defined inside one project, and it is even possible to change which actions form a pipeline dynamically depending on the deployment environment, the configuration, command line arguments, etc.</p> <p>Even if the framework doesn't impose it, actions are usually organized in a similiar fashion. For instance, a common set of actions for a simple project could be:</p> <ul> <li><code>download</code></li> <li><code>preprocess</code></li> <li><code>train</code></li> <li><code>evaluate</code></li> <li><code>report</code></li> </ul> <p>In a more complex project, those actions could become sequence actions that call other actions doing smaller tasks, but the global structure is going to remain alike.</p>"},{"location":"overview/#the-database","title":"The Database","text":"<p>In the context of <code>PLPipes</code>, a central component is the relational database, which serves as a means of exchanging information between actions. While the file system and other means can be used alternatively, the database is the preferred choice, at least tabular data.</p> <p>With the default configuration, <code>PLPipes</code> creates a SQLite database in the local file system which is inmediately ready for the developer, whitout any setup work or programming required from its side.</p> <p>The framework also provides a rich set of functions for common tasks, such as executing queries and reading the data as data frames, appending data frames to tables, and synchronizing tables between databases.</p> <p>Utilizing a database offers several advantages:</p> <ol> <li> <p>Effortless Data Inspection: You can easily inspect the data using    your preferred database GUI client    (SQLiteStudio,    DBeaver, etc.), a Jupyter notebook, or    simply the SQLite CLI. This allows you to explore the data, perform    cross-referencing with other project data, and utilize SQL for    queries.</p> </li> <li> <p>Structured Data Design: Working with a database encourages    thoughtful data modeling and design.</p> </li> <li> <p>Schema Documentation: You can document the schema of your database,    aiding in understanding and maintaining your data structure.</p> </li> <li> <p>Clear Data Exchange: As you use the database to pass data between    actions, you establish a well-defined interface, enhancing clarity    and consistency.</p> </li> </ol> <p>This database-centric approach in <code>PLPipes</code> simplifies data management and empowers you to work efficiently with your project's data resources.</p> <p>Finally, several local, remote and cloud Databases are supported and can be configured.</p>"},{"location":"overview/#the-runner","title":"The Runner","text":"<p>The actions (or pipelines) are initiated by the runner, which is essentially a Python script that interfaces with <code>plpipes</code>. It has the capability to handle command-line arguments, configuration files, and environment variables in a unified manner.</p> <p>A typical runner invocation appears as follows:</p> <pre><code>python3 bin/run.py train evaluate -s model_name=resnet3\n</code></pre> <p>Users can also create custom runners to leverage the framework in various environments, such as Azure FunctionApps, AWS Lambdas, Jupyter notebooks, Spark and more.</p>"},{"location":"overview/#the-pervasive-configuration","title":"The Pervasive Configuration","text":"<p>All of <code>PLPipes</code> subsystems rely on a central configuration, each with specific expectations for retrieving their data. For example, configuring database connections consistently follows the same pattern across any <code>PLPipes</code> project. Once you've configured it for one, you'll find the process familiar and applicable to all.</p> <p>While certain parameters may vary (configuring a connection to a local file database differs from configuring one for a cloud-based server like Azure SQL) the fundamental approach remains consistent at a higher level.</p> <p>This approach also simplifies resource tracking for individual projects, as all resources are clearly declared within the configuration files.</p>"},{"location":"overview/#the-helper-modules","title":"The Helper Modules","text":"<p>Finally, <code>PLPipes</code> aims to be a rich framwork which could take care of any task related to a data scientest work.</p> <p>That is for instance the reason why it offers a cloud module and a powerful package for accessing several cloud storage services. Because even when it is not something core to the data scientist work, it is something than in practice we frequently need to do, and so it goes in!</p>"},{"location":"overview/#in-summary","title":"In Summary","text":"<p>In summary, when using <code>PLPipes</code>, instead of a bunch of scripts, every one doing something different, we have a set of pipelines built on top of actions that use a relational database to store intermediate data and we use a standardized python script to get everything running.</p> <p>Additionally, it provides a lot of additional modules to make the data scientist life much easier!</p>"},{"location":"project-setup/","title":"Project Setup","text":"<p>This chapter describes how to set up a PLPipes project from scratch.</p> <p>PLPipes is quite configurable and most of its workings can be changed and redefined, but that doesn't preclude it from offering some sane defaults that we advise you to follow.</p> <p>Specifically, by default, it expects some directory structure and a main script which is used to organize the project operations as described in the following sections:</p>"},{"location":"project-setup/#directory-structure","title":"Directory structure","text":"<p>A PLPipes project is structured in the following directories which should be created by hand (development of a utility to do it automatically is planed).</p> <ul> <li> <p><code>lib</code> (optional): This is where reusable Python modules specific to     the project are stored.</p> </li> <li> <p><code>bin</code>: This is the place where to place scripts for the     project. Though, usually if just contains the main     script <code>run.py</code>.</p> <p>Other scripts can be placed here, but it should be noted that the Actions mechanism available through <code>run.py</code> is the preferred way to organize the project operations.</p> </li> <li> <p><code>actions</code>: Action definitions. See Actions.</p> </li> <li> <p><code>notebooks</code> (optional): Jupyter notebooks go here.</p> </li> <li> <p><code>config</code>: Configuration files are stored here. See     Configuration.</p> </li> <li> <p><code>defaults</code> (optional): Default configuration files go here (the     contents of this directory should be committed to git).</p> <p>The semantic distinction between <code>defaults</code> and <code>config</code> is something we are still considering and that may change.</p> </li> <li> <p><code>input</code> (optional): Project input files.</p> </li> <li> <p><code>work</code>: Working directory, intermediate files go here.</p> <p>Also, the default working database is stored here as <code>work/work.duckdb</code>.</p> </li> <li> <p><code>output</code> (optional): Final output files generated can go here.</p> </li> <li> <p><code>venv</code> (optional): Even if <code>plpipes</code> does not depend on it, we     recommend to use a virtual environment for the project whit that     name.</p> </li> </ul>"},{"location":"project-setup/#the-main-script","title":"The main script","text":"<p><code>bin/run.py</code> is the main entry point for PLPipes and should be created by hand with the following content:</p> <pre><code>#!/usr/bin/env python3\nfrom plpipes.runner import main\nmain()\n</code></pre>"},{"location":"runner/","title":"Runner","text":"<p>The purpose of the runner is to provide a unified entry point for project actions and pipelines.</p> <p>It extracts information from a set of environment variables and also parses command line arguments in a standardized manner.</p>"},{"location":"runner/#command-line-arguments","title":"Command line arguments","text":"<p>The accepted command line arguments are as follows:</p> <ul> <li> <p><code>-d</code>, <code>--debug</code>: Sets the logging level to debug.</p> </li> <li> <p><code>-c file</code>, <code>--config file</code>: Reads configuration settings from the specified file.</p> </li> <li> <p><code>-s key=value</code>, <code>--set key=value</code>: Sets the given configuration. For example: <code>-s fs.output=/var/storage/ai-output</code>.</p> </li> <li> <p><code>-S key=value</code>, <code>--set-json key=value</code>: Parses the provided value as JSON and sets the corresponding configuration entry.</p> </li> <li> <p><code>-e env</code>, <code>--env env</code>: Defines the deployment environment.</p> </li> <li> <p><code>action1 action2 ...</code>: A list of actions to execute.</p> </li> </ul>"},{"location":"runner/#environment-variables","title":"Environment variables","text":"<p>The following environment variables can be used to configure the framework:</p> <ul> <li> <p><code>PLPIPES_ROOT_DIR</code>: The project root directory.</p> </li> <li> <p><code>PLPIPES_ENV</code>: The deployment environment (typically <code>DEV</code>, <code>PRE</code>, or <code>PRO</code>).</p> </li> <li> <p><code>PLPIPES_LOGLEVEL</code>: The default log level (<code>debug</code>, <code>info</code>, <code>warning</code>, or <code>error</code>).</p> </li> </ul>"},{"location":"runner/#under-the-hood","title":"Under the hood","text":"<p>The runner consists of two parts: a small <code>run.py</code> script that serves as a thin wrapper for the  <code>main</code> function provided by <code>plpipes.runner</code>.</p> <p><code>run.py</code> is necessary as <code>plpipes</code> uses the script's path to locate the project root directory and other related files.</p>"},{"location":"runner/#custom-scripts","title":"Custom scripts","text":"<p>In some cases, you may need to create a custom script outside the actions structure. To do this, you can write a custom runner as follows:</p> <pre><code>import plpipes.runner\n\n# Get a pre-initialized argument parser\narg_parser = plpipes.runner.arg_parser()\n\n# Add new options to the argument parser if needed\narg_parser.add_argument(...)\n\n# Parse arguments and initialize plpipes\nopts = plpipes.runner.parse_args_and_init(arg_parser, sys.argv)\n\n# Your code goes here!!!\n</code></pre> <p>For simpler cases where no additional arguments are required, the framework also provides a <code>simple_init</code> function:</p> <pre><code>import plpipes.runner\nplpipes.runner.simple_init()\n\n# Your code goes here!!!\n</code></pre> <p>It's worth noting that PLPipes uses the script name (or its stem) as a key when loading configuration files, enabling the use of different configurations for scripts that are loaded automatically. Refer to the configuration File Structure section above.</p>"},{"location":"spark/","title":"Spark","text":"<p><code>plpipes</code> provides an integration layer for Spark/Databricks via the package <code>plpipes.spark</code> and also a set of database backends and drivers for using the Spark DB engine as a regular database.</p> <p>Spark support should still be considered experimental.</p>"},{"location":"spark/#sparksession","title":"SparkSession","text":"<p>SparkSession setup is performed using a set of drivers, which handle different environments.</p> <p>Currently, the supported drivers are as follow:</p> <ul> <li> <p><code>embedded</code>: initializes a Spark environment without any external   infrastructure. Once the Python program ends, the Spark system also   shuts down.</p> </li> <li> <p><code>databricks</code>: connects to a remote Databricks cluster using   <code>databricks-connect</code>.</p> </li> </ul> <p>Every driver accepts a different set of configuration options which are described below.</p>"},{"location":"spark/#usage","title":"Usage","text":"<p>A Spark session can be accesed as follows:</p> <pre><code>from plpipes.spark import spark_session\n\nspark = spark_session()\n...\n</code></pre> <p>Any action needed to initialize the session or any other subsystem is performed automatically.</p>"},{"location":"spark/#configuration","title":"Configuration","text":"<p>The Spark layer is configured through the <code>spark</code> entry. A <code>driver</code> setting is used to pick which driver to use, any other accepted configuration is driver-dependent.</p> <p>Example:</p> <pre><code>spark:\n  driver: embedded\n  log_level: WARN\n  extra:\n    spark:\n      foo: footomal\n</code></pre> <p>The entries supported by the different drivers are as follows:</p>"},{"location":"spark/#embedded-driver","title":"<code>embedded</code> driver","text":"<ul> <li><code>app_name</code>: application name (defaults to <code>work</code>).</li> <li><code>home</code>: spark working directory (defaults to <code>work/spark</code>).</li> <li><code>extra</code>: subtree containing extra configuration options which are   passed verbatim to the <code>SparkSession.builder.config</code> method. Note   that the options accepted by that method usually start by <code>spark</code>.   See the Spark   documentation   for details.</li> </ul>"},{"location":"spark/#databricks-driver","title":"<code>databricks</code> driver","text":"<ul> <li><code>profile</code>: profile name as defined in the file <code>~/.databrickscfg</code>   (defaults to <code>DEFAULT</code>).</li> <li><code>extra</code> subtree containing extra configuration options which are   passed verbatim to the <code>SparkSession.builder.config</code> method. Note   that the options accepted by that method usually start by <code>spark</code>.   See the Spark   documentation   for details.</li> </ul>"},{"location":"spark/#database-integration","title":"Database integration","text":"<p>Spark database engine can be accessed through the <code>plpipes.database</code> package as any other database.</p> <p>See Databases for the details.</p>"},{"location":"spark/#databricks-integration","title":"Databricks integration","text":"<p>Access to Spark clusters inside Databricks is provided through the <code>databricks</code> driver. It expects to find a <code>databricks-connect</code> profile already configured in the file <code>~/.databrickscfg</code>.</p> <p>That file can be created automatically using the Databricks CLI which accepts several authentication mechanisms.</p> <p>The following command can be used to initialize a profile:</p> <pre><code>databricks auth login --host &lt;workspace-url&gt;\n</code></pre> <p>The workspace-url can be taken the host part of the URL from the web browser when inside the Databricks environment. It usually looks like <code>https://adb-xxxxxxxxxxx.azuredatabricks.net</code>.</p> <p>Also, the <code>cluster_id</code> must be added by hand to the profile. It appears on the URL when inspecting the cluster inside the Databricks environment.</p> <p>Sample <code>.databrickscfg</code> file:</p> <pre><code>; The profile defined in the DEFAULT section is to be used as a fallback when no profile is explicitly specified.\n[DEFAULT]\nhost       = https://adb-xxxxxxxxxxxxxxxx.azuredatabricks.net\nauth_type  = databricks-cli\ncluster_id = 0123-123456-ht3tynfg\n</code></pre>"},{"location":"reference/plpipes/","title":"plpipes","text":"<p>Module for the plpipes package.</p> <p>This module serves as a container for the plpipes library. All the interesting functionalities and features are implemented in the  submodules of this package.</p>"},{"location":"reference/summary/","title":"Reference","text":"<ul> <li><code>plpipes</code></li> <li><code>plpipes.action</code></li> <li><code>plpipes.action.base</code></li> <li><code>plpipes.action.driver</code></li> <li><code>plpipes.action.driver.archive_unpacker</code></li> <li><code>plpipes.action.driver.downloader</code></li> <li><code>plpipes.action.driver.downloader.helpers</code></li> <li><code>plpipes.action.driver.downloader.service</code></li> <li><code>plpipes.action.driver.downloader.service.aemet</code></li> <li><code>plpipes.action.driver.downloader.service.ine</code></li> <li><code>plpipes.action.driver.file_downloader</code></li> <li><code>plpipes.action.driver.loop</code></li> <li><code>plpipes.action.driver.prql</code></li> <li><code>plpipes.action.driver.quarto</code></li> <li><code>plpipes.action.driver.simple</code></li> <li><code>plpipes.action.driver.sql</code></li> <li><code>plpipes.action.driver.sql.jinja2</code></li> <li><code>plpipes.action.registry</code></li> <li><code>plpipes.action.runner</code></li> <li><code>plpipes.autoaction</code></li> <li><code>plpipes.cloud</code></li> <li><code>plpipes.cloud.azure</code></li> <li><code>plpipes.cloud.azure.auth</code></li> <li><code>plpipes.cloud.azure.auth.base</code></li> <li><code>plpipes.cloud.azure.auth.plugin</code></li> <li><code>plpipes.cloud.azure.auth.plugin.azure_cli</code></li> <li><code>plpipes.cloud.azure.auth.plugin.client_secret</code></li> <li><code>plpipes.cloud.azure.auth.plugin.interactive_browser</code></li> <li><code>plpipes.cloud.azure.auth.plugin.managed_identity</code></li> <li><code>plpipes.cloud.azure.graph</code></li> <li><code>plpipes.cloud.google</code></li> <li><code>plpipes.cloud.google.auth</code></li> <li><code>plpipes.cloud.google.auth.base</code></li> <li><code>plpipes.cloud.google.auth.plugin</code></li> <li><code>plpipes.cloud.google.auth.plugin.oauth2</code></li> <li><code>plpipes.cloud.google.vertexai</code></li> <li><code>plpipes.cloud.openai</code></li> <li><code>plpipes.cloud.openai.provider</code></li> <li><code>plpipes.cloud.openai.provider.plugin</code></li> <li><code>plpipes.cloud.openai.provider.plugin.azure</code></li> <li><code>plpipes.cloud.openai.provider.plugin.openai</code></li> <li><code>plpipes.config</code></li> <li><code>plpipes.database</code></li> <li><code>plpipes.database.backend</code></li> <li><code>plpipes.database.backend.dict</code></li> <li><code>plpipes.database.backend.geopandas</code></li> <li><code>plpipes.database.backend.pandas</code></li> <li><code>plpipes.database.backend.plugin</code></li> <li><code>plpipes.database.backend.plugin.dict</code></li> <li><code>plpipes.database.backend.plugin.geopandas</code></li> <li><code>plpipes.database.backend.plugin.geopandas__spatialite</code></li> <li><code>plpipes.database.backend.plugin.pandas</code></li> <li><code>plpipes.database.backend.plugin.pandas__spark</code></li> <li><code>plpipes.database.backend.plugin.spark</code></li> <li><code>plpipes.database.backend.plugin.tuple</code></li> <li><code>plpipes.database.backend.spark</code></li> <li><code>plpipes.database.backend.tuple</code></li> <li><code>plpipes.database.driver</code></li> <li><code>plpipes.database.driver.filedb</code></li> <li><code>plpipes.database.driver.mysql</code></li> <li><code>plpipes.database.driver.odbc</code></li> <li><code>plpipes.database.driver.plugin</code></li> <li><code>plpipes.database.driver.plugin.duckdb</code></li> <li><code>plpipes.database.driver.plugin.influxdb1</code></li> <li><code>plpipes.database.driver.plugin.mariadb</code></li> <li><code>plpipes.database.driver.plugin.mysql</code></li> <li><code>plpipes.database.driver.plugin.postgresql</code></li> <li><code>plpipes.database.driver.plugin.spark</code></li> <li><code>plpipes.database.driver.plugin.spatialite</code></li> <li><code>plpipes.database.driver.plugin.sql_server</code></li> <li><code>plpipes.database.driver.plugin.sqlite</code></li> <li><code>plpipes.database.driver.sql_server</code></li> <li><code>plpipes.database.driver.sqlalchemy</code></li> <li><code>plpipes.database.driver.sqlite</code></li> <li><code>plpipes.database.driver.sqlite.extension</code></li> <li><code>plpipes.database.driver.sqlite.extension.vss</code></li> <li><code>plpipes.database.driver.transaction</code></li> <li><code>plpipes.database.sqlext</code></li> <li><code>plpipes.exceptions</code></li> <li><code>plpipes.filesystem</code></li> <li><code>plpipes.init</code></li> <li><code>plpipes.jupyter</code></li> <li><code>plpipes.net</code></li> <li><code>plpipes.net.client</code></li> <li><code>plpipes.net.client.eurostat</code></li> <li><code>plpipes.net.client.us_bls</code></li> <li><code>plpipes.net.client.us_ecb</code></li> <li><code>plpipes.net.client.us_eia</code></li> <li><code>plpipes.plugin</code></li> <li><code>plpipes.runner</code></li> <li><code>plpipes.spark</code></li> <li><code>plpipes.spark.plugin</code></li> <li><code>plpipes.spark.plugin.databricks</code></li> <li><code>plpipes.spark.plugin.embedded</code></li> <li><code>plpipes.tool</code></li> <li><code>plpipes.tool.dbeaver</code></li> <li><code>plpipes.tool.dbeaver.__main__</code></li> <li><code>plpipes.tool.dbeaver.conarg</code></li> <li><code>plpipes.tool.dbeaver.conarg.driver</code></li> <li><code>plpipes.tool.dbeaver.conarg.driver.azure_sql</code></li> <li><code>plpipes.tool.dbeaver.conarg.driver.mariabd</code></li> <li><code>plpipes.tool.dbeaver.conarg.driver.mysql</code></li> <li><code>plpipes.tool.dbeaver.conarg.driver.sql_server</code></li> <li><code>plpipes.tool.dbeaver.conarg.driver.sqlite</code></li> <li><code>plpipes.tool.dbeaver.conarg.mysql</code></li> <li><code>plpipes.tool.dbeaver.conarg.sql_server</code></li> <li><code>plpipes.tool.ipython</code></li> <li><code>plpipes.tool.ipython.__main__</code></li> <li><code>plpipes.tool.run</code></li> <li><code>plpipes.tool.run.__main__</code></li> <li><code>plpipes.util</code></li> <li><code>plpipes.util.contextvar</code></li> <li><code>plpipes.util.database</code></li> <li><code>plpipes.util.method_decorators</code></li> <li><code>plpipes.util.net</code></li> <li><code>plpipes.util.pluralsingular</code></li> <li><code>plpipes.util.typedict</code></li> </ul>"},{"location":"reference/plpipes/action/","title":"plpipes.action","text":"<p>This module handles the registration and execution of various action drivers for the plpipes framework.</p> <p>Action drivers are responsible for executing specific types of actions defined within the project. The supported action drivers include simple actions, SQL actions, downloading actions, quarto processing, file downloading, archive unpacking, and loop actions.</p>"},{"location":"reference/plpipes/autoaction/","title":"plpipes.autoaction","text":"<p>plpipes.autoaction</p> <p>This module is a \"magic\" module that enables Python actions to be executed as if they were standard scripts. It should be imported at the beginning of any action script, as it performs necessary initialization and variable injection.</p> <p>When imported, this module checks if the plpipes environment is initialized. If it is not, it sets up the environment and injects variables into the calling code's global namespace. This includes variables defined by PLPipes for actions, making them readily available for the action script without requiring explicit definitions.</p> <p>Usage: - Import this module at the very start of your action script to ensure proper initialization and variable accessibility. - The module will automatically handle the necessary setup and variable injection.</p> <p>Example:</p> <pre><code>import plpipes.autoaction\n# Your action script logic follows...\n</code></pre> <p>Exceptions: - If the module is not the first import in the script, an exception will be raised indicating that the plpipes.autoaction must be the first sentence in the action script.</p>"},{"location":"reference/plpipes/cloud/","title":"plpipes.cloud","text":"<p>This module is just a container for its submodules.</p>"},{"location":"reference/plpipes/config/","title":"plpipes.config","text":"<p>This module provides a configuration management system.  The main way to access the configuration is through the global variable <code>cfg</code>,  which behaves like a dictionary but supports dotted keys for hierarchical  access to configuration entries.</p>"},{"location":"reference/plpipes/config/#plpipes.config.cfg","title":"<code>cfg = cfg_stack.root()</code>  <code>module-attribute</code>","text":"<p>Singleton instance of the configuration object provided by PLPipes. This object allows access to the configuration settings managed by plpipes and this module (plpipes.config). It provides a dictionary-like interface to retrieve and manipulate configuration values.</p>"},{"location":"reference/plpipes/config/#plpipes.config.ConfigStack","title":"<code>ConfigStack</code>","text":"<p>Manage a stack of configuration frames.</p> Source code in <code>src/plpipes/config.py</code> <pre><code>class ConfigStack:\n    \"\"\"Manage a stack of configuration frames.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize a new ConfigStack with empty frames and cache.\"\"\"\n        self._frames = []\n        self._cache = {}\n\n    def _cd(self, path):\n        \"\"\"Change directory to the given path in the configuration stack.\"\"\"\n        return _Ptr(self, path)\n\n    def root(self):\n        \"\"\"Return a pointer to the root of the configuration.\"\"\"\n        return self._cd(\"\")\n\n    def reset_cache(self):\n        \"\"\"Reset the caching mechanism for configuration retrieval.\"\"\"\n        self._cache = {}\n\n    def _get(self, key, frame=0):\n        \"\"\"Get the value of a configuration key, with caching.\"\"\"\n        if frame == 0:\n            if key not in self._cache:\n                self._cache[key] = self._get_nocache(key, 0)\n            return self._cache[key]\n        else:\n            return self._get_nocache(key, frame)\n\n    def _get_nocache(self, key, frame):\n        \"\"\"\n        Retrieve the value associated with a given configuration key\n        while considering wildcard entries and frame specificity.\n\n        The method implements a search algorithm that takes into account\n        the specificity of configuration entries and their order of \n        loading based on frame. It follows these rules:\n\n        1. More specific entries always win over less specific ones.\n        2. For entries with the same specificity, the one from the\n           lowest frame (last loaded) wins.\n\n        This is implemented using a mix of A*/depth-first search algorithm.\n\n        Parameters:\n        key (str): The configuration key to look up, expressed in\n                   dotted notation.\n        frame: The frame context from which to retrieve the key.\n\n        Returns:\n        The value associated with the specified key.\n\n        Raises:\n        KeyError: If the key is not found in the configuration.\n        ValueError: If the key does not point to a terminal node.\n        \"\"\"\n\n        (key_part, *right) = key.split(\".\")\n        # queue structure:\n        #   specificity, frame_ix, tree, left_path, frozen_key, rigth_path\n        queue = [(('!', '*')[k], ix, f, (key_part, '*')[k], (key_part, '*')[k], right)\n                 for ix, f in enumerate(self._frames[frame:])\n                 for k in (0, 1)]\n        while queue:\n            queue.sort(reverse=True)\n            (specifity, frame_ix, tree, left, key_part, right) = queue.pop()\n            while True:\n                try:\n                    if isinstance(tree, dict):\n                        tree = tree[key_part]\n                    elif isinstance(tree, list):\n                        queue = []\n                        if key_part.isnumeric():\n                            tree = tree[int(key_part)]\n                        else:\n                            raise IndexError(\"Expecting numeric key\")\n                    else:\n                        raise ValueError(f\"Config key '{key}' traversing blocked by a non dictionary object at {left}\")\n                except (IndexError, KeyError):\n                    break\n\n                if right:\n                    (key_part, *right) = right\n                    queue.append((specifity + \"*\", frame_ix, tree, left + \".*\", '*', right))\n                    left = left + \".\" + key_part\n                    specifity += \"!\"\n                else:\n                    if isinstance(tree, dict):\n                        raise ValueError(f\"config key '{key}' does not point to a terminal node\")\n                    return tree\n        raise KeyError(f\"config key '{key}' not found\")\n\n    def _contains(self, key):\n        \"\"\"Check if the configuration contains the specified key.\"\"\"\n        try:\n            self._get(key, 0)\n            return True\n        except KeyError:\n            return False\n\n    def _merge(self, key, newtree, frame=0):\n        \"\"\"Merge new configuration data into the specified key of the frame.\"\"\"\n        # Auto-allocate frames\n        if len(self._frames) &lt;= frame:\n            self._frames += [{} for _ in range(frame - len(self._frames) + 1)]\n        tree = self._frames[frame]\n\n        if key != \"\":\n            parts = key.split(\".\")\n            last = parts.pop()\n            for p in parts:\n                if (p not in tree) or (not isinstance(tree[p], dict)):\n                    tree[p] = {}\n                tree = tree[p]\n            tree[last] = _merge_any(tree.get(last, None), newtree)\n        else:\n            if not isinstance(newtree, dict):\n                raise ValueError(\"Top configuration must be a dictionary\")\n            self._frames[frame] = _merge_any(tree, newtree)\n        self._cache = {}\n\n    def _set(self, key, value):\n        \"\"\"Set the value for a given configuration key.\"\"\"\n        if not isinstance(value, (str, int, float, bool, list)) and value is not None:\n            if isinstance(value, dict):\n                raise ValueError(\"It is not possible to set a configuration entry to a dictionary, use merge instead\")\n            value = str(value)\n        self._merge(key, value)\n\n    def _multicd(self, key):\n        \"\"\"Change directory to a key, considering all matching frames.\"\"\"\n        # queue structure:\n        #   specificity, frame_ix, tree\n        queue = [(\"\", ix, f) for ix, f in enumerate(self._frames)]\n        if key != \"\":\n            right = key.split(\".\")\n            while right:\n                queue.sort()\n                key = right.pop(0)\n                new_queue = []\n                for specifity, ix, tree in queue:\n                    if isinstance(tree, dict):\n                        for s in ('!', '*'):\n                            k = s if s == '*' else key\n                            if k in tree:\n                                new_queue.append((specifity + s, ix, tree[k]))\n                    elif not new_queue:\n                        raise ValueError(f\"Config key '{key}' blocked by a non dictionary object\")\n                    else:\n                        break\n                queue = new_queue\n        return [t for _, _, t in sorted(queue, reverse=True)]\n\n    def _to_tree(self, key, defaults=None):\n        \"\"\"Convert a key's configuration to a tree structure.\"\"\"\n        m = self._multicd(key)\n        tree = {}\n        if defaults is not None:\n            tree = _merge_any(tree, defaults)\n        for other in m:\n            tree = _merge_any(tree, other)\n        return tree\n\n    def _keys(self, key):\n        \"\"\"Retrieve the keys in a specified configuration key.\"\"\"\n        m = self._multicd(key)\n        seen = set()\n        inner_is_dict = True\n        for other in m:\n            if isinstance(other, dict):\n                if not inner_is_dict:\n                    inner_is_dict = True\n                    seen = set()\n                for k in other.keys():\n                    if k != '*':\n                        seen.add(k)\n            else:\n                inner_is_dict = False\n        if inner_is_dict:\n            return sorted(seen)\n        raise ValueError(f\"Config key '{key}' blocked by a non dictionary object\")\n\n    def _squash_frames(self):\n        \"\"\"Merge all frames into one.\"\"\"\n        tree = self._frames.pop()\n        while self._frames:\n            tree = _merge_any(tree, self._frames.pop())\n        self._frames.append(tree)\n</code></pre>"},{"location":"reference/plpipes/config/#plpipes.config.ConfigStack.__init__","title":"<code>__init__()</code>","text":"<p>Initialize a new ConfigStack with empty frames and cache.</p> Source code in <code>src/plpipes/config.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a new ConfigStack with empty frames and cache.\"\"\"\n    self._frames = []\n    self._cache = {}\n</code></pre>"},{"location":"reference/plpipes/config/#plpipes.config.ConfigStack.reset_cache","title":"<code>reset_cache()</code>","text":"<p>Reset the caching mechanism for configuration retrieval.</p> Source code in <code>src/plpipes/config.py</code> <pre><code>def reset_cache(self):\n    \"\"\"Reset the caching mechanism for configuration retrieval.\"\"\"\n    self._cache = {}\n</code></pre>"},{"location":"reference/plpipes/config/#plpipes.config.ConfigStack.root","title":"<code>root()</code>","text":"<p>Return a pointer to the root of the configuration.</p> Source code in <code>src/plpipes/config.py</code> <pre><code>def root(self):\n    \"\"\"Return a pointer to the root of the configuration.\"\"\"\n    return self._cd(\"\")\n</code></pre>"},{"location":"reference/plpipes/database/","title":"plpipes.database","text":""},{"location":"reference/plpipes/database/#plpipes.database.begin","title":"<code>begin(db=None)</code>","text":"<p>Begin a transaction on the specified database instance.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>The name of the database instance to begin a transaction. Defaults to \"work\".</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Transaction</code> <p>A transaction object for the database.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def begin(db=None):\n    \"\"\"\n    Begin a transaction on the specified database instance.\n\n    Args:\n        db (str, optional): The name of the database instance to begin a transaction. Defaults to \"work\".\n\n    Returns:\n        Transaction: A transaction object for the database.\n    \"\"\"\n    return lookup(db).begin()\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.copy_table","title":"<code>copy_table(from_table_name, to_table_name=None, from_db=None, to_db=None, db=None, if_exists='replace', **kws)</code>","text":"<p>Copy a table from one database instance to another.</p> <p>Parameters:</p> Name Type Description Default <code>from_table_name</code> <code>str</code> <p>The name of the source table to copy.</p> required <code>to_table_name</code> <code>str</code> <p>The name of the destination table. Defaults to the source table name.</p> <code>None</code> <code>from_db</code> <code>str</code> <p>The source database instance to copy from.</p> <code>None</code> <code>to_db</code> <code>str</code> <p>The destination database instance to copy to.</p> <code>None</code> <code>db</code> <code>str</code> <p>The current database instance.</p> <code>None</code> <code>if_exists</code> <code>str</code> <p>What to do if the destination table already exists. Defaults to \"replace\".</p> <code>'replace'</code> <code>**kws</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def copy_table(from_table_name, to_table_name=None,\n               from_db=None, to_db=None, db=None,\n               if_exists=\"replace\", **kws):\n    \"\"\"\n    Copy a table from one database instance to another.\n\n    Args:\n        from_table_name (str): The name of the source table to copy.\n        to_table_name (str, optional): The name of the destination table. Defaults to the source table name.\n        from_db (str, optional): The source database instance to copy from.\n        to_db (str, optional): The destination database instance to copy to.\n        db (str, optional): The current database instance.\n        if_exists (str, optional): What to do if the destination table already exists. Defaults to \"replace\".\n        **kws: Additional keyword arguments.\n\n    Returns:\n        None\n    \"\"\"\n    if to_table_name is None:\n        to_table_name = from_table_name.split(\".\")[-1]\n\n    if from_db is None:\n        from_db = db\n    if to_db is None:\n        to_db = db\n\n    with _begin_or_pass_through(from_db) as from_txn:\n        if from_db == to_db:\n            logging.debug(f\"copy table {from_table_name} as {to_table_name} inside db {from_txn.db_name()}\")\n            from_txn.copy_table(from_table_name, to_table_name, if_exists=if_exists, **kws)\n        else:\n            with _begin_or_pass_through(to_db) as to_txn:\n                logging.debug(f\"copy table {from_table_name} from db {from_txn.db_name()} as {to_table_name} in db {to_txn.db_name()}\")\n                if if_exists == \"replace\":\n                    to_txn.drop_table(to_table_name)\n                    if_exists=\"append\"\n                elif if_exists == \"drop_rows\":\n                    to_txn.drop_table_rows(to_table_name)\n                    if_exists=\"append\"\n                first = True\n                for df in from_txn.read_table_chunked(from_table_name, **kws):\n                    if first:\n                        to_txn.create_table(to_table_name, df, if_exists=if_exists)\n                        first = False\n                    else:\n                        to_txn.create_table(to_table_name, df, if_exists=\"append\")\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.create_table","title":"<code>create_table(table_name, sql_or_df, parameters=None, db=None, if_exists='replace', **kws)</code>","text":"<p>Create a new table in the database from a DataFrame, SQL command, or SQLAlchemy select object.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to create.</p> required <code>sql_or_df</code> <code>DataFrame, str, or SQLAlchemy select object</code> <p>The DataFrame, SQL command, or SQLAlchemy select object for creating the table.</p> required <code>parameters</code> <code>dict</code> <p>The parameters for creating the table.</p> <code>None</code> <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>if_exists</code> <code>str</code> <p>What to do if the table already exists. Defaults to \"replace\".</p> <code>'replace'</code> <code>**kws</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def create_table(table_name, sql_or_df, parameters=None, db=None, if_exists=\"replace\", **kws):\n    \"\"\"\n    Create a new table in the database from a DataFrame, SQL command, or SQLAlchemy select object.\n\n    Args:\n        table_name (str): The name of the table to create.\n        sql_or_df (DataFrame, str, or SQLAlchemy select object): The DataFrame, SQL command, or SQLAlchemy select object for creating the table.\n        parameters (dict, optional): The parameters for creating the table.\n        db (str, optional): The database instance to use.\n        if_exists (str, optional): What to do if the table already exists. Defaults to \"replace\".\n        **kws: Additional keyword arguments.\n\n    Returns:\n        None\n    \"\"\"\n    logging.debug(f\"create table {table_name}\")\n    with _begin_or_pass_through(db) as txn:\n        return txn.create_table(table_name, sql_or_df, parameters, if_exists, **kws)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.create_view","title":"<code>create_view(view_name, sql, parameters=None, db=None, if_exists='replace', **kws)</code>","text":"<p>Create a new view in the database.</p> <p>Parameters:</p> Name Type Description Default <code>view_name</code> <code>str</code> <p>The name of the view to create.</p> required <code>sql</code> <code>str</code> <p>The SQL command for creating the view.</p> required <code>parameters</code> <code>dict</code> <p>The parameters for creating the view.</p> <code>None</code> <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>if_exists</code> <code>str</code> <p>What to do if the view already exists. Defaults to \"replace\".</p> <code>'replace'</code> <code>**kws</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def create_view(view_name, sql, parameters=None, db=None, if_exists=\"replace\", **kws):\n    \"\"\"\n    Create a new view in the database.\n\n    Args:\n        view_name (str): The name of the view to create.\n        sql (str): The SQL command for creating the view.\n        parameters (dict, optional): The parameters for creating the view.\n        db (str, optional): The database instance to use.\n        if_exists (str, optional): What to do if the view already exists. Defaults to \"replace\".\n        **kws: Additional keyword arguments.\n\n    Returns:\n        None\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.create_view(view_name, sql, parameters, if_exists, **kws)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.drop_table","title":"<code>drop_table(table_name, db=None, only_if_exists=False)</code>","text":"<p>Drop a table from the database.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to drop.</p> required <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>only_if_exists</code> <code>bool</code> <p>If True, do not raise an error if the table does not exist.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def drop_table(table_name, db=None, only_if_exists=False):\n    \"\"\"\n    Drop a table from the database.\n\n    Args:\n        table_name (str): The name of the table to drop.\n        db (str, optional): The database instance to use.\n        only_if_exists (bool, optional): If True, do not raise an error if the table does not exist.\n\n    Returns:\n        None\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.drop_table(table_name, only_if_exists)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.engine","title":"<code>engine(db=None)</code>","text":"<p>Retrieve the database engine for the specified database instance.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>The name of the database instance to retrieve the engine for. Defaults to \"work\".</p> <code>None</code> <p>Returns:</p> Name Type Description <code>engine</code> <p>The database engine object.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def engine(db=None):\n    \"\"\"\n    Retrieve the database engine for the specified database instance.\n\n    Args:\n        db (str, optional): The name of the database instance to retrieve the engine for. Defaults to \"work\".\n\n    Returns:\n        engine: The database engine object.\n    \"\"\"\n    return lookup(db).engine()\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.execute","title":"<code>execute(sql, parameters=None, db=None)</code>","text":"<p>Execute a SQL command that does not return a result set.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL command to execute.</p> required <code>parameters</code> <code>dict</code> <p>The parameters for the SQL command.</p> <code>None</code> <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def execute(sql, parameters=None, db=None):\n    \"\"\"\n    Execute a SQL command that does not return a result set.\n\n    Args:\n        sql (str): The SQL command to execute.\n        parameters (dict, optional): The parameters for the SQL command.\n        db (str, optional): The database instance to use.\n\n    Returns:\n        None\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.execute(sql, parameters)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.execute_script","title":"<code>execute_script(sql_script, db=None)</code>","text":"<p>Execute a sequence of SQL commands.</p> <p>Parameters:</p> Name Type Description Default <code>sql_script</code> <code>str</code> <p>The SQL script to execute.</p> required <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def execute_script(sql_script, db=None):\n    \"\"\"\n    Execute a sequence of SQL commands.\n\n    Args:\n        sql_script (str): The SQL script to execute.\n        db (str, optional): The database instance to use.\n\n    Returns:\n        None\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.execute_script(sql_script)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.list_tables","title":"<code>list_tables(db=None)</code>","text":"<p>List all tables in the specified database.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of table names in the database.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def list_tables(db=None):\n    \"\"\"\n    List all tables in the specified database.\n\n    Args:\n        db (str, optional): The database instance to use.\n\n    Returns:\n        list: A list of table names in the database.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.list_tables()\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.list_views","title":"<code>list_views(db=None)</code>","text":"<p>List all views in the specified database.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of view names in the database.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def list_views(db=None):\n    \"\"\"\n    List all views in the specified database.\n\n    Args:\n        db (str, optional): The database instance to use.\n\n    Returns:\n        list: A list of view names in the database.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.list_views()\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.load_backend","title":"<code>load_backend(name, db=None)</code>","text":"<p>Load a specific backend into the database driver.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the backend to load.</p> required <code>db</code> <code>str</code> <p>The database instance to load the backend into. Defaults to \"work\".</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def load_backend(name, db=None):\n    \"\"\"\n    Load a specific backend into the database driver.\n\n    Args:\n        name (str): The name of the backend to load.\n        db (str, optional): The database instance to load the backend into. Defaults to \"work\".\n\n    Returns:\n        None\n    \"\"\"\n    lookup(db).load_backend(name)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.lookup","title":"<code>lookup(db=None)</code>","text":"<p>Lookup the database driver instance for the specified database.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>The name of the database instance to look up. Defaults to \"work\".</p> <code>None</code> <p>Returns:</p> Name Type Description <code>driver</code> <p>The database driver instance.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def lookup(db=None):\n    \"\"\"\n    Lookup the database driver instance for the specified database.\n\n    Args:\n        db (str, optional): The name of the database instance to look up. Defaults to \"work\".\n\n    Returns:\n        driver: The database driver instance.\n    \"\"\"\n    if db is None:\n        db = \"work\"\n    if db not in _db_registry:\n        _db_registry[db] = _init_driver(db)\n    return _db_registry[db]\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.query","title":"<code>query(sql, parameters=None, db=None, backend=None, **kws)</code>","text":"<p>Execute a SQL query and return the results.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>The parameters for the SQL query.</p> <code>None</code> <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>backend</code> <code>str</code> <p>The backend to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>The results of the query as a DataFrame.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def query(sql, parameters=None, db=None, backend=None, **kws):\n    \"\"\"\n    Execute a SQL query and return the results.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): The parameters for the SQL query.\n        db (str, optional): The database instance to use.\n        backend (str, optional): The backend to use.\n\n    Returns:\n        DataFrame: The results of the query as a DataFrame.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.query(sql, parameters, backend, **kws)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.query_chunked","title":"<code>query_chunked(sql, parameters=None, db=None, backend=None, **kws)</code>","text":"<p>Execute a SQL query and yield results in chunks.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>The parameters for the SQL query.</p> <code>None</code> <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>backend</code> <code>str</code> <p>The backend to use.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Yields:</p> Name Type Description <code>DataFrame</code> <p>Each chunk of the results as a DataFrame.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def query_chunked(sql, parameters=None, db=None, backend=None, **kws):\n    \"\"\"\n    Execute a SQL query and yield results in chunks.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): The parameters for the SQL query.\n        db (str, optional): The database instance to use.\n        backend (str, optional): The backend to use.\n        **kws: Additional keyword arguments.\n\n    Yields:\n        DataFrame: Each chunk of the results as a DataFrame.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        for df in txn.query_chunked(sql, parameters, backend, **kws):\n            yield df\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.query_first","title":"<code>query_first(sql, parameters=None, db=None, backend=None, **kws)</code>","text":"<p>Execute a SQL query and return the first result.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>The parameters for the SQL query.</p> <code>None</code> <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>backend</code> <code>str</code> <p>The backend to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>object</code> <p>The first result of the query.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def query_first(sql, parameters=None, db=None, backend=None, **kws):\n    \"\"\"\n    Execute a SQL query and return the first result.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): The parameters for the SQL query.\n        db (str, optional): The database instance to use.\n        backend (str, optional): The backend to use.\n\n    Returns:\n        object: The first result of the query.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.query_first(sql, parameters, backend, **kws)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.query_first_value","title":"<code>query_first_value(sql, parameters=None, db=None, backend='tuple', **kws)</code>","text":"<p>Execute a SQL query and return the first value from the result.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>The parameters for the SQL query.</p> <code>None</code> <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>backend</code> <code>str</code> <p>The backend to use. Defaults to \"tuple\".</p> <code>'tuple'</code> <p>Returns:</p> Name Type Description <code>object</code> <p>The first value from the query result.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def query_first_value(sql, parameters=None, db=None, backend=\"tuple\", **kws):\n    \"\"\"\n    Execute a SQL query and return the first value from the result.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): The parameters for the SQL query.\n        db (str, optional): The database instance to use.\n        backend (str, optional): The backend to use. Defaults to \"tuple\".\n\n    Returns:\n        object: The first value from the query result.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.query_first_value(sql, parameters, backend, **kws)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.query_group","title":"<code>query_group(sql, parameters=None, db=None, by=None, backend=None, **kws)</code>","text":"<p>Execute a SQL query and yield results grouped by specified criteria.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>The parameters for the SQL query.</p> <code>None</code> <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>by</code> <code>str</code> <p>The column or columns to group by.</p> <code>None</code> <code>backend</code> <code>str</code> <p>The backend to use.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Yields:</p> Name Type Description <code>DataFrame</code> <p>Each group of results as a DataFrame.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def query_group(sql, parameters=None, db=None, by=None, backend=None, **kws):\n    \"\"\"\n    Execute a SQL query and yield results grouped by specified criteria.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): The parameters for the SQL query.\n        db (str, optional): The database instance to use.\n        by (str, optional): The column or columns to group by.\n        backend (str, optional): The backend to use.\n        **kws: Additional keyword arguments.\n\n    Yields:\n        DataFrame: Each group of results as a DataFrame.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        for df in txn.query_group(sql, parameters, by, backend, **kws):\n            yield df\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.read_table","title":"<code>read_table(table_name, db=None, backend=None, **kws)</code>","text":"<p>Read the contents of a table and return it as a data frame.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to read.</p> required <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <code>backend</code> <code>str</code> <p>The backend to use.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>The contents of the table as a DataFrame.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def read_table(table_name, db=None, backend=None, **kws):\n    \"\"\"\n    Read the contents of a table and return it as a data frame.\n\n    Args:\n        table_name (str): The name of the table to read.\n        db (str, optional): The database instance to use.\n        backend (str, optional): The backend to use.\n        **kws: Additional keyword arguments.\n\n    Returns:\n        DataFrame: The contents of the table as a DataFrame.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.read_table(table_name, backend, **kws)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.table_exists_p","title":"<code>table_exists_p(table_name, db=None)</code>","text":"<p>Check if a table exists in the specified database.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to check.</p> required <code>db</code> <code>str</code> <p>The database instance to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the table exists, False otherwise.</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def table_exists_p(table_name, db=None):\n    \"\"\"\n    Check if a table exists in the specified database.\n\n    Args:\n        table_name (str): The name of the table to check.\n        db (str, optional): The database instance to use.\n\n    Returns:\n        bool: True if the table exists, False otherwise.\n    \"\"\"\n    with _begin_or_pass_through(db) as txn:\n        return txn.table_exists_p(table_name)\n</code></pre>"},{"location":"reference/plpipes/database/#plpipes.database.update_table","title":"<code>update_table(from_table_name, to_table_name=None, from_db=None, to_db=None, db=None, key=None, key_dir='&gt;=', **kws)</code>","text":"<p>Update a table in the destination database from the source table.</p> <p>Parameters:</p> Name Type Description Default <code>from_table_name</code> <code>str</code> <p>The name of the source table to update from.</p> required <code>to_table_name</code> <code>str</code> <p>The name of the destination table to update. Defaults to the source table name.</p> <code>None</code> <code>from_db</code> <code>str</code> <p>The source database instance.</p> <code>None</code> <code>to_db</code> <code>str</code> <p>The destination database instance.</p> <code>None</code> <code>db</code> <code>str</code> <p>The current database instance.</p> <code>None</code> <code>key</code> <code>str</code> <p>The key column used to identify new rows.</p> <code>None</code> <code>key_dir</code> <code>str</code> <p>The direction for the key comparison. Defaults to \"&gt;=\".</p> <code>'&gt;='</code> <code>**kws</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/database/__init__.py</code> <pre><code>def update_table(from_table_name, to_table_name=None,\n                 from_db=None, to_db=None, db=None,\n                 key=None, key_dir=\"&gt;=\", **kws):\n    \"\"\"\n    Update a table in the destination database from the source table.\n\n    Args:\n        from_table_name (str): The name of the source table to update from.\n        to_table_name (str, optional): The name of the destination table to update. Defaults to the source table name.\n        from_db (str, optional): The source database instance.\n        to_db (str, optional): The destination database instance.\n        db (str, optional): The current database instance.\n        key (str): The key column used to identify new rows.\n        key_dir (str, optional): The direction for the key comparison. Defaults to \"&gt;=\".\n        **kws: Additional keyword arguments.\n\n    Returns:\n        None\n    \"\"\"\n    if to_table_name is None:\n        to_table_name = from_table_name\n\n    if from_db is None:\n        from_db = db\n    if to_db is None:\n        to_db = db\n\n    try:\n        ascending, strict = _key_dir_unpacked[key_dir]\n    except KeyError:\n        raise ValueError(f\"Invalid key_dir value {key_dir}\")\n\n    with _begin_or_pass_through(from_db) as from_txn:\n        with _begin_or_pass_through(to_db) as to_txn:\n            logging.debug(f\"Updating table {from_table_name} from db {from_txn.db_name()} as {to_table_name} in db {to_txn.db_name()}\")\n\n            if to_txn.driver()._engine.dialect.has_table(to_txn._conn, to_table_name):\n                count = to_txn.query_first_value(f\"select count(*) from (select {key} from {to_table_name} limit 1) as t\")\n                if count &gt; 0:\n                    top_func = \"max\" if ascending else \"min\"\n                    # FIXME: escape key identifier properly!\n                    top = to_txn.query_first_value(f\"select {top_func}({key}) from {to_table_name}\")\n                    if not strict:\n                        # we don't know whether we already have all the rows with key=top, so we have to also update those!\n                        to_txn.execute(f\"delete from {to_table_name} where {key} = :top\", parameters={'top': top})\n                    for df in from_txn.query_chunked(f\"select * from {from_table_name} where {key} {key_dir} :top\",\n                                                     parameters={'top': top}):\n                        to_txn.create_table(to_table_name, df, if_exists=\"append\")\n                    return\n            # No table, or table is empty\n\n            for df in from_txn.read_table_chunked(from_table_name):\n                to_txn.create_table(to_table_name, df, if_exists=\"append\")\n</code></pre>"},{"location":"reference/plpipes/exceptions/","title":"plpipes.exceptions","text":"<p>plpipes.exceptions</p> <p>This module defines custom exception classes for handling various error scenarios in the plpipes package. These exceptions extend the built-in Exception class and provide better context for error handling and debugging.</p>"},{"location":"reference/plpipes/exceptions/#plpipes.exceptions.AuthenticationError","title":"<code>AuthenticationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised for authentication-related errors.</p> Source code in <code>src/plpipes/exceptions.py</code> <pre><code>class AuthenticationError(Exception):\n    \"\"\"\n    Exception raised for authentication-related errors.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/plpipes/exceptions/#plpipes.exceptions.CloudAccessError","title":"<code>CloudAccessError</code>","text":"<p>               Bases: <code>CloudError</code></p> <p>Exception raised for access-related errors when interacting with cloud services.</p> Source code in <code>src/plpipes/exceptions.py</code> <pre><code>class CloudAccessError(CloudError):\n    \"\"\"\n    Exception raised for access-related errors when interacting with cloud services.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/plpipes/exceptions/#plpipes.exceptions.CloudError","title":"<code>CloudError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for all cloud-related errors.</p> Source code in <code>src/plpipes/exceptions.py</code> <pre><code>class CloudError(Exception):\n    \"\"\"\n    Base exception class for all cloud-related errors.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/plpipes/exceptions/#plpipes.exceptions.CloudFSError","title":"<code>CloudFSError</code>","text":"<p>               Bases: <code>CloudError</code></p> <p>Exception raised for file system errors related to cloud operations.</p> Source code in <code>src/plpipes/exceptions.py</code> <pre><code>class CloudFSError(CloudError):\n    \"\"\"\n    Exception raised for file system errors related to cloud operations.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/plpipes/filesystem/","title":"plpipes.filesystem","text":""},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.assign_section","title":"<code>assign_section(target_section, relpath=None, section=None, **kwargs)</code>","text":"<p>Assign a target section in the configuration and return a constructed path.</p> <p>Parameters:</p> Name Type Description Default <code>target_section</code> <code>str</code> <p>The section to assign.</p> required <code>relpath</code> <code>str or None</code> <p>Relative path to use if section does not exist.</p> <code>None</code> <code>section</code> <code>str or None</code> <p>Alternative section to use.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for the path function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Path</code> <p>A Path object for the assigned section.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def assign_section(target_section, relpath=None, section=None, **kwargs):\n    \"\"\"\n    Assign a target section in the configuration and return a constructed path.\n\n    Args:\n        target_section (str): The section to assign.\n        relpath (str or None): Relative path to use if section does not exist.\n        section (str or None): Alternative section to use.\n        **kwargs: Additional keyword arguments for the path function.\n\n    Returns:\n        Path: A Path object for the assigned section.\n    \"\"\"\n    if target_section not in cfg.cd(\"fs\"):\n        if relpath is None:\n            relpath = target_section\n        cfg[\"fs.\" + target_section] = str(_path(relpath, section))\n    return path(section=target_section, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.openfile","title":"<code>openfile(relpath, mode='r', section=None)</code>","text":"<p>Open a file and return the file object.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path to the file.</p> required <code>mode</code> <code>str</code> <p>Mode in which to open the file (default is 'r').</p> <code>'r'</code> <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <p>Returns:</p> Type Description <p>file object: The opened file object.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def openfile(relpath, mode=\"r\", section=None):\n    \"\"\"\n    Open a file and return the file object.\n\n    Args:\n        relpath (str): Relative path to the file.\n        mode (str): Mode in which to open the file (default is 'r').\n        section (str or None): Configuration section to use.\n\n    Returns:\n        file object: The opened file object.\n    \"\"\"\n    return open(path(relpath, section), mode)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.path","title":"<code>path(*args, mkparentdir=False, mkdir=False, **kwargs)</code>","text":"<p>Generate a Path object based on the provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>Positional arguments for the _path function.</p> <code>()</code> <code>mkparentdir</code> <code>bool</code> <p>If True, create the parent directory of the path.</p> <code>False</code> <code>mkdir</code> <code>bool</code> <p>If True, create the path directory.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for the _path function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Path</code> <p>A Path object representing the constructed path.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def path(*args, mkparentdir=False, mkdir=False, **kwargs):\n    \"\"\"\n    Generate a Path object based on the provided arguments.\n\n    Args:\n        *args: Positional arguments for the _path function.\n        mkparentdir (bool): If True, create the parent directory of the path.\n        mkdir (bool): If True, create the path directory.\n        **kwargs: Additional keyword arguments for the _path function.\n\n    Returns:\n        Path: A Path object representing the constructed path.\n    \"\"\"\n    p = _path(*args, **kwargs)\n    if mkdir:\n        p.mkdir(exist_ok=True, parents=True)\n    elif mkparentdir:\n        p.parent.mkdir(exist_ok=True, parents=True)\n    return p\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.read_csv","title":"<code>read_csv(relpath, section=None, **kwargs)</code>","text":"<p>Read a CSV file and return a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path to the CSV file.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for pandas read_csv.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>DataFrame containing the CSV data.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def read_csv(relpath, section=None, **kwargs):\n    \"\"\"\n    Read a CSV file and return a DataFrame.\n\n    Args:\n        relpath (str): Relative path to the CSV file.\n        section (str or None): Configuration section to use.\n        **kwargs: Additional keyword arguments for pandas read_csv.\n\n    Returns:\n        DataFrame: DataFrame containing the CSV data.\n    \"\"\"\n    import pandas as pd\n    return pd.read_csv(path(relpath, section), **kwargs)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.read_excel","title":"<code>read_excel(relpath, section=None, **kwargs)</code>","text":"<p>Read data from an Excel file and return a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path to the Excel file.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for pandas read_excel.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>DataFrame containing the Excel data.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def read_excel(relpath, section=None, **kwargs):\n    \"\"\"\n    Read data from an Excel file and return a DataFrame.\n\n    Args:\n        relpath (str): Relative path to the Excel file.\n        section (str or None): Configuration section to use.\n        **kwargs: Additional keyword arguments for pandas read_excel.\n\n    Returns:\n        DataFrame: DataFrame containing the Excel data.\n    \"\"\"\n    import pandas as pd\n    return pd.read_excel(path(relpath, section), **kwargs)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.read_json","title":"<code>read_json(relpath, section=None)</code>","text":"<p>Read data from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path to the JSON file.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>any</code> <p>The deserialized data from the JSON file.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def read_json(relpath, section=None):\n    \"\"\"\n    Read data from a JSON file.\n\n    Args:\n        relpath (str): Relative path to the JSON file.\n        section (str or None): Configuration section to use.\n\n    Returns:\n        any: The deserialized data from the JSON file.\n    \"\"\"\n    import json\n    with openfile(relpath, section=section) as f:\n        return json.load(f)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.read_text","title":"<code>read_text(relpath, section=None, encoding='utf-8')</code>","text":"<p>Read text from a file.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path to the text file.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <code>encoding</code> <code>str</code> <p>Encoding to use for reading the file (default is 'utf-8').</p> <code>'utf-8'</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The contents of the file as a string.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def read_text(relpath, section=None, encoding=\"utf-8\"):\n    \"\"\"\n    Read text from a file.\n\n    Args:\n        relpath (str): Relative path to the text file.\n        section (str or None): Configuration section to use.\n        encoding (str): Encoding to use for reading the file (default is 'utf-8').\n\n    Returns:\n        str: The contents of the file as a string.\n    \"\"\"\n    target = path(relpath, section)\n    with open(target, \"r\", encoding=encoding) as f:\n        return f.read()\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.read_yaml","title":"<code>read_yaml(relpath, section=None)</code>","text":"<p>Read data from a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path to the YAML file.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>any</code> <p>The deserialized data from the YAML file.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def read_yaml(relpath, section=None):\n    \"\"\"\n    Read data from a YAML file.\n\n    Args:\n        relpath (str): Relative path to the YAML file.\n        section (str or None): Configuration section to use.\n\n    Returns:\n        any: The deserialized data from the YAML file.\n    \"\"\"\n    import yaml\n    with openfile(relpath, section=section) as f:\n        return yaml.safe_load(f)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.tempdir","title":"<code>tempdir(parent=None)</code>","text":"<p>Create a temporary directory for file operations.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>str or None</code> <p>Parent directory for the temporary directory.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>TemporaryDirectory</code> <p>Temporary directory context manager.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def tempdir(parent=None):\n    \"\"\"\n    Create a temporary directory for file operations.\n\n    Args:\n        parent (str or None): Parent directory for the temporary directory.\n\n    Returns:\n        TemporaryDirectory: Temporary directory context manager.\n    \"\"\"\n    if parent is None:\n        parent = fs.path(\"tmp\")\n    import tempfile\n\n    return tempfile.TemporaryDirectory(dir=parent)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.write_csv","title":"<code>write_csv(relpath, df, section=None, mkdir=True, **kwargs)</code>","text":"<p>Write a DataFrame to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path for the CSV file.</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame to write.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <code>mkdir</code> <code>bool</code> <p>If True, create the directory if it does not exist.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments for pandas to_csv.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def write_csv(relpath, df, section=None, mkdir=True, **kwargs):\n    \"\"\"\n    Write a DataFrame to a CSV file.\n\n    Args:\n        relpath (str): Relative path for the CSV file.\n        df (DataFrame): DataFrame to write.\n        section (str or None): Configuration section to use.\n        mkdir (bool): If True, create the directory if it does not exist.\n        **kwargs: Additional keyword arguments for pandas to_csv.\n\n    Returns:\n        None\n    \"\"\"\n    target = path(relpath, section)\n    if mkdir:\n        target.parent.mkdir(parents=True, exist_ok=True)\n    df.to_csv(target, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.write_excel","title":"<code>write_excel(relpath, df, section=None, mkparentdir=True, autofilter=False, **kwargs)</code>","text":"<p>Write a DataFrame to an Excel file.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path for the Excel file.</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame to write.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <code>mkparentdir</code> <code>bool</code> <p>If True, create the parent directory if it does not exist.</p> <code>True</code> <code>autofilter</code> <code>bool</code> <p>If True, apply autofilter to the written Excel file.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for pandas to_excel.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Path</code> <p>The path of the written Excel file.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def write_excel(relpath, df, section=None, mkparentdir=True, autofilter=False, **kwargs):\n    \"\"\"\n    Write a DataFrame to an Excel file.\n\n    Args:\n        relpath (str): Relative path for the Excel file.\n        df (DataFrame): DataFrame to write.\n        section (str or None): Configuration section to use.\n        mkparentdir (bool): If True, create the parent directory if it does not exist.\n        autofilter (bool): If True, apply autofilter to the written Excel file.\n        **kwargs: Additional keyword arguments for pandas to_excel.\n\n    Returns:\n        Path: The path of the written Excel file.\n    \"\"\"\n    target = path(relpath, section=section, mkparentdir=mkparentdir)\n    df.to_excel(target, index=False, **kwargs)\n\n    if autofilter:\n        import openpyxl\n        wb = openpyxl.load_workbook(target)\n        ws = wb.active\n        ws.auto_filter.ref = ws.dimensions\n        wb.save(target)\n\n    return target\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.write_text","title":"<code>write_text(relpath, text, section=None, mkdir=True)</code>","text":"<p>Write text to a file.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path for the text file.</p> required <code>text</code> <code>str</code> <p>Text to write to the file.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <code>mkdir</code> <code>bool</code> <p>If True, create the directory if it does not exist.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>int</code> <p>Number of characters written to the file.</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def write_text(relpath, text, section=None, mkdir=True):\n    \"\"\"\n    Write text to a file.\n\n    Args:\n        relpath (str): Relative path for the text file.\n        text (str): Text to write to the file.\n        section (str or None): Configuration section to use.\n        mkdir (bool): If True, create the directory if it does not exist.\n\n    Returns:\n        int: Number of characters written to the file.\n    \"\"\"\n    target = path(relpath, section)\n    if mkdir:\n        target.parent.mkdir(parents=True, exist_ok=True)\n    with open(target, \"w\") as f:\n        return f.write(text)\n</code></pre>"},{"location":"reference/plpipes/filesystem/#plpipes.filesystem.write_yaml","title":"<code>write_yaml(relpath, data, section=None, mkdir=True, **kwargs)</code>","text":"<p>Write data to a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>relpath</code> <code>str</code> <p>Relative path for the YAML file.</p> required <code>data</code> <code>any</code> <p>Data to serialize to YAML.</p> required <code>section</code> <code>str or None</code> <p>Configuration section to use.</p> <code>None</code> <code>mkdir</code> <code>bool</code> <p>If True, create the directory if it does not exist.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments for yaml.dump.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/filesystem.py</code> <pre><code>def write_yaml(relpath, data, section=None, mkdir=True, **kwargs):\n    \"\"\"\n    Write data to a YAML file.\n\n    Args:\n        relpath (str): Relative path for the YAML file.\n        data (any): Data to serialize to YAML.\n        section (str or None): Configuration section to use.\n        mkdir (bool): If True, create the directory if it does not exist.\n        **kwargs: Additional keyword arguments for yaml.dump.\n\n    Returns:\n        None\n    \"\"\"\n    import yaml\n    target = path(relpath, section)\n    if mkdir:\n        target.parent.mkdir(parents=True, exist_ok=True)\n    with open(target, \"w\") as f:\n        yaml.dump(data, f, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/init/","title":"plpipes.init","text":""},{"location":"reference/plpipes/init/#plpipes.init.init","title":"<code>init(*configs, config_files=[])</code>","text":"<p>Initializes the PLPipes configuration.</p> <p>This function merges provided configurations, command line arguments, and environment variables to set up the application. It also initializes logging and file system paths.</p> <p>Parameters:</p> Name Type Description Default <code>*configs</code> <p>Additional configuration dictionaries.</p> <code>()</code> <code>config_files</code> <p>List of custom configuration files to be merged.</p> <code>[]</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if initialization is successful.</p> Source code in <code>src/plpipes/init.py</code> <pre><code>def init(*configs, config_files=[]):\n    \"\"\"Initializes the PLPipes configuration.\n\n    This function merges provided configurations, command line arguments, and environment variables\n    to set up the application. It also initializes logging and file system paths.\n\n    Args:\n        *configs: Additional configuration dictionaries.\n        config_files: List of custom configuration files to be merged.\n\n    Returns:\n        bool: True if initialization is successful.\n    \"\"\"\n    from pathlib import Path\n\n    global _initialized\n    if _initialized:\n        logging.warning(\"Reinitialicing PLPipes\")\n\n    # frame 0: command line arguments\n    # frame 1: custom configuration files\n    # frame 2: standard configuration files\n\n    cfg.merge(_config0, frame=2)\n\n    for config in configs:\n        for k, v in config.items():\n            cfg.merge(v, key=k, frame=0)\n\n    prog = Path(sys.argv[0])\n    default_stem = str(prog.stem)\n\n    # update cfg to get the log levels (normal and file)\n    for fn in config_files:\n        cfg.merge_file(fn, frame=1)\n\n    list_configuration_files_not_found = []\n\n    global_cfg_dir = Path.home() / \".config/plpipes\"\n    for suffix in (\"\", \"-secrets\"):\n        for ext in (\"json\", \"yml\", \"yaml\"):\n            path = global_cfg_dir / f\"plpipes{suffix}.{ext}\"\n            if path.exists():\n                cfg.merge_file(path, frame=2)\n            else:\n                list_configuration_files_not_found.append(path)\n\n    for dir_key in (False, True):\n        for stem_key in (False, True):\n            for secrets_part in (\"\", \"-secrets\"):\n                for env_key in (False, True):\n                    for ext in (\"json\", \"yml\", \"yaml\"):\n                        # The following values can be changed as\n                        # config files are read, so they are\n                        # recalculated every time:\n\n                        env         = cfg.get('env', 'dev')\n                        stem        = cfg.get('fs.stem', default_stem)\n                        root_dir    = Path(cfg.get('fs.root'   , prog.parent.parent.absolute()))\n                        config_dir  = Path(cfg.get('fs.config' , root_dir / \"config\"))\n                        default_dir = Path(cfg.get('fs.default', root_dir / \"default\"))\n\n                        env_part  = f\"-{env}\"  if env_key  else \"\"\n                        stem_part = stem       if stem_key else \"common\"\n                        dir       = config_dir if dir_key  else default_dir\n                        path      = dir / f\"{stem_part}{secrets_part}{env_part}.{ext}\"\n                        if path.exists():\n                            cfg.merge_file(path, frame=2)\n                        else:\n                            list_configuration_files_not_found.append(path)\n\n    # set the root log level as NOTSET, which is the deepest level; it's like\n    # this because all the other handlers, even if they have ther own levels,\n    # will not log anything if the root level is higher than their level\n    logging.getLogger().setLevel(\"NOTSET\")\n\n    cfg.squash_frames()\n\n    cfg.setdefault('fs.stem', default_stem)\n\n    # calculate configuration for file system paths and set it\n    root_dir = Path(cfg.setdefault('fs.root', prog.parent.parent.absolute()))\n    for e in ('bin', 'lib', 'config', 'default',\n              'input', 'output', 'work', 'actions',\n              'resources'):\n        cfg.setdefault(\"fs.\" + e, root_dir / e)\n\n    init_run_as_of_date()\n\n    _log_setup()\n\n    logging.debug(f\"List of configuration files not found: {list_configuration_files_not_found}\")\n\n    logging.debug(f\"Configuration: {repr(cfg.to_tree())}\")\n\n    _initialized = True\n\n    return True\n</code></pre>"},{"location":"reference/plpipes/init/#plpipes.init.init_run_as_of_date","title":"<code>init_run_as_of_date()</code>","text":"<p>Initializes the 'as_of_date' configuration entry.</p> <p>It sets the 'run.as_of_date_normalized' entry in the configuration based on the specified or default 'run.as_of_date'.</p> <p>Returns:</p> Type Description <p>None</p> Source code in <code>src/plpipes/init.py</code> <pre><code>def init_run_as_of_date():\n    \"\"\"Initializes the 'as_of_date' configuration entry.\n\n    It sets the 'run.as_of_date_normalized' entry in the configuration\n    based on the specified or default 'run.as_of_date'.\n\n    Returns:\n        None\n    \"\"\"\n    date = cfg.setdefault('run.as_of_date', 'now')\n    as_of_date = friendlydateparser.parse_datetime(date)\n    as_of_date = as_of_date.astimezone(datetime.timezone.utc)\n    cfg['run.as_of_date_normalized'] = as_of_date.strftime(\"%Y%m%dT%H%M%SZ0\")\n</code></pre>"},{"location":"reference/plpipes/jupyter/","title":"plpipes.jupyter","text":"<p>plpipes.jupyter - a Jupyter extension module for initializing and managing the PLPipes framework.</p>"},{"location":"reference/plpipes/jupyter/#plpipes.jupyter.PLPipesMagics","title":"<code>PLPipesMagics</code>","text":"<p>               Bases: <code>Magics</code></p> <p>A class to define Jupyter magic commands for the PLPipes framework.</p> Source code in <code>src/plpipes/jupyter.py</code> <pre><code>@magics_class\nclass PLPipesMagics(Magics):\n    \"\"\"\n    A class to define Jupyter magic commands for the PLPipes framework.\n    \"\"\"\n\n    def __init__(self, shell):\n        \"\"\"\n        Initializes the PLPipesMagics class.\n\n        Parameters:\n            shell: The IPython shell instance.\n        \"\"\"\n        super().__init__(shell)\n        self.initialized = False\n\n    @needs_local_scope\n    @line_magic\n    def plpipes(self, line, local_ns):\n        \"\"\"\n        Magic function to initialize the PLPipes framework based on the given configuration.\n\n        Parameters:\n            line (str): The line of input provided to the magic command.\n            local_ns (dict): The local namespace to inject configurations and database objects.\n        \"\"\"\n        # import sql.connection\n\n        if self.initialized:\n            logging.warn(\"PLPipes framework already initialized. You will have to restart the kernel if you want to load a new configuration\")\n        else:\n            if \"PLPIPES_ROOT_DIR\" in os.environ:\n                root_dir = pathlib.Path(os.environ[\"PLPIPES_ROOT_DIR\"]).resolve(strict=True)\n            else:\n                root_dir = pathlib.Path(os.getcwd()).resolve(strict=True)\n                while not (root_dir/\"config\").is_dir():\n                    old_root_dir = root_dir\n                    root_dir = root_dir.parent\n                    if old_root_dir == root_dir:\n                        raise RuntimeError(f\"PLPipes project root dir not found (cwd: {os.getcwd()}\")\n\n            stem = line.strip()\n            if stem == \"\":\n                stem = \"jupyter\"\n            logging.info(\"Initializing PLPipes framework\")\n            plpipes.init.init({\"fs.stem\": stem, \"fs.root\": str(root_dir)})\n\n            # class MyConnection(sql.connection.Connection):\n            #     @classmethod\n            #     def set(cls, descriptor, *args, **argkw):\n            #         # Introduce @@name shortcut for referring to PLPipes databases\n            #         if isinstance(descriptor, str) and descriptor.startswith(\"@@\"):\n            #             dbname = descriptor[2:]\n            #             descriptor = str(plpipes.database.engine(dbname).url)\n            #         return super().set(descriptor, *args, **argkw)\n            # sql.connection.Connection = MyConnection\n\n            sys.path.append(plpipes.config.cfg[\"fs.lib\"])\n\n            self.initialized = True\n\n        local_ns[\"cfg\"] = plpipes.config.cfg\n        local_ns[\"db\"] = plpipes.database\n        local_ns[\"create_table\"] = plpipes.database.create_table\n        local_ns[\"query\"] = plpipes.database.query\n\n        for dir in (\"root\", \"input\", \"work\", \"output\"):\n            local_ns[f\"{dir}_dir\"] = pathlib.Path(plpipes.config.cfg[f\"fs.{dir}\"])\n</code></pre>"},{"location":"reference/plpipes/jupyter/#plpipes.jupyter.PLPipesMagics.__init__","title":"<code>__init__(shell)</code>","text":"<p>Initializes the PLPipesMagics class.</p> <p>Parameters:</p> Name Type Description Default <code>shell</code> <p>The IPython shell instance.</p> required Source code in <code>src/plpipes/jupyter.py</code> <pre><code>def __init__(self, shell):\n    \"\"\"\n    Initializes the PLPipesMagics class.\n\n    Parameters:\n        shell: The IPython shell instance.\n    \"\"\"\n    super().__init__(shell)\n    self.initialized = False\n</code></pre>"},{"location":"reference/plpipes/jupyter/#plpipes.jupyter.PLPipesMagics.plpipes","title":"<code>plpipes(line, local_ns)</code>","text":"<p>Magic function to initialize the PLPipes framework based on the given configuration.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>The line of input provided to the magic command.</p> required <code>local_ns</code> <code>dict</code> <p>The local namespace to inject configurations and database objects.</p> required Source code in <code>src/plpipes/jupyter.py</code> <pre><code>@needs_local_scope\n@line_magic\ndef plpipes(self, line, local_ns):\n    \"\"\"\n    Magic function to initialize the PLPipes framework based on the given configuration.\n\n    Parameters:\n        line (str): The line of input provided to the magic command.\n        local_ns (dict): The local namespace to inject configurations and database objects.\n    \"\"\"\n    # import sql.connection\n\n    if self.initialized:\n        logging.warn(\"PLPipes framework already initialized. You will have to restart the kernel if you want to load a new configuration\")\n    else:\n        if \"PLPIPES_ROOT_DIR\" in os.environ:\n            root_dir = pathlib.Path(os.environ[\"PLPIPES_ROOT_DIR\"]).resolve(strict=True)\n        else:\n            root_dir = pathlib.Path(os.getcwd()).resolve(strict=True)\n            while not (root_dir/\"config\").is_dir():\n                old_root_dir = root_dir\n                root_dir = root_dir.parent\n                if old_root_dir == root_dir:\n                    raise RuntimeError(f\"PLPipes project root dir not found (cwd: {os.getcwd()}\")\n\n        stem = line.strip()\n        if stem == \"\":\n            stem = \"jupyter\"\n        logging.info(\"Initializing PLPipes framework\")\n        plpipes.init.init({\"fs.stem\": stem, \"fs.root\": str(root_dir)})\n\n        # class MyConnection(sql.connection.Connection):\n        #     @classmethod\n        #     def set(cls, descriptor, *args, **argkw):\n        #         # Introduce @@name shortcut for referring to PLPipes databases\n        #         if isinstance(descriptor, str) and descriptor.startswith(\"@@\"):\n        #             dbname = descriptor[2:]\n        #             descriptor = str(plpipes.database.engine(dbname).url)\n        #         return super().set(descriptor, *args, **argkw)\n        # sql.connection.Connection = MyConnection\n\n        sys.path.append(plpipes.config.cfg[\"fs.lib\"])\n\n        self.initialized = True\n\n    local_ns[\"cfg\"] = plpipes.config.cfg\n    local_ns[\"db\"] = plpipes.database\n    local_ns[\"create_table\"] = plpipes.database.create_table\n    local_ns[\"query\"] = plpipes.database.query\n\n    for dir in (\"root\", \"input\", \"work\", \"output\"):\n        local_ns[f\"{dir}_dir\"] = pathlib.Path(plpipes.config.cfg[f\"fs.{dir}\"])\n</code></pre>"},{"location":"reference/plpipes/jupyter/#plpipes.jupyter.load_ipython_extension","title":"<code>load_ipython_extension(ipython)</code>","text":"<p>Loads the PLPipes magic extension in the IPython environment.</p> <p>Parameters:</p> Name Type Description Default <code>ipython</code> <p>The IPython instance to load the extension into.</p> required Source code in <code>src/plpipes/jupyter.py</code> <pre><code>def load_ipython_extension(ipython):\n    \"\"\"\n    Loads the PLPipes magic extension in the IPython environment.\n\n    Parameters:\n        ipython: The IPython instance to load the extension into.\n    \"\"\"\n    global former_connection_class\n    ipython.register_magics(PLPipesMagics)\n</code></pre>"},{"location":"reference/plpipes/net/","title":"plpipes.net","text":""},{"location":"reference/plpipes/plugin/","title":"plpipes.plugin","text":""},{"location":"reference/plpipes/plugin/#plpipes.plugin.Plugin","title":"<code>Plugin</code>","text":"<p>A base class for plugins to be registered in the Registry.</p> Source code in <code>src/plpipes/plugin.py</code> <pre><code>class Plugin():\n    \"\"\"\n    A base class for plugins to be registered in the Registry.\n    \"\"\"\n\n    @classmethod\n    def _init_plugin(klass, key):\n        \"\"\"\n        Initializes the plugin with its key.\n\n        Args:\n            klass: The class being initialized as a plugin.\n            key: The key associated with this plugin.\n        \"\"\"\n        klass._plugin_name = key\n</code></pre>"},{"location":"reference/plpipes/plugin/#plpipes.plugin.Registry","title":"<code>Registry</code>","text":"<p>A class to manage a registry of plugins.</p> <p>Attributes:</p> Name Type Description <code>_name</code> <p>The name of the registry.</p> <code>_path</code> <p>The import path for the plugins.</p> <code>_registry</code> <p>A dictionary holding registered plugins.</p> Source code in <code>src/plpipes/plugin.py</code> <pre><code>class Registry():\n    \"\"\"\n    A class to manage a registry of plugins.\n\n    Attributes:\n        _name: The name of the registry.\n        _path: The import path for the plugins.\n        _registry: A dictionary holding registered plugins.\n    \"\"\"\n\n    def __init__(self, name, path):\n        \"\"\"\n        Initializes the Registry with a name and path.\n\n        Args:\n            name: The name of the registry.\n            path: The import path where plugins are located.\n        \"\"\"\n        self._name = name\n        self._path = path\n        self._registry = {}\n\n    def _add(self, obj):\n        \"\"\"\n        Adds an object to the registry using the current key.\n\n        Args:\n            obj: The object to be added to the registry.\n        \"\"\"\n        key = _current_key.get()\n        self._registry[key] = obj\n\n    def lookup(self, key, subkeys=None):\n        \"\"\"\n        Looks up a registered object by its key and optional subkeys.\n\n        Args:\n            key: The main key for the lookup.\n            subkeys: Optional list of subkeys to further refine the lookup.\n\n        Returns:\n            The object associated with the given key and subkeys.\n\n        Raises:\n            ModuleNotFoundError: If the module corresponding to the key cannot be found.\n        \"\"\"\n        if subkeys:\n            long_key = \"__\".join([key, subkeys[0]])\n        else:\n            long_key = key\n        if long_key not in self._registry:\n            try:\n                with set_context_var(_current_registry, self), \\\n                     set_context_var(_current_key, long_key):\n                    module = self._path + \".\" + long_key\n                    logging.debug(f\"loading class {module} for key {long_key} in registry {self._name}\")\n                    __import__(module)\n            except ModuleNotFoundError:\n                if subkeys:\n                    self._registry[long_key] = self.lookup(key, subkeys[1:])\n                else:\n                    raise\n        return self._registry[long_key]\n</code></pre>"},{"location":"reference/plpipes/plugin/#plpipes.plugin.Registry.__init__","title":"<code>__init__(name, path)</code>","text":"<p>Initializes the Registry with a name and path.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>The name of the registry.</p> required <code>path</code> <p>The import path where plugins are located.</p> required Source code in <code>src/plpipes/plugin.py</code> <pre><code>def __init__(self, name, path):\n    \"\"\"\n    Initializes the Registry with a name and path.\n\n    Args:\n        name: The name of the registry.\n        path: The import path where plugins are located.\n    \"\"\"\n    self._name = name\n    self._path = path\n    self._registry = {}\n</code></pre>"},{"location":"reference/plpipes/plugin/#plpipes.plugin.Registry.lookup","title":"<code>lookup(key, subkeys=None)</code>","text":"<p>Looks up a registered object by its key and optional subkeys.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>The main key for the lookup.</p> required <code>subkeys</code> <p>Optional list of subkeys to further refine the lookup.</p> <code>None</code> <p>Returns:</p> Type Description <p>The object associated with the given key and subkeys.</p> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If the module corresponding to the key cannot be found.</p> Source code in <code>src/plpipes/plugin.py</code> <pre><code>def lookup(self, key, subkeys=None):\n    \"\"\"\n    Looks up a registered object by its key and optional subkeys.\n\n    Args:\n        key: The main key for the lookup.\n        subkeys: Optional list of subkeys to further refine the lookup.\n\n    Returns:\n        The object associated with the given key and subkeys.\n\n    Raises:\n        ModuleNotFoundError: If the module corresponding to the key cannot be found.\n    \"\"\"\n    if subkeys:\n        long_key = \"__\".join([key, subkeys[0]])\n    else:\n        long_key = key\n    if long_key not in self._registry:\n        try:\n            with set_context_var(_current_registry, self), \\\n                 set_context_var(_current_key, long_key):\n                module = self._path + \".\" + long_key\n                logging.debug(f\"loading class {module} for key {long_key} in registry {self._name}\")\n                __import__(module)\n        except ModuleNotFoundError:\n            if subkeys:\n                self._registry[long_key] = self.lookup(key, subkeys[1:])\n            else:\n                raise\n    return self._registry[long_key]\n</code></pre>"},{"location":"reference/plpipes/plugin/#plpipes.plugin.plugin","title":"<code>plugin(klass)</code>","text":"<p>A decorator that initializes a plugin and adds it to the registry.</p> <p>Parameters:</p> Name Type Description Default <code>klass</code> <p>The class to be registered as a plugin.</p> required <p>Returns:</p> Type Description <p>The decorated class.</p> Source code in <code>src/plpipes/plugin.py</code> <pre><code>def plugin(klass):\n    \"\"\"\n    A decorator that initializes a plugin and adds it to the registry.\n\n    Args:\n        klass: The class to be registered as a plugin.\n\n    Returns:\n        The decorated class.\n    \"\"\"\n    klass._init_plugin(_current_key.get())\n    _current_registry.get()._add(klass)\n    return klass\n</code></pre>"},{"location":"reference/plpipes/runner/","title":"plpipes.runner","text":"<p>Module: plpipes.runner</p> <p>The purpose of the runner is to offer a unified entry point for the project actions and pipelines. It extracts information from a set of environment variables and parses command line arguments in a standard way.</p> <p>For more information, refer to Runner.</p>"},{"location":"reference/plpipes/runner/#plpipes.runner.arg_parser","title":"<code>arg_parser(**kwargs)</code>","text":"<p>Initializes the argument parser for the runner.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>Additional keyword arguments for customizing the parser.</p> <code>{}</code> <p>Returns:</p> Type Description <p>An instance of argparse.ArgumentParser configured for the runner.</p> Source code in <code>src/plpipes/runner.py</code> <pre><code>def arg_parser(**kwargs):\n    \"\"\"\n    Initializes the argument parser for the runner.\n\n    Parameters:\n        kwargs: Additional keyword arguments for customizing the parser.\n\n    Returns:\n        An instance of argparse.ArgumentParser configured for the runner.\n    \"\"\"\n    parser = argparse.ArgumentParser(**{**_default_arg_parser_args, **kwargs})\n    parser.add_argument('-d', '--debug',\n                        help=\"Turns on debugging\",\n                        action='store_true')\n    parser.add_argument('-c', '--config',\n                        action=\"append\",\n                        metavar=\"CFG_FN\",\n                        help=\"Additional configuration file\",\n                        default=[])\n    parser.add_argument('-s', '--set',\n                        action=_PairAction,\n                        metavar=\"CFG_KEY=VAL\",\n                        help=\"Set configuration entry\",\n                        default=[])\n    parser.add_argument('-S', '--set-json',\n                        action=_PairAction,\n                        metavar=\"CFG_KEY=JSON_VAL\",\n                        unpack=\"json\",\n                        dest=\"set\",\n                        help=\"Set configuration entry (value is parsed as JSON)\")\n    parser.add_argument('-e', '--env',\n                        metavar=\"ENVIRONMENT\",\n                        help=\"Select environment (dev, pre, pro, etc.)\")\n    return parser\n</code></pre>"},{"location":"reference/plpipes/runner/#plpipes.runner.main","title":"<code>main(args=None)</code>","text":"<p>Main entry point for the runner. Parses arguments and executes specified actions.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <p>The command line arguments to parse (defaults to None).</p> <code>None</code> Source code in <code>src/plpipes/runner.py</code> <pre><code>def main(args=None):\n    \"\"\"\n    Main entry point for the runner. Parses arguments and executes specified actions.\n\n    Parameters:\n        args: The command line arguments to parse (defaults to None).\n    \"\"\"\n    parser = arg_parser()\n    parser.add_argument('actions', nargs=\"*\",\n                        metavar=\"ACTION\", default=[\"default\"])\n    opts = parse_args_and_init(parser, args)\n\n    for action in opts.actions:\n        logging.info(f\"Executing action {action}\")\n        plpipes.action.run(action)\n</code></pre>"},{"location":"reference/plpipes/runner/#plpipes.runner.parse_args_and_init","title":"<code>parse_args_and_init(arg_parser, args=None)</code>","text":"<p>Parses command line arguments and initializes the PLPipes framework.</p> <p>Parameters:</p> Name Type Description Default <code>arg_parser</code> <p>The argument parser instance to use for parsing.</p> required <code>args</code> <p>The command line arguments to parse (defaults to sys.argv).</p> <code>None</code> <p>Returns:</p> Type Description <p>The parsed options as an object with attributes corresponding to the arguments.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the program name is missing from the argument list.</p> Source code in <code>src/plpipes/runner.py</code> <pre><code>def parse_args_and_init(arg_parser, args=None):\n    \"\"\"\n    Parses command line arguments and initializes the PLPipes framework.\n\n    Parameters:\n        arg_parser: The argument parser instance to use for parsing.\n        args: The command line arguments to parse (defaults to sys.argv).\n\n    Returns:\n        The parsed options as an object with attributes corresponding to the arguments.\n\n    Raises:\n        Exception: If the program name is missing from the argument list.\n    \"\"\"\n    if args is None:\n        args = sys.argv\n\n    if len(args) &lt; 1:\n        raise Exception(\"Unable to infer config stem. Program name missing from argument list\")\n\n    prog_path = pathlib.Path(args[0])\n    if \"PLPIPES_ROOT_DIR\" in os.environ:\n        root_dir = pathlib.Path(os.environ[\"PLPIPES_ROOT_DIR\"]).resolve(strict=True)\n    else:\n        root_dir = prog_path.parent.parent\n    root_dir = root_dir.absolute()\n\n    opts = arg_parser.parse_args(args[1:])\n\n    config_extra = [{'fs': {'stem': str(prog_path.stem),\n                            'root': str(root_dir),\n                            'project': str(root_dir.stem)}}]\n\n    config_extra += opts.set\n\n    if opts.env is not None:\n        config_extra[\"env\"] = opts.env\n    if opts.debug:\n        config_extra.append({\"logging.level\": \"debug\"})\n        config_extra.append({\"logging.level_file\": \"debug\"})\n\n    plpipes.init.init(*config_extra, config_files=opts.config)\n\n    sys.path.append(plpipes.config.cfg[\"fs.lib\"])\n\n    os.environ.setdefault(\"PLPIPES_ROOT_DIR\", plpipes.config.cfg[\"fs.root\"])\n\n    return opts\n</code></pre>"},{"location":"reference/plpipes/runner/#plpipes.runner.simple_init","title":"<code>simple_init(args=None)</code>","text":"<p>A simplified initialization function that uses a default argument parser.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <p>The command line arguments to parse (defaults to None).</p> <code>None</code> <p>Returns:</p> Type Description <p>The parsed options as an object with attributes corresponding to the arguments.</p> Source code in <code>src/plpipes/runner.py</code> <pre><code>def simple_init(args=None):\n    \"\"\"\n    A simplified initialization function that uses a default argument parser.\n\n    Parameters:\n        args: The command line arguments to parse (defaults to None).\n\n    Returns:\n        The parsed options as an object with attributes corresponding to the arguments.\n    \"\"\"\n    return parse_args_and_init(arg_parser(), args)\n</code></pre>"},{"location":"reference/plpipes/spark/","title":"plpipes.spark","text":""},{"location":"reference/plpipes/spark/#plpipes.spark.__dir_to_config","title":"<code>__dir_to_config(*args, url=False, **kwargs)</code>","text":"<p>Convert directory path to a string representation.</p> <p>This function constructs a file path from given arguments and options, resolving the path and converting it to a URL if specified.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>Arguments to build the file path.</p> <code>()</code> <code>url</code> <code>bool</code> <p>If True, returns the path as a URL. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for path construction.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The constructed file path or URL.</p> Source code in <code>src/plpipes/spark/__init__.py</code> <pre><code>def __dir_to_config(*args, url=False, **kwargs):\n    \"\"\"Convert directory path to a string representation.\n\n    This function constructs a file path from given arguments and\n    options, resolving the path and converting it to a URL if specified.\n\n    Args:\n        *args: Arguments to build the file path.\n        url (bool): If True, returns the path as a URL. Defaults to False.\n        **kwargs: Additional keyword arguments for path construction.\n\n    Returns:\n        str: The constructed file path or URL.\n    \"\"\"\n    s = str(fs.path(*args, **kwargs).resolve()).replace(\"\\\\\", \"/\")\n    if url:\n        return f'file://{s}'\n    return s\n</code></pre>"},{"location":"reference/plpipes/spark/#plpipes.spark.spark_session","title":"<code>spark_session()</code>","text":"<p>Retrieve or create a Spark session.</p> <p>This function checks if a Spark session already exists and returns it. If not, it initializes a new Spark session based on the configuration specified in the 'spark' section of the configuration object.</p> <p>Returns:</p> Type Description <p>Spark session instance.</p> Source code in <code>src/plpipes/spark/__init__.py</code> <pre><code>def spark_session():\n    \"\"\"Retrieve or create a Spark session.\n\n    This function checks if a Spark session already exists and returns it.\n    If not, it initializes a new Spark session based on the configuration\n    specified in the 'spark' section of the configuration object.\n\n    Returns:\n        Spark session instance.\n    \"\"\"\n    global _spark_session\n    if _spark_session is None:\n        _spark_session = _init_spark_session()\n    return _spark_session\n</code></pre>"},{"location":"reference/plpipes/tool/","title":"plpipes.tool","text":"<p>This package provides a collection of tools that can be utilized via the command line.</p> <p>You can run them using the following command:</p> <pre><code>python -m plpipes.tool.foo [arguments]\n</code></pre>"},{"location":"reference/plpipes/util/","title":"plpipes.util","text":"<p>Miscellanea package including several submodules for different functionalities.</p>"},{"location":"reference/plpipes/action/base/","title":"plpipes.action.base","text":""},{"location":"reference/plpipes/action/base/#plpipes.action.base.Action","title":"<code>Action</code>","text":"<p>Represents an action to be performed within the plpipes framework.</p> <p>Attributes:</p> Name Type Description <code>_name</code> <code>str</code> <p>The name of the action.</p> <code>_cfg</code> <code>dict</code> <p>Configuration parameters for the action.</p> Source code in <code>src/plpipes/action/base.py</code> <pre><code>class Action:\n    \"\"\"\n    Represents an action to be performed within the plpipes framework.\n\n    Attributes:\n        _name (str): The name of the action.\n        _cfg (dict): Configuration parameters for the action.\n    \"\"\"\n\n    def __init__(self, name, action_cfg):\n        \"\"\"\n        Initializes the Action instance.\n\n        Args:\n            name (str): The name of the action.\n            action_cfg (dict): Configuration parameters for the action.\n        \"\"\"\n        self._name = name\n        self._cfg = action_cfg\n\n    def name(self):\n        \"\"\"\n        Returns the name of the action.\n\n        Returns:\n            str: The name of the action.\n        \"\"\"\n        return self._name\n\n    def short_name(self):\n        \"\"\"\n        Returns the short name of the action, derived from the full name.\n\n        Returns:\n            str: The short name of the action.\n        \"\"\"\n        return re.split(r'[./\\\\]', self._name)[-1]\n\n    def _do_it(self, indent):\n        \"\"\"\n        Executes the action.\n\n        Args:\n            indent (int): The indentation level for logging.\n        \"\"\"\n        self.do_it()\n\n    def do_it(self):\n        \"\"\"\n        The main logic of the action must be implemented in subclasses.\n        This should contain the code that performs the action.\n        \"\"\"\n        ...\n\n    def run(self, indent=0):\n        \"\"\"\n        Executes the action and logs its execution time.\n\n        Args:\n            indent (int): The indentation level for logging.\n        \"\"\"\n        name = self.name()\n        logging.info(f\"{' '*indent}Action {name} started\")\n        start = time.time()\n        self._do_it(indent=indent)\n        lapse = int(10 * (time.time() - start) + 0.5) / 10.0\n        logging.info(f\"{' '*indent}Action {name} done ({lapse}s)\")\n\n    def __str__(self):\n        \"\"\"\n        Returns a string representation of the Action instance.\n\n        Returns:\n            str: A string representation of the Action.\n        \"\"\"\n        return f\"&lt;Action {self._name}&gt;\"\n</code></pre>"},{"location":"reference/plpipes/action/base/#plpipes.action.base.Action.__init__","title":"<code>__init__(name, action_cfg)</code>","text":"<p>Initializes the Action instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the action.</p> required <code>action_cfg</code> <code>dict</code> <p>Configuration parameters for the action.</p> required Source code in <code>src/plpipes/action/base.py</code> <pre><code>def __init__(self, name, action_cfg):\n    \"\"\"\n    Initializes the Action instance.\n\n    Args:\n        name (str): The name of the action.\n        action_cfg (dict): Configuration parameters for the action.\n    \"\"\"\n    self._name = name\n    self._cfg = action_cfg\n</code></pre>"},{"location":"reference/plpipes/action/base/#plpipes.action.base.Action.__str__","title":"<code>__str__()</code>","text":"<p>Returns a string representation of the Action instance.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>A string representation of the Action.</p> Source code in <code>src/plpipes/action/base.py</code> <pre><code>def __str__(self):\n    \"\"\"\n    Returns a string representation of the Action instance.\n\n    Returns:\n        str: A string representation of the Action.\n    \"\"\"\n    return f\"&lt;Action {self._name}&gt;\"\n</code></pre>"},{"location":"reference/plpipes/action/base/#plpipes.action.base.Action.do_it","title":"<code>do_it()</code>","text":"<p>The main logic of the action must be implemented in subclasses. This should contain the code that performs the action.</p> Source code in <code>src/plpipes/action/base.py</code> <pre><code>def do_it(self):\n    \"\"\"\n    The main logic of the action must be implemented in subclasses.\n    This should contain the code that performs the action.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/plpipes/action/base/#plpipes.action.base.Action.name","title":"<code>name()</code>","text":"<p>Returns the name of the action.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The name of the action.</p> Source code in <code>src/plpipes/action/base.py</code> <pre><code>def name(self):\n    \"\"\"\n    Returns the name of the action.\n\n    Returns:\n        str: The name of the action.\n    \"\"\"\n    return self._name\n</code></pre>"},{"location":"reference/plpipes/action/base/#plpipes.action.base.Action.run","title":"<code>run(indent=0)</code>","text":"<p>Executes the action and logs its execution time.</p> <p>Parameters:</p> Name Type Description Default <code>indent</code> <code>int</code> <p>The indentation level for logging.</p> <code>0</code> Source code in <code>src/plpipes/action/base.py</code> <pre><code>def run(self, indent=0):\n    \"\"\"\n    Executes the action and logs its execution time.\n\n    Args:\n        indent (int): The indentation level for logging.\n    \"\"\"\n    name = self.name()\n    logging.info(f\"{' '*indent}Action {name} started\")\n    start = time.time()\n    self._do_it(indent=indent)\n    lapse = int(10 * (time.time() - start) + 0.5) / 10.0\n    logging.info(f\"{' '*indent}Action {name} done ({lapse}s)\")\n</code></pre>"},{"location":"reference/plpipes/action/base/#plpipes.action.base.Action.short_name","title":"<code>short_name()</code>","text":"<p>Returns the short name of the action, derived from the full name.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The short name of the action.</p> Source code in <code>src/plpipes/action/base.py</code> <pre><code>def short_name(self):\n    \"\"\"\n    Returns the short name of the action, derived from the full name.\n\n    Returns:\n        str: The short name of the action.\n    \"\"\"\n    return re.split(r'[./\\\\]', self._name)[-1]\n</code></pre>"},{"location":"reference/plpipes/action/driver/","title":"plpipes.action.driver","text":"<p>This package contains various drivers for managing actions.</p>"},{"location":"reference/plpipes/action/registry/","title":"plpipes.action.registry","text":""},{"location":"reference/plpipes/action/registry/#plpipes.action.registry.register_class","title":"<code>register_class(action_type, action_class, *suffixes)</code>","text":"<p>Register a new action class with its associated action type and suffixes.</p> <p>Parameters: action_type (str): The type of action being registered. action_class (type): The class that implements the action. suffixes (str): One or more file suffixes associated with the action type.</p> Source code in <code>src/plpipes/action/registry.py</code> <pre><code>def register_class(action_type, action_class, *suffixes):\n    \"\"\"\n    Register a new action class with its associated action type and suffixes.\n\n    Parameters:\n    action_type (str): The type of action being registered.\n    action_class (type): The class that implements the action.\n    suffixes (str): One or more file suffixes associated with the action type.\n    \"\"\"\n    _class_registry[action_type] = action_class\n\n    for suffix in suffixes:\n        _suffix_registry.append((suffix, action_type))\n\n    _suffix_registry.sort(key=lambda x: len(x[0]), reverse=True)\n</code></pre>"},{"location":"reference/plpipes/action/runner/","title":"plpipes.action.runner","text":""},{"location":"reference/plpipes/action/runner/#plpipes.action.runner.lookup","title":"<code>lookup(name, parent='')</code>","text":"<p>Lookup and retrieve an action by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the action to look up.</p> required <code>parent</code> <code>str</code> <p>An optional parent action name.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>Action</code> <p>The action instance corresponding to the provided name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the action type is not declared or the action file is not found.</p> Source code in <code>src/plpipes/action/runner.py</code> <pre><code>def lookup(name, parent=\"\"):\n    \"\"\"\n    Lookup and retrieve an action by its name.\n\n    Args:\n        name (str): The name of the action to look up.\n        parent (str): An optional parent action name.\n\n    Returns:\n        Action: The action instance corresponding to the provided name.\n\n    Raises:\n        ValueError: If the action type is not declared or the action file is not found.\n    \"\"\"\n    name = resolve_action_name(name, parent)\n    if name not in _action_cache:\n        actions_dir = pathlib.Path(cfg[\"fs.actions\"])\n        files = _find_action_files(actions_dir, name)\n\n        cfg_path = \"actions.\" + \".children.\".join(name.split(\".\"))\n        acfg = cfg.cd(cfg_path)\n\n        for ext in (\"yaml\", \"json\"):\n            if ext in files:\n                acfg.merge_file(files[ext], frame=-1)\n\n        for k, v in files.items():\n            acfg.setdefault(f\"files.{k}\", v)\n\n        action_type = acfg.setdefault(\"type\", _action_type_lookup(files))\n        if action_type is None:\n            raise ValueError(f\"Action {name} has no type declared or action file not found\")\n\n        logging.debug(f\"action_type: {action_type}\")\n        _action_cache[name] = _action_class_lookup(action_type)(name, acfg)\n\n    return _action_cache[name]\n</code></pre>"},{"location":"reference/plpipes/action/runner/#plpipes.action.runner.resolve_action_name","title":"<code>resolve_action_name(name, parent)</code>","text":"<p>Resolve the full action name from a relative action name and its parent.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The action name to resolve.</p> required <code>parent</code> <code>str</code> <p>The parent action name.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The resolved full action name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the name is a relative name but no parent is provided.</p> Source code in <code>src/plpipes/action/runner.py</code> <pre><code>def resolve_action_name(name, parent):\n    \"\"\"\n    Resolve the full action name from a relative action name and its parent.\n\n    Args:\n        name (str): The action name to resolve.\n        parent (str): The parent action name.\n\n    Returns:\n        str: The resolved full action name.\n\n    Raises:\n        ValueError: If the name is a relative name but no parent is provided.\n    \"\"\"\n    if name.startswith(\".\"):\n        if parent:\n            return f\"{parent}{name}\"\n        else:\n            raise ValueError(\"Can't resolve relative action name without a parent\")\n    return name\n</code></pre>"},{"location":"reference/plpipes/action/runner/#plpipes.action.runner.run","title":"<code>run(name)</code>","text":"<p>Execute the action corresponding to the provided name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the action to run.</p> required Source code in <code>src/plpipes/action/runner.py</code> <pre><code>def run(name):\n    \"\"\"\n    Execute the action corresponding to the provided name.\n\n    Args:\n        name (str): The name of the action to run.\n    \"\"\"\n    lookup(name).run()\n</code></pre>"},{"location":"reference/plpipes/action/driver/archive_unpacker/","title":"plpipes.action.driver.archive_unpacker","text":"<p>This module contains the _ArchiveUnpacker class, which is responsible for handling actions with type <code>archive_unpacker</code>  within the plpipes framework.</p> <p>The <code>archive_unpacker</code> action reads the configuration to identify the archive file and its target extraction location.  It utilizes the patoolib library to perform the extraction of the specified archive.</p>"},{"location":"reference/plpipes/action/driver/downloader/","title":"plpipes.action.driver.downloader","text":""},{"location":"reference/plpipes/action/driver/file_downloader/","title":"plpipes.action.driver.file_downloader","text":"<p>This module provides functionality for downloading files from a specified URL. It utilizes the HTTPx library to handle HTTP requests and supports resuming interrupted downloads. The module includes the action class for file downloading and relevant helper functions.</p>"},{"location":"reference/plpipes/action/driver/loop/","title":"plpipes.action.driver.loop","text":""},{"location":"reference/plpipes/action/driver/loop/#plpipes.action.driver.loop.RunAsOfDateIterator","title":"<code>RunAsOfDateIterator</code>","text":"<p>               Bases: <code>_ListIterator</code></p> <p>Iterator for run-as-of-date values based on specified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key for the iterator.</p> required <code>icfg</code> <code>dict</code> <p>Configuration settings for the iterator.</p> required Source code in <code>src/plpipes/action/driver/loop.py</code> <pre><code>class RunAsOfDateIterator(_ListIterator):\n    \"\"\"\n    Iterator for run-as-of-date values based on specified parameters.\n\n    Args:\n        key (str): The key for the iterator.\n        icfg (dict): Configuration settings for the iterator.\n    \"\"\"\n\n    def __init__(self, key, icfg):\n        \"\"\"\n        Initializes the run-as-of-date iterator.\n\n        Args:\n            key (str): The key for the iterator.\n            icfg (dict): Configuration settings for the iterator.\n        \"\"\"\n        values = icfg.get(\"values\")\n        icfg.setdefault(\"target\", \"run.as_of_date\")\n\n        start = icfg.get(\"start\")\n        if start is not None:\n            end = icfg.get(\"end\", \"today\")\n            periodicity = icfg.get(\"periodicity\", \"daily\")\n            values = self._date_range(start, end, periodicity, values)\n        elif values is None:\n            raise ValueError(\"No values or start date provided for RunAsOfDateIterator\")\n\n        super().__init__(key, icfg, list(values))\n\n    def _date_range(self, start, end, periodicity, more_values):\n        \"\"\"\n        Generates a range of dates based on the specified parameters.\n\n        Args:\n            start (str): Start date.\n            end (str): End date.\n            periodicity (str): The frequency of the dates (daily, weekly, etc.).\n            more_values (list): Additional values to include in the range.\n\n        Returns:\n            list: A sorted list of dates within the specified range.\n        \"\"\"\n        from friendlydateparser import parse_date\n        from dateutil.relativedelta import relativedelta\n        start = parse_date(start)\n        end = parse_date(end)\n        if periodicity == \"daily\":\n            step = relativedelta(days=1)\n        elif periodicity == \"weekly\":\n            step = relativedelta(days=7)\n        elif periodicity == \"monthly\":\n            step = relativedelta(months=1)\n        elif periodicity == \"yearly\":\n            step = relativedelta(years=1)\n        else:\n            raise ValueError(f\"Unsupported periodicity {periodicity}\")\n\n        if more_values is None:\n            more_values = []\n        values = set(fdp.parse_date(v) for v in more_values)\n        value = start\n        while value &lt;= end:\n            values.add(value)\n            value += step\n        values = sorted(values)\n        logging.debug(f\"Date range from {start} to {end} with periodicity {periodicity} yields {values}\")\n        return values\n\n    def reset(self):\n        \"\"\"Resets the current date to 'now' and initializes the run date.\"\"\"\n        super().reset()\n        cfg['run.as_of_date'] = 'now'\n        init_run_as_of_date()\n\n    def next(self):\n        \"\"\"\n        Advances the iterator to the next date value.\n\n        Returns:\n            bool: True if there is a next date; False otherwise.\n        \"\"\"\n        if super().next():\n            init_run_as_of_date()\n            return True\n        return False\n</code></pre>"},{"location":"reference/plpipes/action/driver/loop/#plpipes.action.driver.loop.RunAsOfDateIterator.__init__","title":"<code>__init__(key, icfg)</code>","text":"<p>Initializes the run-as-of-date iterator.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key for the iterator.</p> required <code>icfg</code> <code>dict</code> <p>Configuration settings for the iterator.</p> required Source code in <code>src/plpipes/action/driver/loop.py</code> <pre><code>def __init__(self, key, icfg):\n    \"\"\"\n    Initializes the run-as-of-date iterator.\n\n    Args:\n        key (str): The key for the iterator.\n        icfg (dict): Configuration settings for the iterator.\n    \"\"\"\n    values = icfg.get(\"values\")\n    icfg.setdefault(\"target\", \"run.as_of_date\")\n\n    start = icfg.get(\"start\")\n    if start is not None:\n        end = icfg.get(\"end\", \"today\")\n        periodicity = icfg.get(\"periodicity\", \"daily\")\n        values = self._date_range(start, end, periodicity, values)\n    elif values is None:\n        raise ValueError(\"No values or start date provided for RunAsOfDateIterator\")\n\n    super().__init__(key, icfg, list(values))\n</code></pre>"},{"location":"reference/plpipes/action/driver/loop/#plpipes.action.driver.loop.RunAsOfDateIterator.next","title":"<code>next()</code>","text":"<p>Advances the iterator to the next date value.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if there is a next date; False otherwise.</p> Source code in <code>src/plpipes/action/driver/loop.py</code> <pre><code>def next(self):\n    \"\"\"\n    Advances the iterator to the next date value.\n\n    Returns:\n        bool: True if there is a next date; False otherwise.\n    \"\"\"\n    if super().next():\n        init_run_as_of_date()\n        return True\n    return False\n</code></pre>"},{"location":"reference/plpipes/action/driver/loop/#plpipes.action.driver.loop.RunAsOfDateIterator.reset","title":"<code>reset()</code>","text":"<p>Resets the current date to 'now' and initializes the run date.</p> Source code in <code>src/plpipes/action/driver/loop.py</code> <pre><code>def reset(self):\n    \"\"\"Resets the current date to 'now' and initializes the run date.\"\"\"\n    super().reset()\n    cfg['run.as_of_date'] = 'now'\n    init_run_as_of_date()\n</code></pre>"},{"location":"reference/plpipes/action/driver/prql/","title":"plpipes.action.driver.prql","text":""},{"location":"reference/plpipes/action/driver/quarto/","title":"plpipes.action.driver.quarto","text":"<p>This module provides functionality for generating reports from Quarto markdown files within the plpipes framework.</p> <p>It includes a runner class for executing Quarto rendering actions, along with utilities for handling YAML headers in Quarto files, patching Quarto markdown files with necessary configurations, and managing context changes during execution.</p>"},{"location":"reference/plpipes/action/driver/simple/","title":"plpipes.action.driver.simple","text":"<p>This module implements the basic drivers for running Python code and sequences of actions in the plpipes framework.</p> <p>This module contains action drivers for executing Python scripts and for sequencing multiple actions. The action drivers are responsible for managing the execution of specific actions defined in the project.</p>"},{"location":"reference/plpipes/action/driver/sql/","title":"plpipes.action.driver.sql","text":"<p>This module contains drivers for handling SQL-related actions within the plpipes framework.</p> <p>The supported actions include executing raw SQL scripts, creating SQL tables from templates, and creating SQL views from templates. Each action driver is responsible for loading the appropriate SQL configuration, rendering templates, and executing the SQL commands against the specified database.</p>"},{"location":"reference/plpipes/action/driver/downloader/helpers/","title":"plpipes.action.driver.downloader.helpers","text":""},{"location":"reference/plpipes/action/driver/downloader/service/","title":"plpipes.action.driver.downloader.service","text":""},{"location":"reference/plpipes/action/driver/downloader/service/aemet/","title":"plpipes.action.driver.downloader.service.aemet","text":""},{"location":"reference/plpipes/action/driver/downloader/service/ine/","title":"plpipes.action.driver.downloader.service.ine","text":""},{"location":"reference/plpipes/action/driver/sql/jinja2/","title":"plpipes.action.driver.sql.jinja2","text":"<p>This module contains the logic for generating SQL code using the Jinja2 template system. It provides several convenient helpers for easing SQL generation.</p>"},{"location":"reference/plpipes/action/driver/sql/jinja2/#plpipes.action.driver.sql.jinja2.render_template","title":"<code>render_template(src, global_vars)</code>","text":"<p>Render a Jinja2 template with the given source and global variables.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>str</code> <p>The source template string.</p> required <code>global_vars</code> <code>dict</code> <p>A dictionary of global variables to be passed to the template.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The rendered template output.</p> Source code in <code>src/plpipes/action/driver/sql/jinja2.py</code> <pre><code>def render_template(src, global_vars):\n    \"\"\"Render a Jinja2 template with the given source and global variables.\n\n    Args:\n        src (str): The source template string.\n        global_vars (dict): A dictionary of global variables to be passed to the template.\n\n    Returns:\n        str: The rendered template output.\n    \"\"\"\n    env = jinja2.Environment()\n    env.filters['cols'] = _join_columns\n    env.filters['esc'] = _escape\n    env.filters['quote'] = _quote\n    env.filters['debug'] = _debug\n    env.filters['pluralize'] = _pluralize\n    env.filters['singularize'] = _singularize\n    env.globals['cfg_tree'] = _cfg_tree\n    env.globals['cfg_list'] = _cfg_list\n    env.globals['logging'] = logging\n    return env.from_string(src).render(**global_vars)\n</code></pre>"},{"location":"reference/plpipes/cloud/azure/","title":"plpipes.cloud.azure","text":""},{"location":"reference/plpipes/cloud/google/","title":"plpipes.cloud.google","text":""},{"location":"reference/plpipes/cloud/openai/","title":"plpipes.cloud.openai","text":""},{"location":"reference/plpipes/cloud/azure/auth/","title":"plpipes.cloud.azure.auth","text":"<p>Module for Azure authentication management within the plpipes framework.</p> <p>This module provides functionalities to manage Azure credentials using different authentication methods, including interactive browser and Azure CLI methods. Credential objects can be retrieved based on the  configured authentication account.</p>"},{"location":"reference/plpipes/cloud/azure/auth/#plpipes.cloud.azure.auth.credentials","title":"<code>credentials(account_name)</code>","text":"<p>Retrieves the credential object associated with the given account name.</p> <p>Parameters:</p> Name Type Description Default <code>account_name</code> <code>str</code> <p>The name of the authentication account.</p> required <p>Returns:</p> Type Description <p>Credential object for the specified account.</p> Source code in <code>src/plpipes/cloud/azure/auth/__init__.py</code> <pre><code>def credentials(account_name):\n    \"\"\"\n    Retrieves the credential object associated with the given account name.\n\n    Args:\n        account_name (str): The name of the authentication account.\n\n    Returns:\n        Credential object for the specified account.\n    \"\"\"\n    if account_name not in _registry:\n        _registry[account_name] = _init_backend(account_name)\n    return _registry[account_name].credentials()\n</code></pre>"},{"location":"reference/plpipes/cloud/azure/graph/","title":"plpipes.cloud.azure.graph","text":""},{"location":"reference/plpipes/cloud/azure/graph/#plpipes.cloud.azure.graph.fs","title":"<code>fs(account_name)</code>","text":"<p>Get the file system object for the specified account name.</p> <p>Parameters:</p> Name Type Description Default <code>account_name</code> <code>str</code> <p>The name of the account.</p> required <p>Returns:</p> Name Type Description <code>_FS</code> <p>Instance of the file system object for the specified account.</p> Source code in <code>src/plpipes/cloud/azure/graph.py</code> <pre><code>def fs(account_name):\n    \"\"\"Get the file system object for the specified account name.\n\n    Args:\n        account_name (str): The name of the account.\n\n    Returns:\n        _FS: Instance of the file system object for the specified account.\n    \"\"\"\n    if account_name not in _fs_registry:\n        _init_fs(account_name)\n    return _fs_registry[account_name].root()\n</code></pre>"},{"location":"reference/plpipes/cloud/azure/graph/#plpipes.cloud.azure.graph.graph","title":"<code>graph(account_name)</code>","text":"<p>Get the GraphClient object for the specified account name.</p> <p>Parameters:</p> Name Type Description Default <code>account_name</code> <code>str</code> <p>The name of the account.</p> required <p>Returns:</p> Name Type Description <code>GraphClient</code> <p>Instance of GraphClient for the specified account.</p> Source code in <code>src/plpipes/cloud/azure/graph.py</code> <pre><code>def graph(account_name):\n    \"\"\"Get the GraphClient object for the specified account name.\n\n    Args:\n        account_name (str): The name of the account.\n\n    Returns:\n        GraphClient: Instance of GraphClient for the specified account.\n    \"\"\"\n    if account_name not in _graph_registry:\n        _init_graph(account_name)\n    return _graph_registry[account_name]\n</code></pre>"},{"location":"reference/plpipes/cloud/azure/auth/base/","title":"plpipes.cloud.azure.auth.base","text":""},{"location":"reference/plpipes/cloud/azure/auth/plugin/","title":"plpipes.cloud.azure.auth.plugin","text":""},{"location":"reference/plpipes/cloud/azure/auth/plugin/azure_cli/","title":"plpipes.cloud.azure.auth.plugin.azure_cli","text":""},{"location":"reference/plpipes/cloud/azure/auth/plugin/client_secret/","title":"plpipes.cloud.azure.auth.plugin.client_secret","text":""},{"location":"reference/plpipes/cloud/azure/auth/plugin/interactive_browser/","title":"plpipes.cloud.azure.auth.plugin.interactive_browser","text":""},{"location":"reference/plpipes/cloud/azure/auth/plugin/managed_identity/","title":"plpipes.cloud.azure.auth.plugin.managed_identity","text":""},{"location":"reference/plpipes/cloud/google/auth/","title":"plpipes.cloud.google.auth","text":""},{"location":"reference/plpipes/cloud/google/vertexai/","title":"plpipes.cloud.google.vertexai","text":""},{"location":"reference/plpipes/cloud/google/auth/base/","title":"plpipes.cloud.google.auth.base","text":""},{"location":"reference/plpipes/cloud/google/auth/plugin/","title":"plpipes.cloud.google.auth.plugin","text":""},{"location":"reference/plpipes/cloud/google/auth/plugin/oauth2/","title":"plpipes.cloud.google.auth.plugin.oauth2","text":""},{"location":"reference/plpipes/cloud/openai/provider/","title":"plpipes.cloud.openai.provider","text":""},{"location":"reference/plpipes/cloud/openai/provider/plugin/","title":"plpipes.cloud.openai.provider.plugin","text":""},{"location":"reference/plpipes/cloud/openai/provider/plugin/azure/","title":"plpipes.cloud.openai.provider.plugin.azure","text":""},{"location":"reference/plpipes/cloud/openai/provider/plugin/openai/","title":"plpipes.cloud.openai.provider.plugin.openai","text":""},{"location":"reference/plpipes/database/backend/","title":"plpipes.database.backend","text":"<p>Module for defining the database backend interface in the plpipes framework.</p> <p>This module provides the Backend class, which serves as an abstraction layer for different database backends. It allows interaction with various data representations such as pandas, geopandas, Spark DataFrames, polars, and more.</p> <p>Classes:</p> Name Description <code>Backend</code> <p>The base class for database backends providing methods for      executing queries, handling data chunking, grouping results,      and retrieving first results.</p>"},{"location":"reference/plpipes/database/backend/#plpipes.database.backend.Backend","title":"<code>Backend</code>","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for database backends.</p> <p>This class defines the interface for various database backends that can perform queries and manage data representations.</p> <p>Methods:</p> Name Description <code>query</code> <p>Executes a query and returns the result.</p> <code>query_chunked</code> <p>Executes a chunked query and returns results.</p> <code>query_group</code> <p>Executes a grouped query and returns results.</p> <code>query_first</code> <p>Executes a query and returns the first result.</p> <code>query_first_value</code> <p>Executes a query and returns the first value.</p> Source code in <code>src/plpipes/database/backend/__init__.py</code> <pre><code>class Backend(Plugin):\n    \"\"\"\n    Abstract base class for database backends.\n\n    This class defines the interface for various database backends that can\n    perform queries and manage data representations.\n\n    Methods:\n        query(engine, sql, parameters, kws): Executes a query and returns the result.\n        query_chunked(engine, sql, parameter, kws): Executes a chunked query and returns results.\n        query_group(engine, sql, parameters, by, kws): Executes a grouped query and returns results.\n        query_first(engine, sql, parameters, kws): Executes a query and returns the first result.\n        query_first_value(engine, sql, parameters, kws): Executes a query and returns the first value.\n    \"\"\"\n\n    def query(self, engine, sql, parameters, kws):\n        \"\"\"\n        Executes a query against the database.\n\n        Args:\n            engine (object): The database engine to use for executing the query.\n            sql (str): The SQL query to execute.\n            parameters (dict): Optional parameters for the SQL query.\n            kws (dict): Additional keyword arguments for the execution.\n\n        Raises:\n            NotImplementedError: This method must be implemented in subclasses.\n        \"\"\"\n        raise NotImplementedError(\"This function is not yet implemented.\")\n\n    def query_chunked(self, engine, sql, parameters, kws):\n        \"\"\"\n        Executes a chunked query against the database.\n\n        Args:\n            engine (object): The database engine to use for executing the query.\n            sql (str): The SQL query to execute.\n            parameters (dict): Optional parameters for the SQL query.\n            kws (dict): Additional keyword arguments for the execution.\n\n        Raises:\n            NotImplementedError: This method must be implemented in subclasses.\n        \"\"\"\n        raise NotImplementedError(\"This function is not yet implemented.\")\n\n    def query_group(self, engine, sql, parameters, by, kws):\n        \"\"\"\n        Executes a grouped query against the database.\n\n        Args:\n            engine (object): The database engine to use for executing the query.\n            sql (str): The SQL query to execute.\n            parameters (dict): Optional parameters for the SQL query.\n            by (str): The column(s) to group the results by.\n            kws (dict): Additional keyword arguments for the execution.\n\n        Raises:\n            NotImplementedError: This method must be implemented in subclasses.\n        \"\"\"\n        raise NotImplementedError(\"This function is not yet implemented.\")\n\n    def query_first(self, engine, sql, parameters, kws):\n        \"\"\"\n        Executes a query and retrieves the first result.\n\n        Args:\n            engine (object): The database engine to use for executing the query.\n            sql (str): The SQL query to execute.\n            parameters (dict): Optional parameters for the SQL query.\n            kws (dict): Additional keyword arguments for the execution.\n\n        Raises:\n            NotImplementedError: This method must be implemented in subclasses.\n        \"\"\"\n        raise NotImplementedError(\"This function is not yet implemented.\")\n\n    def query_first_value(self, engine, sql, parameters, kws):\n        \"\"\"\n        Executes a query and retrieves the first value from the result.\n\n        Args:\n            engine (object): The database engine to use for executing the query.\n            sql (str): The SQL query to execute.\n            parameters (dict): Optional parameters for the SQL query.\n            kws (dict): Additional keyword arguments for the execution.\n\n        Raises:\n            NotImplementedError: This method must be implemented in subclasses.\n        \"\"\"\n        raise NotImplementedError(\"This function is not yet implemented.\")\n</code></pre>"},{"location":"reference/plpipes/database/backend/#plpipes.database.backend.Backend.query","title":"<code>query(engine, sql, parameters, kws)</code>","text":"<p>Executes a query against the database.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>object</code> <p>The database engine to use for executing the query.</p> required <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>Optional parameters for the SQL query.</p> required <code>kws</code> <code>dict</code> <p>Additional keyword arguments for the execution.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in subclasses.</p> Source code in <code>src/plpipes/database/backend/__init__.py</code> <pre><code>def query(self, engine, sql, parameters, kws):\n    \"\"\"\n    Executes a query against the database.\n\n    Args:\n        engine (object): The database engine to use for executing the query.\n        sql (str): The SQL query to execute.\n        parameters (dict): Optional parameters for the SQL query.\n        kws (dict): Additional keyword arguments for the execution.\n\n    Raises:\n        NotImplementedError: This method must be implemented in subclasses.\n    \"\"\"\n    raise NotImplementedError(\"This function is not yet implemented.\")\n</code></pre>"},{"location":"reference/plpipes/database/backend/#plpipes.database.backend.Backend.query_chunked","title":"<code>query_chunked(engine, sql, parameters, kws)</code>","text":"<p>Executes a chunked query against the database.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>object</code> <p>The database engine to use for executing the query.</p> required <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>Optional parameters for the SQL query.</p> required <code>kws</code> <code>dict</code> <p>Additional keyword arguments for the execution.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in subclasses.</p> Source code in <code>src/plpipes/database/backend/__init__.py</code> <pre><code>def query_chunked(self, engine, sql, parameters, kws):\n    \"\"\"\n    Executes a chunked query against the database.\n\n    Args:\n        engine (object): The database engine to use for executing the query.\n        sql (str): The SQL query to execute.\n        parameters (dict): Optional parameters for the SQL query.\n        kws (dict): Additional keyword arguments for the execution.\n\n    Raises:\n        NotImplementedError: This method must be implemented in subclasses.\n    \"\"\"\n    raise NotImplementedError(\"This function is not yet implemented.\")\n</code></pre>"},{"location":"reference/plpipes/database/backend/#plpipes.database.backend.Backend.query_first","title":"<code>query_first(engine, sql, parameters, kws)</code>","text":"<p>Executes a query and retrieves the first result.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>object</code> <p>The database engine to use for executing the query.</p> required <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>Optional parameters for the SQL query.</p> required <code>kws</code> <code>dict</code> <p>Additional keyword arguments for the execution.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in subclasses.</p> Source code in <code>src/plpipes/database/backend/__init__.py</code> <pre><code>def query_first(self, engine, sql, parameters, kws):\n    \"\"\"\n    Executes a query and retrieves the first result.\n\n    Args:\n        engine (object): The database engine to use for executing the query.\n        sql (str): The SQL query to execute.\n        parameters (dict): Optional parameters for the SQL query.\n        kws (dict): Additional keyword arguments for the execution.\n\n    Raises:\n        NotImplementedError: This method must be implemented in subclasses.\n    \"\"\"\n    raise NotImplementedError(\"This function is not yet implemented.\")\n</code></pre>"},{"location":"reference/plpipes/database/backend/#plpipes.database.backend.Backend.query_first_value","title":"<code>query_first_value(engine, sql, parameters, kws)</code>","text":"<p>Executes a query and retrieves the first value from the result.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>object</code> <p>The database engine to use for executing the query.</p> required <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>Optional parameters for the SQL query.</p> required <code>kws</code> <code>dict</code> <p>Additional keyword arguments for the execution.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in subclasses.</p> Source code in <code>src/plpipes/database/backend/__init__.py</code> <pre><code>def query_first_value(self, engine, sql, parameters, kws):\n    \"\"\"\n    Executes a query and retrieves the first value from the result.\n\n    Args:\n        engine (object): The database engine to use for executing the query.\n        sql (str): The SQL query to execute.\n        parameters (dict): Optional parameters for the SQL query.\n        kws (dict): Additional keyword arguments for the execution.\n\n    Raises:\n        NotImplementedError: This method must be implemented in subclasses.\n    \"\"\"\n    raise NotImplementedError(\"This function is not yet implemented.\")\n</code></pre>"},{"location":"reference/plpipes/database/backend/#plpipes.database.backend.Backend.query_group","title":"<code>query_group(engine, sql, parameters, by, kws)</code>","text":"<p>Executes a grouped query against the database.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>object</code> <p>The database engine to use for executing the query.</p> required <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>Optional parameters for the SQL query.</p> required <code>by</code> <code>str</code> <p>The column(s) to group the results by.</p> required <code>kws</code> <code>dict</code> <p>Additional keyword arguments for the execution.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in subclasses.</p> Source code in <code>src/plpipes/database/backend/__init__.py</code> <pre><code>def query_group(self, engine, sql, parameters, by, kws):\n    \"\"\"\n    Executes a grouped query against the database.\n\n    Args:\n        engine (object): The database engine to use for executing the query.\n        sql (str): The SQL query to execute.\n        parameters (dict): Optional parameters for the SQL query.\n        by (str): The column(s) to group the results by.\n        kws (dict): Additional keyword arguments for the execution.\n\n    Raises:\n        NotImplementedError: This method must be implemented in subclasses.\n    \"\"\"\n    raise NotImplementedError(\"This function is not yet implemented.\")\n</code></pre>"},{"location":"reference/plpipes/database/driver/","title":"plpipes.database.driver","text":"<p>Module for handling database drivers in the plpipes framework.</p> <p>This module defines the Driver class that acts as an abstraction layer for database interactions, allowing for the use of various backends for database operations. It provides an interface for executing SQL commands, managing transactions, and interacting with tables and views within a database.</p> <p>Classes:</p> Name Description <code>Driver</code> <p>The base class for database drivers providing methods for     executing SQL commands, handling transactions, and managing     database backend interactions.</p>"},{"location":"reference/plpipes/database/driver/#plpipes.database.driver.Driver","title":"<code>Driver</code>","text":"<p>               Bases: <code>Plugin</code></p> <p>Driver class for handling database interactions.</p> <p>Attributes:</p> Name Type Description <code>_default_backend_name</code> <code>str</code> <p>The default backend name to use.</p> <code>_backend_subkeys</code> <code>list</code> <p>List of backend subkeys associated with this driver.</p> <p>Methods:</p> Name Description <code>config</code> <p>Returns the configuration for the driver.</p> <code>driver_name</code> <p>Returns the name of the driver.</p> <code>begin</code> <p>Context manager for starting a transaction.</p> <code>_execute</code> <p>Executes an SQL command in the transaction.</p> <code>_execute_script</code> <p>Executes a SQL script in the transaction.</p> <code>_list_tables</code> <p>Lists tables in the database.</p> <code>_read_table</code> <p>Reads a table from the database.</p> <code>_drop_table</code> <p>Drops a table from the database.</p> <code>_create_table</code> <p>Creates a new table.</p> <code>_create_view</code> <p>Creates a new view in the database.</p> <code>_copy_table</code> <p>Copies data between tables.</p> <code>_query_chunked</code> <p>Executes a chunked query.</p> <code>_query_group</code> <p>Executes a grouped query.</p> <code>load_backend</code> <p>Loads a specific backend into the driver.</p> Source code in <code>src/plpipes/database/driver/__init__.py</code> <pre><code>class Driver(plpipes.plugin.Plugin):\n    \"\"\"\n    Driver class for handling database interactions.\n\n    Attributes:\n        _default_backend_name (str): The default backend name to use.\n        _backend_subkeys (list): List of backend subkeys associated with this driver.\n\n    Methods:\n        config(): Returns the configuration for the driver.\n        driver_name(): Returns the name of the driver.\n        begin(): Context manager for starting a transaction.\n        _execute(txn, sql, parameters=None): Executes an SQL command in the transaction.\n        _execute_script(txn, sql): Executes a SQL script in the transaction.\n        _list_tables(txn): Lists tables in the database.\n        _read_table(txn, table_name, backend, kws): Reads a table from the database.\n        _drop_table(txn, table_name, only_if_exists): Drops a table from the database.\n        _create_table(txn, table_name, sql_or_df, parameters, if_exists, kws): Creates a new table.\n        _create_view(txn, view_name, sql, parameters, if_exists, kws): Creates a new view in the database.\n        _copy_table(txn, from_table_name, to_table_name, if_exists, kws): Copies data between tables.\n        _query_chunked(txn, sql, parameters, backend, kws): Executes a chunked query.\n        _query_group(txn, sql, parameters, by, backend, kws): Executes a grouped query.\n        load_backend(name): Loads a specific backend into the driver.\n    \"\"\"\n\n    _default_backend_name = \"pandas\"\n    _backend_subkeys = []\n\n    @classmethod\n    def _init_plugin(klass, key):\n        \"\"\"\n        Initializes the plugin with backend registry and configuration.\n\n        Args:\n            klass: The class reference.\n            key: The key of the plugin instance.\n        \"\"\"\n        super()._init_plugin(key)\n        klass._backend_registry = {}\n        klass._backend_subkeys = [key, *klass._backend_subkeys]\n        klass._create_table = klass._create_table.copy()\n\n    @classmethod\n    def _backend_lookup(klass, name):\n        \"\"\"\n        Looks up and returns the specified backend by name.\n\n        Args:\n            klass: The class reference.\n            name: The name of the backend to look up.\n\n        Returns:\n            backend: The backend instance associated with the specified name.\n        \"\"\"\n        try:\n            return klass._backend_registry[name]\n        except KeyError:\n            backend_class = _backend_class_registry.lookup(name, subkeys=klass._backend_subkeys)\n            backend = backend_class()\n            klass._backend_registry[name] = backend\n            backend.register_handlers({'create_table': klass._create_table.td})\n            logging.debug(f\"backend {backend._plugin_name} for {klass._plugin_name} loaded\")\n            return backend\n\n    def __init__(self, name, drv_cfg):\n        \"\"\"\n        Initializes the Driver instance with a name and configuration.\n\n        Args:\n            name: The name of the database driver.\n            drv_cfg: The configuration settings for the driver instance.\n        \"\"\"\n        self._name = name\n        self._cfg = drv_cfg\n        self._last_key = 0\n        self._default_backend = self._backend_lookup(self._cfg.get(\"backend\", self._default_backend_name))\n        for backend_name in self._cfg.get('extra_backends', []):\n            self._backend_lookup(backend_name)\n\n    def config(self):\n        \"\"\"\n        Returns the configuration settings for the driver.\n\n        Returns:\n            Tree: A tree representation of the configuration.\n        \"\"\"\n        return self._cfg.to_tree()\n\n    def _backend(self, name):\n        \"\"\"\n        Retrieves the requested backend or the default backend if none is specified.\n\n        Args:\n            name: The name of the backend to retrieve.\n\n        Returns:\n            backend: The specified backend instance or default backend if name is None.\n        \"\"\"\n        if name is None:\n            return self._default_backend\n        logging.debug(f\"looking up backend {name}\")\n        return self._backend_lookup(name)\n\n    def driver_name(self):\n        \"\"\"\n        Returns the name of the database driver.\n\n        Returns:\n            str: The name of the driver.\n        \"\"\"\n        return self._plugin_name\n\n    @optional_abstract\n    @contextmanager\n    def begin(self):\n        \"\"\"\n        Context manager for beginning a database transaction.\n\n        Yields:\n            Transaction: A transaction object for conducting operations within a context.\n        \"\"\"\n        ...\n\n    @optional_abstract\n    def _execute(self, txn, sql, parameters=None):\n        \"\"\"\n        Executes an SQL command within a transaction.\n\n        Args:\n            txn: The transaction instance to execute the command within.\n            sql: The SQL command to execute.\n            parameters: Optional parameters for the SQL command.\n        \"\"\"\n        ...\n\n    @optional_abstract\n    def _execute_script(self, txn, sql):\n        \"\"\"\n        Executes a SQL script within a transaction.\n\n        Args:\n            txn: The transaction instance to execute the script within.\n            sql: The SQL script to execute.\n        \"\"\"\n        ...\n\n    @optional_abstract\n    def _list_tables(self, txn):\n        \"\"\"\n        Lists all tables within the database for the given transaction.\n\n        Args:\n            txn: The transaction instance for querying the database.\n        \"\"\"\n        ...\n\n    def _next_key(self):\n        \"\"\"\n        Generates the next unique key for database operations.\n\n        Returns:\n            int: A unique key for the current operation.\n        \"\"\"\n        self._last_key += 1\n        return self._last_key\n\n    def _query(self, txn, sql, parameters, backend, kws):\n        \"\"\"\n        Executes a database query and returns the result.\n\n        Args:\n            txn: The transaction instance to use for the query.\n            sql: The SQL query string to execute.\n            parameters: Optional parameters for the SQL query.\n            backend: The backend to use for executing the query.\n            kws: Additional keyword arguments for the backend.\n\n        Returns:\n            Result: The result of the query execution.\n        \"\"\"\n        logging.debug(f\"database query code: {repr(sql)}, parameters: {str(parameters)[0:40]}\")\n        return self._backend(backend).query(txn, sql, parameters, kws)\n\n    def _query_first(self, txn, sql, parameters, backend, kws):\n        \"\"\"\n        Executes a query and returns the first result.\n\n        Args:\n            txn: The transaction instance.\n            sql: The SQL query string to execute.\n            parameters: Optional parameters for the SQL query.\n            backend: The backend to use for executing the query.\n            kws: Additional keyword arguments.\n\n        Returns:\n            Result: The first result of the query execution.\n        \"\"\"\n        logging.debug(f\"database query code: {repr(sql)}, parameters: {str(parameters)[0:40]}\")\n        return self._backend(backend).query_first(txn, sql, parameters, kws)\n\n    def _query_first_value(self, txn, sql, parameters, backend, kws):\n        \"\"\"\n        Executes a query and returns the first value from the result.\n\n        Args:\n            txn: The transaction instance.\n            sql: The SQL query string to execute.\n            parameters: Optional parameters for the SQL query.\n            backend: The backend to use for executing the query.\n            kws: Additional keyword arguments.\n\n        Returns:\n            Any: The first value from the result of the query execution.\n        \"\"\"\n        logging.debug(f\"database query code: {repr(sql)}, parameters: {str(parameters)[0:40]}\")\n        return self._backend(backend).query_first_value(txn, sql, parameters, kws)\n\n    @optional_abstract\n    def _read_table(self, txn, table_name, backend, kws):\n        \"\"\"\n        Reads a table from the database.\n\n        Args:\n            txn: The transaction instance.\n            table_name: The name of the table to read.\n            backend: The backend to use for reading the table.\n            kws: Additional keyword arguments.\n\n        Returns:\n            DataFrame: The data read from the table.\n        \"\"\"\n        ...\n\n    @optional_abstract\n    def _drop_table(self, txn, table_name, only_if_exists):\n        \"\"\"\n        Drops a specified table from the database.\n\n        Args:\n            txn: The transaction instance.\n            table_name: The name of the table to be dropped.\n            only_if_exists: Boolean to specify if the table should only be dropped if it exists.\n        \"\"\"\n        ...\n\n    @dispatcher({str: '_create_table_from_str',\n                 list: '_create_table_from_records',\n                 types.GeneratorType: '_create_table_from_iterator',},\n                ix=2)\n    def _create_table(self, txn, table_name, sql_or_df, parameters, if_exists, kws):\n        \"\"\"\n        Creates a table in the database from various input types.\n\n        Args:\n            txn: The transaction instance to create the table within.\n            table_name: The name of the table to create.\n            sql_or_df: The SQL command or DataFrame to define the table.\n            parameters: Optional parameters for creating the table.\n            if_exists: Specifies how to handle the table if it already exists.\n            kws: Additional keyword arguments.\n        \"\"\"\n        ...\n\n    @optional_abstract\n    def _create_table_from_str(self, txn, table_name, sql, parameters, if_exists, kws):\n        \"\"\"\n        Creates a table from a SQL string command.\n\n        Args:\n            txn: The transaction instance.\n            table_name: The name of the table to create.\n            sql: SQL string defining the table schema.\n            parameters: Optional parameters for the SQL command.\n            if_exists: Specifies how to handle the table if it already exists.\n            kws: Additional keyword arguments.\n        \"\"\"\n        ...\n\n    @optional_abstract\n    def _create_table_from_clause(self, txn, table_name, clause, parameters, if_exists, kws):\n        \"\"\"\n        Creates a table from a SQL clause.\n\n        Args:\n            txn: The transaction instance.\n            table_name: The name of the table to create.\n            clause: SQL clause for creating the table.\n            parameters: Optional parameters for the SQL command.\n            if_exists: Specifies how to handle the table if it already exists.\n            kws: Additional keyword arguments.\n        \"\"\"\n        ...\n\n    def _create_table_from_records(self, txn, table_name, records, parameters, if_exists, kws):\n        \"\"\"\n        Creates a table from a list of records.\n\n        Args:\n            txn: The transaction instance.\n            table_name: The name of the table to create.\n            records: Iterable containing records for the table.\n            parameters: Optional parameters for creating the table.\n            if_exists: Specifies how to handle the table if it already exists.\n            kws: Additional keyword arguments.\n        \"\"\"\n        backend = self._backend(kws.pop(\"backend\", None))\n        backend.create_table_from_records(txn, table_name, records, parameters, if_exists, kws)\n\n    def _create_table_from_iterator(self, txn, table_name, iterator, parameters, if_exists, kws):\n        \"\"\"\n        Creates a table from an iterator yielding records.\n\n        Args:\n            txn: The transaction instance.\n            table_name: The name of the table to create.\n            iterator: Iterator yielding records for the table.\n            parameters: Optional parameters for creating the table.\n            if_exists: Specifies how to handle the table if it already exists.\n            kws: Additional keyword arguments.\n        \"\"\"\n        for chunk in iterator:\n            self._create_table(txn, table_name, chunk, parameters, if_exists, kws)\n            if_exists = 'append'\n\n    @optional_abstract\n    def _create_view(self, txn, view_name, sql, parameters, if_exists, kws):\n        \"\"\"\n        Creates a view in the database.\n\n        Args:\n            txn: The transaction instance.\n            view_name: The name of the view to create.\n            sql: SQL string defining the view.\n            parameters: Optional parameters for creating the view.\n            if_exists: Specifies how to handle the view if it already exists.\n            kws: Additional keyword arguments.\n        \"\"\"\n        ...\n\n    @optional_abstract\n    def _copy_table(self, txn, from_table_name, to_table_name, if_exists, kws):\n        \"\"\"\n        Copies the contents of one table to another.\n\n        Args:\n            txn: The transaction instance.\n            from_table_name: The name of the table to copy from.\n            to_table_name: The name of the table to copy to.\n            if_exists: Specifies how to handle the table if it already exists.\n            kws: Additional keyword arguments.\n        \"\"\"\n        ...\n\n    @optional_abstract\n    def _read_table_chunked(self, txn, table_name, backend, kws):\n        \"\"\"\n        Reads a table in chunks.\n\n        Args:\n            txn: The transaction instance.\n            table_name: The name of the table to read.\n            backend: The backend to use for reading the table.\n            kws: Additional keyword arguments.\n        \"\"\"\n        ...\n\n    def _query_chunked(self, txn, sql, parameters, backend, kws):\n        \"\"\"\n        Executes a chunked query and returns results.\n\n        Args:\n            txn: The transaction instance.\n            sql: The SQL query string to execute.\n            parameters: Optional parameters for the SQL query.\n            backend: The backend to use for executing the query.\n            kws: Additional keyword arguments.\n\n        Returns:\n            Chunked results of the query execution.\n        \"\"\"\n        return self._backend(backend).query_chunked(txn, sql, parameters, kws)\n\n    def _query_group(self, txn, sql, parameters, by, backend, kws):\n        \"\"\"\n        Executes a grouped query and returns results.\n\n        Args:\n            txn: The transaction instance.\n            sql: The SQL query string to execute.\n            parameters: Optional parameters for the SQL query.\n            by: Column(s) to group the results by.\n            backend: The backend to use for executing the query.\n            kws: Additional keyword arguments.\n\n        Returns:\n            Grouped results of the query execution.\n        \"\"\"\n        return self._backend(backend).query_group(txn, sql, parameters, by, kws)\n\n    def load_backend(self, name):\n        \"\"\"\n        Loads a specific backend into the driver.\n\n        Args:\n            name: The name of the backend to load.\n        \"\"\"\n        self._backend_lookup(name)\n</code></pre>"},{"location":"reference/plpipes/database/driver/#plpipes.database.driver.Driver.__init__","title":"<code>__init__(name, drv_cfg)</code>","text":"<p>Initializes the Driver instance with a name and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>The name of the database driver.</p> required <code>drv_cfg</code> <p>The configuration settings for the driver instance.</p> required Source code in <code>src/plpipes/database/driver/__init__.py</code> <pre><code>def __init__(self, name, drv_cfg):\n    \"\"\"\n    Initializes the Driver instance with a name and configuration.\n\n    Args:\n        name: The name of the database driver.\n        drv_cfg: The configuration settings for the driver instance.\n    \"\"\"\n    self._name = name\n    self._cfg = drv_cfg\n    self._last_key = 0\n    self._default_backend = self._backend_lookup(self._cfg.get(\"backend\", self._default_backend_name))\n    for backend_name in self._cfg.get('extra_backends', []):\n        self._backend_lookup(backend_name)\n</code></pre>"},{"location":"reference/plpipes/database/driver/#plpipes.database.driver.Driver.begin","title":"<code>begin()</code>","text":"<p>Context manager for beginning a database transaction.</p> <p>Yields:</p> Name Type Description <code>Transaction</code> <p>A transaction object for conducting operations within a context.</p> Source code in <code>src/plpipes/database/driver/__init__.py</code> <pre><code>@optional_abstract\n@contextmanager\ndef begin(self):\n    \"\"\"\n    Context manager for beginning a database transaction.\n\n    Yields:\n        Transaction: A transaction object for conducting operations within a context.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/plpipes/database/driver/#plpipes.database.driver.Driver.config","title":"<code>config()</code>","text":"<p>Returns the configuration settings for the driver.</p> <p>Returns:</p> Name Type Description <code>Tree</code> <p>A tree representation of the configuration.</p> Source code in <code>src/plpipes/database/driver/__init__.py</code> <pre><code>def config(self):\n    \"\"\"\n    Returns the configuration settings for the driver.\n\n    Returns:\n        Tree: A tree representation of the configuration.\n    \"\"\"\n    return self._cfg.to_tree()\n</code></pre>"},{"location":"reference/plpipes/database/driver/#plpipes.database.driver.Driver.driver_name","title":"<code>driver_name()</code>","text":"<p>Returns the name of the database driver.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The name of the driver.</p> Source code in <code>src/plpipes/database/driver/__init__.py</code> <pre><code>def driver_name(self):\n    \"\"\"\n    Returns the name of the database driver.\n\n    Returns:\n        str: The name of the driver.\n    \"\"\"\n    return self._plugin_name\n</code></pre>"},{"location":"reference/plpipes/database/driver/#plpipes.database.driver.Driver.load_backend","title":"<code>load_backend(name)</code>","text":"<p>Loads a specific backend into the driver.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>The name of the backend to load.</p> required Source code in <code>src/plpipes/database/driver/__init__.py</code> <pre><code>def load_backend(self, name):\n    \"\"\"\n    Loads a specific backend into the driver.\n\n    Args:\n        name: The name of the backend to load.\n    \"\"\"\n    self._backend_lookup(name)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/","title":"plpipes.database.sqlext","text":"<p>This module provides SQLAlchemy extensions for performing tasks not natively supported by the SQLAlchemy ORM. It includes constructs for creating and dropping tables and views, inserting data from queries, and handling subqueries.</p>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.AsSubquery","title":"<code>AsSubquery</code>","text":"<p>               Bases: <code>FromClause</code></p> <p>Class for handling subqueries.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>class AsSubquery(FromClause):\n    \"\"\"\n    Class for handling subqueries.\n    \"\"\"\n    inherit_cache = False\n\n    def __init__(self, txt):\n        \"\"\"\n        Initializes a subquery.\n\n        :param txt: The text of the subquery.\n        \"\"\"\n        self._txt = txt\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.AsSubquery.__init__","title":"<code>__init__(txt)</code>","text":"<p>Initializes a subquery.</p> <p>:param txt: The text of the subquery.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>def __init__(self, txt):\n    \"\"\"\n    Initializes a subquery.\n\n    :param txt: The text of the subquery.\n    \"\"\"\n    self._txt = txt\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.CreateTableAs","title":"<code>CreateTableAs</code>","text":"<p>               Bases: <code>_CreateSomethingAs</code></p> <p>Class for creating a table from a select statement.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>class CreateTableAs(_CreateSomethingAs):\n    \"\"\"\n    Class for creating a table from a select statement.\n    \"\"\"\n    inherit_cache = True\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initializes the creation of a table.\n        \"\"\"\n        super().__init__(\"TABLE\", *args, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.CreateTableAs.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initializes the creation of a table.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initializes the creation of a table.\n    \"\"\"\n    super().__init__(\"TABLE\", *args, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.CreateViewAs","title":"<code>CreateViewAs</code>","text":"<p>               Bases: <code>_CreateSomethingAs</code></p> <p>Class for creating a view from a select statement.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>class CreateViewAs(_CreateSomethingAs):\n    \"\"\"\n    Class for creating a view from a select statement.\n    \"\"\"\n    inherit_cache = True\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initializes the creation of a view.\n        \"\"\"\n        super().__init__(\"VIEW\", *args, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.CreateViewAs.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initializes the creation of a view.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initializes the creation of a view.\n    \"\"\"\n    super().__init__(\"VIEW\", *args, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.DropTable","title":"<code>DropTable</code>","text":"<p>               Bases: <code>_DropSomething</code></p> <p>Class for dropping a table.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>class DropTable(_DropSomething):\n    \"\"\"\n    Class for dropping a table.\n    \"\"\"\n    inherit_cache = False\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initializes the drop operation for a table.\n        \"\"\"\n        super().__init__(\"TABLE\", *args, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.DropTable.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initializes the drop operation for a table.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initializes the drop operation for a table.\n    \"\"\"\n    super().__init__(\"TABLE\", *args, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.DropView","title":"<code>DropView</code>","text":"<p>               Bases: <code>_DropSomething</code></p> <p>Class for dropping a view.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>class DropView(_DropSomething):\n    \"\"\"\n    Class for dropping a view.\n    \"\"\"\n    inherit_cache = False\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initializes the drop operation for a view.\n        \"\"\"\n        super().__init__(\"VIEW\", *args, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.DropView.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initializes the drop operation for a view.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initializes the drop operation for a view.\n    \"\"\"\n    super().__init__(\"VIEW\", *args, **kwargs)\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.InsertIntoTableFromQuery","title":"<code>InsertIntoTableFromQuery</code>","text":"<p>               Bases: <code>Executable</code>, <code>ClauseElement</code></p> <p>Class for inserting data into a table from a select statement.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>class InsertIntoTableFromQuery(Executable, ClauseElement):\n    \"\"\"\n    Class for inserting data into a table from a select statement.\n    \"\"\"\n    inherit_cache = True\n\n    def __init__(self, table_name, select):\n        \"\"\"\n        Initializes the insert operation.\n\n        :param table_name: Name of the table to insert into.\n        :param select: Select statement providing data to insert.\n        \"\"\"\n        self._table_name = table_name\n        self._select = select\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.InsertIntoTableFromQuery.__init__","title":"<code>__init__(table_name, select)</code>","text":"<p>Initializes the insert operation.</p> <p>:param table_name: Name of the table to insert into. :param select: Select statement providing data to insert.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>def __init__(self, table_name, select):\n    \"\"\"\n    Initializes the insert operation.\n\n    :param table_name: Name of the table to insert into.\n    :param select: Select statement providing data to insert.\n    \"\"\"\n    self._table_name = table_name\n    self._select = select\n</code></pre>"},{"location":"reference/plpipes/database/sqlext/#plpipes.database.sqlext.Wrap","title":"<code>Wrap(str_or_something)</code>","text":"<p>Wraps a string or other expression into a SQLAlchemy text object.</p> <p>:param str_or_something: The string or expression to wrap. :return: A SQLAlchemy text object or the original expression.</p> Source code in <code>src/plpipes/database/sqlext.py</code> <pre><code>def Wrap(str_or_something):\n    \"\"\"\n    Wraps a string or other expression into a SQLAlchemy text object.\n\n    :param str_or_something: The string or expression to wrap.\n    :return: A SQLAlchemy text object or the original expression.\n    \"\"\"\n    if isinstance(str_or_something, str):\n        return sqlalchemy.sql.text(str_or_something)\n    return str_or_something\n</code></pre>"},{"location":"reference/plpipes/database/backend/dict/","title":"plpipes.database.backend.dict","text":""},{"location":"reference/plpipes/database/backend/geopandas/","title":"plpipes.database.backend.geopandas","text":""},{"location":"reference/plpipes/database/backend/pandas/","title":"plpipes.database.backend.pandas","text":""},{"location":"reference/plpipes/database/backend/plugin/","title":"plpipes.database.backend.plugin","text":""},{"location":"reference/plpipes/database/backend/spark/","title":"plpipes.database.backend.spark","text":""},{"location":"reference/plpipes/database/backend/tuple/","title":"plpipes.database.backend.tuple","text":""},{"location":"reference/plpipes/database/backend/plugin/dict/","title":"plpipes.database.backend.plugin.dict","text":""},{"location":"reference/plpipes/database/backend/plugin/geopandas/","title":"plpipes.database.backend.plugin.geopandas","text":""},{"location":"reference/plpipes/database/backend/plugin/geopandas__spatialite/","title":"plpipes.database.backend.plugin.geopandas__spatialite","text":""},{"location":"reference/plpipes/database/backend/plugin/pandas/","title":"plpipes.database.backend.plugin.pandas","text":""},{"location":"reference/plpipes/database/backend/plugin/pandas__spark/","title":"plpipes.database.backend.plugin.pandas__spark","text":""},{"location":"reference/plpipes/database/backend/plugin/spark/","title":"plpipes.database.backend.plugin.spark","text":""},{"location":"reference/plpipes/database/backend/plugin/tuple/","title":"plpipes.database.backend.plugin.tuple","text":""},{"location":"reference/plpipes/database/driver/filedb/","title":"plpipes.database.driver.filedb","text":""},{"location":"reference/plpipes/database/driver/mysql/","title":"plpipes.database.driver.mysql","text":""},{"location":"reference/plpipes/database/driver/odbc/","title":"plpipes.database.driver.odbc","text":""},{"location":"reference/plpipes/database/driver/plugin/","title":"plpipes.database.driver.plugin","text":""},{"location":"reference/plpipes/database/driver/sql_server/","title":"plpipes.database.driver.sql_server","text":""},{"location":"reference/plpipes/database/driver/sqlalchemy/","title":"plpipes.database.driver.sqlalchemy","text":""},{"location":"reference/plpipes/database/driver/sqlite/","title":"plpipes.database.driver.sqlite","text":""},{"location":"reference/plpipes/database/driver/transaction/","title":"plpipes.database.driver.transaction","text":""},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction","title":"<code>Transaction</code>","text":"<p>The Transaction class represents a database transaction.</p> <p>Attributes:</p> Name Type Description <code>driver</code> <code>object</code> <p>The database driver object.</p> <code>conn</code> <code>object</code> <p>The database connection object.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>class Transaction:\n    \"\"\"\n    The Transaction class represents a database transaction.\n\n    Attributes:\n        driver (object): The database driver object.\n        conn (object): The database connection object.\n    \"\"\"\n\n    def __init__(self, driver, conn):\n        \"\"\"\n        Creates a new transaction object.\n\n        Args:\n            driver (object): The database driver object.\n            conn (object): The database connection object.\n\n        Note:\n            Transaction objects should not be created calling the class\n            constructor directly but through Driver `begin` method.\n        \"\"\"\n        self._driver = driver\n        self._conn = conn\n\n    def driver(self):\n        \"\"\"\n        Returns the database driver object associated with this transaction.\n\n        Returns:\n            object: The database driver object.\n        \"\"\"\n        return self._driver\n\n    def db_name(self):\n        \"\"\"Returns the name of the database.\"\"\"\n        return self._driver._name\n\n    def connection(self):\n        \"\"\"\n        Returns the database connection object associated with this transaction.\n\n        Returns:\n            object: The database connection object.\n        \"\"\"\n        return self._conn\n\n    def execute(self, sql, parameters=None):\n        \"\"\"\n        Executes an SQL statement with optional parameters.\n\n        Args:\n            sql (str): The SQL statement to execute.\n            parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n        \"\"\"\n        self._driver._execute(self, sql, parameters)\n\n    def execute_script(self, sql_script):\n        \"\"\"\n        Executes a script containing multiple SQL statements.\n\n        Args:\n            sql_script (str): The SQL script to execute.\n        \"\"\"\n        return self._driver._execute_script(self, sql_script)\n\n    def create_table(self, table_name, sql_or_df, parameters=None, if_exists=\"replace\", **kws):\n        \"\"\"\n        Creates a new table in the database.\n\n        Args:\n            table_name (str): The name of the table to create.\n            sql_or_df (str or DataFrame): The SQL statement or DataFrame defining the table schema.\n            parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n            if_exists (str, optional): How to handle the table if it already exists. Valid options are \"fail\", \"replace\", and \"append\".\n            **kws: Additional keyword arguments to pass to the driver.\n        \"\"\"\n        return self._driver._create_table(self, table_name, sql_or_df, parameters, if_exists, kws)\n\n    def create_view(self, view_name, sql, parameters=None, if_exists=\"replace\", **kws):\n        \"\"\"\n        Creates a new view in the database.\n\n        Args:\n            view_name (str): The name of the view to create.\n            sql (str): The SQL statement defining the view.\n            parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n            if_exists (str, optional): How to handle the view if it already exists. Valid options are \"fail\", \"replace\", and \"append\".\n            **kws: Additional keyword arguments to pass to the driver.\n        \"\"\"\n        return self._driver._create_view(self, view_name, sql, parameters, if_exists, kws)\n\n    def read_table(self, table_name, backend=None, **kws):\n        \"\"\"\n        Reads a table from the database into a DataFrame.\n\n        Args:\n            table_name (str): The name of the table to read.\n            backend (optional): The backend to use for reading the table. If None, the default backend for the driver is used.\n            **kws: Additional keyword arguments to pass to the backend.\n\n        Returns:\n            DataFrame: A DataFrame containing the table data.\n        \"\"\"\n        return self._driver._read_table(self, table_name, backend, kws)\n\n    def read_table_chunked(self, table_name, backend=None, **kws):\n        \"\"\"\n        Reads a table from the database in chunks.\n\n        Args:\n            table_name (str): The name of the table to read.\n            backend (optional): The backend to use for reading the table. If None, the default backend for the driver is used.\n            **kws: Additional keyword arguments to pass to the backend.\n        \"\"\"\n        return self._driver._read_table_chunked(self, table_name, backend, kws)\n\n    def query(self, sql, parameters=None, backend=None, **kws):\n        \"\"\"\n        Executes an SQL query and returns the result as a DataFrame.\n\n        Args:\n            sql (str): The SQL query to execute.\n            parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n            backend (optional): The backend to use for executing the query. If None, the default backend is used.\n            **kws: Additional keyword arguments to pass to the driver.\n\n        Returns:\n            DataFrame: A DataFrame containing the query result.\n        \"\"\"\n        return self._driver._query(self, sql, parameters, backend, kws)\n\n    def query_first(self, sql, parameters=None, backend=None, **kws):\n        \"\"\"\n        Executes an SQL query and returns the first row of the result.\n\n        Args:\n            sql (str): The SQL query to execute.\n            parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n            backend (optional): The backend to use for executing the query. If None, the default backend is used.\n            **kws: Additional keyword arguments to pass to the driver.\n\n        Returns:\n            DataFrame or dict: A dataframe/dictionary containing the result first row.\n        \"\"\"\n        return self._driver._query_first(self, sql, parameters, backend, kws)\n\n    def query_first_value(self, sql, parameters=None, backend=\"tuple\", **kws):\n        \"\"\"\n        Executes an SQL query and returns the first value from the result.\n\n        Args:\n            sql (str): The SQL query to execute.\n            parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n            backend (str, optional): The backend to use for executing the query. If None, the default backend is used. Defaults to `tuple`.\n            **kws: Additional keyword arguments to pass to the driver.\n\n        Returns:\n            Any: The first value from the result (first row, first column).\n        \"\"\"\n        return self._driver._query_first_value(self, sql, parameters, backend, kws)\n\n    def query_chunked(self, sql, parameters=None, backend=None, **kws):\n        \"\"\"\n        Executes an SQL query and returns the result as an iterator over chunks of rows.\n\n        Args:\n            sql (str): The SQL query to execute.\n            parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n            backend (optional): The backend to use for executing the query. If None, the default backend is used.\n            **kws: Additional keyword arguments to pass to the driver.\n\n        Returns:\n            iterator: An iterator over chunks of rows.\n        \"\"\"\n        return self._driver._query_chunked(self, sql, parameters, backend, kws)\n\n    def query_group(self, sql, parameters=None, by=None, backend=None, **kws):\n        \"\"\"\n        Executes an SQL query and returns the result as a DataFrame grouped by one or more columns.\n\n        Args:\n            sql (str): The SQL query to execute.\n            parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n            by (optional): The column(s) to group by.\n            backend (optional): The backend to use for executing the query. If None, the default backend is used.\n            **kws: Additional keyword arguments to pass to the driver.\n\n        Returns:\n            DataFrame: A DataFrame containing the grouped query result.\n        \"\"\"\n        return self._driver._query_group(self, sql, parameters, by, backend, kws)\n\n    def drop_table(self, table_name, only_if_exists=True):\n        \"\"\"\n        Drops a table from the database.\n\n        Args:\n            table_name (str): The name of the table to drop.\n            only_if_exists (bool, optional): If True, the table is only dropped if it exists. Otherwise, an error is raised if the table does not exist.\n        \"\"\"\n        return self._driver._drop_table(self, table_name, only_if_exists)\n\n    def list_tables(self):\n        \"\"\"\n        Lists the tables in the database.\n\n        Returns:\n            DataFrame: DataFrame with the list of tables.\n        \"\"\"\n        return self._driver._list_tables(self)\n\n    def list_views(self):\n        \"\"\"\n        Lists the views in the database.\n\n        Returns:\n            DataFrame: DataFrame with the list of views.\n        \"\"\"\n        return self._driver._list_views(self)\n\n    def table_exists_p(self, table_name):\n        \"\"\"\n        Checks whether a table exists in the database.\n\n        Args:\n            table_name (str): The name of the table to check.\n\n        Returns:\n            bool: True if the table exists, False otherwise.\n        \"\"\"\n        return self._driver._table_exists_p(self, table_name)\n\n    def copy_table(self, from_table_name, to_table_name, if_exists=\"replace\", **kws):\n        \"\"\"\n        Copies the contents of one table to another.\n\n        Args:\n            from_table_name (str): The name of the table to copy from.\n            to_table_name (str): The name of the table to copy to.\n            if_exists (str, optional): How to handle the destination table if it already exists. Valid options are \"fail\", \"replace\", and \"append\".\n            **kws: Additional keyword arguments to pass to the driver.\n\n        Raises:\n            ValueError: If the source and destination table names are the same.\n\n        Returns:\n            int: The number of rows copied.\n        \"\"\"\n        if from_table_name == to_table_name:\n            raise ValueError(\"source and destination tables must be different\")\n        return self._driver._copy_table(self, from_table_name, to_table_name, if_exists, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.__init__","title":"<code>__init__(driver, conn)</code>","text":"<p>Creates a new transaction object.</p> <p>Parameters:</p> Name Type Description Default <code>driver</code> <code>object</code> <p>The database driver object.</p> required <code>conn</code> <code>object</code> <p>The database connection object.</p> required Note <p>Transaction objects should not be created calling the class constructor directly but through Driver <code>begin</code> method.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def __init__(self, driver, conn):\n    \"\"\"\n    Creates a new transaction object.\n\n    Args:\n        driver (object): The database driver object.\n        conn (object): The database connection object.\n\n    Note:\n        Transaction objects should not be created calling the class\n        constructor directly but through Driver `begin` method.\n    \"\"\"\n    self._driver = driver\n    self._conn = conn\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.connection","title":"<code>connection()</code>","text":"<p>Returns the database connection object associated with this transaction.</p> <p>Returns:</p> Name Type Description <code>object</code> <p>The database connection object.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def connection(self):\n    \"\"\"\n    Returns the database connection object associated with this transaction.\n\n    Returns:\n        object: The database connection object.\n    \"\"\"\n    return self._conn\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.copy_table","title":"<code>copy_table(from_table_name, to_table_name, if_exists='replace', **kws)</code>","text":"<p>Copies the contents of one table to another.</p> <p>Parameters:</p> Name Type Description Default <code>from_table_name</code> <code>str</code> <p>The name of the table to copy from.</p> required <code>to_table_name</code> <code>str</code> <p>The name of the table to copy to.</p> required <code>if_exists</code> <code>str</code> <p>How to handle the destination table if it already exists. Valid options are \"fail\", \"replace\", and \"append\".</p> <code>'replace'</code> <code>**kws</code> <p>Additional keyword arguments to pass to the driver.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the source and destination table names are the same.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of rows copied.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def copy_table(self, from_table_name, to_table_name, if_exists=\"replace\", **kws):\n    \"\"\"\n    Copies the contents of one table to another.\n\n    Args:\n        from_table_name (str): The name of the table to copy from.\n        to_table_name (str): The name of the table to copy to.\n        if_exists (str, optional): How to handle the destination table if it already exists. Valid options are \"fail\", \"replace\", and \"append\".\n        **kws: Additional keyword arguments to pass to the driver.\n\n    Raises:\n        ValueError: If the source and destination table names are the same.\n\n    Returns:\n        int: The number of rows copied.\n    \"\"\"\n    if from_table_name == to_table_name:\n        raise ValueError(\"source and destination tables must be different\")\n    return self._driver._copy_table(self, from_table_name, to_table_name, if_exists, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.create_table","title":"<code>create_table(table_name, sql_or_df, parameters=None, if_exists='replace', **kws)</code>","text":"<p>Creates a new table in the database.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to create.</p> required <code>sql_or_df</code> <code>str or DataFrame</code> <p>The SQL statement or DataFrame defining the table schema.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary containing values to fill in SQL statement placeholders.</p> <code>None</code> <code>if_exists</code> <code>str</code> <p>How to handle the table if it already exists. Valid options are \"fail\", \"replace\", and \"append\".</p> <code>'replace'</code> <code>**kws</code> <p>Additional keyword arguments to pass to the driver.</p> <code>{}</code> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def create_table(self, table_name, sql_or_df, parameters=None, if_exists=\"replace\", **kws):\n    \"\"\"\n    Creates a new table in the database.\n\n    Args:\n        table_name (str): The name of the table to create.\n        sql_or_df (str or DataFrame): The SQL statement or DataFrame defining the table schema.\n        parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n        if_exists (str, optional): How to handle the table if it already exists. Valid options are \"fail\", \"replace\", and \"append\".\n        **kws: Additional keyword arguments to pass to the driver.\n    \"\"\"\n    return self._driver._create_table(self, table_name, sql_or_df, parameters, if_exists, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.create_view","title":"<code>create_view(view_name, sql, parameters=None, if_exists='replace', **kws)</code>","text":"<p>Creates a new view in the database.</p> <p>Parameters:</p> Name Type Description Default <code>view_name</code> <code>str</code> <p>The name of the view to create.</p> required <code>sql</code> <code>str</code> <p>The SQL statement defining the view.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary containing values to fill in SQL statement placeholders.</p> <code>None</code> <code>if_exists</code> <code>str</code> <p>How to handle the view if it already exists. Valid options are \"fail\", \"replace\", and \"append\".</p> <code>'replace'</code> <code>**kws</code> <p>Additional keyword arguments to pass to the driver.</p> <code>{}</code> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def create_view(self, view_name, sql, parameters=None, if_exists=\"replace\", **kws):\n    \"\"\"\n    Creates a new view in the database.\n\n    Args:\n        view_name (str): The name of the view to create.\n        sql (str): The SQL statement defining the view.\n        parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n        if_exists (str, optional): How to handle the view if it already exists. Valid options are \"fail\", \"replace\", and \"append\".\n        **kws: Additional keyword arguments to pass to the driver.\n    \"\"\"\n    return self._driver._create_view(self, view_name, sql, parameters, if_exists, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.db_name","title":"<code>db_name()</code>","text":"<p>Returns the name of the database.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def db_name(self):\n    \"\"\"Returns the name of the database.\"\"\"\n    return self._driver._name\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.driver","title":"<code>driver()</code>","text":"<p>Returns the database driver object associated with this transaction.</p> <p>Returns:</p> Name Type Description <code>object</code> <p>The database driver object.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def driver(self):\n    \"\"\"\n    Returns the database driver object associated with this transaction.\n\n    Returns:\n        object: The database driver object.\n    \"\"\"\n    return self._driver\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.drop_table","title":"<code>drop_table(table_name, only_if_exists=True)</code>","text":"<p>Drops a table from the database.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to drop.</p> required <code>only_if_exists</code> <code>bool</code> <p>If True, the table is only dropped if it exists. Otherwise, an error is raised if the table does not exist.</p> <code>True</code> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def drop_table(self, table_name, only_if_exists=True):\n    \"\"\"\n    Drops a table from the database.\n\n    Args:\n        table_name (str): The name of the table to drop.\n        only_if_exists (bool, optional): If True, the table is only dropped if it exists. Otherwise, an error is raised if the table does not exist.\n    \"\"\"\n    return self._driver._drop_table(self, table_name, only_if_exists)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.execute","title":"<code>execute(sql, parameters=None)</code>","text":"<p>Executes an SQL statement with optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to execute.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary containing values to fill in SQL statement placeholders.</p> <code>None</code> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def execute(self, sql, parameters=None):\n    \"\"\"\n    Executes an SQL statement with optional parameters.\n\n    Args:\n        sql (str): The SQL statement to execute.\n        parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n    \"\"\"\n    self._driver._execute(self, sql, parameters)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.execute_script","title":"<code>execute_script(sql_script)</code>","text":"<p>Executes a script containing multiple SQL statements.</p> <p>Parameters:</p> Name Type Description Default <code>sql_script</code> <code>str</code> <p>The SQL script to execute.</p> required Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def execute_script(self, sql_script):\n    \"\"\"\n    Executes a script containing multiple SQL statements.\n\n    Args:\n        sql_script (str): The SQL script to execute.\n    \"\"\"\n    return self._driver._execute_script(self, sql_script)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.list_tables","title":"<code>list_tables()</code>","text":"<p>Lists the tables in the database.</p> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>DataFrame with the list of tables.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def list_tables(self):\n    \"\"\"\n    Lists the tables in the database.\n\n    Returns:\n        DataFrame: DataFrame with the list of tables.\n    \"\"\"\n    return self._driver._list_tables(self)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.list_views","title":"<code>list_views()</code>","text":"<p>Lists the views in the database.</p> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>DataFrame with the list of views.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def list_views(self):\n    \"\"\"\n    Lists the views in the database.\n\n    Returns:\n        DataFrame: DataFrame with the list of views.\n    \"\"\"\n    return self._driver._list_views(self)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.query","title":"<code>query(sql, parameters=None, backend=None, **kws)</code>","text":"<p>Executes an SQL query and returns the result as a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary containing values to fill in SQL statement placeholders.</p> <code>None</code> <code>backend</code> <code>optional</code> <p>The backend to use for executing the query. If None, the default backend is used.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments to pass to the driver.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>A DataFrame containing the query result.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def query(self, sql, parameters=None, backend=None, **kws):\n    \"\"\"\n    Executes an SQL query and returns the result as a DataFrame.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n        backend (optional): The backend to use for executing the query. If None, the default backend is used.\n        **kws: Additional keyword arguments to pass to the driver.\n\n    Returns:\n        DataFrame: A DataFrame containing the query result.\n    \"\"\"\n    return self._driver._query(self, sql, parameters, backend, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.query_chunked","title":"<code>query_chunked(sql, parameters=None, backend=None, **kws)</code>","text":"<p>Executes an SQL query and returns the result as an iterator over chunks of rows.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary containing values to fill in SQL statement placeholders.</p> <code>None</code> <code>backend</code> <code>optional</code> <p>The backend to use for executing the query. If None, the default backend is used.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments to pass to the driver.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>iterator</code> <p>An iterator over chunks of rows.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def query_chunked(self, sql, parameters=None, backend=None, **kws):\n    \"\"\"\n    Executes an SQL query and returns the result as an iterator over chunks of rows.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n        backend (optional): The backend to use for executing the query. If None, the default backend is used.\n        **kws: Additional keyword arguments to pass to the driver.\n\n    Returns:\n        iterator: An iterator over chunks of rows.\n    \"\"\"\n    return self._driver._query_chunked(self, sql, parameters, backend, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.query_first","title":"<code>query_first(sql, parameters=None, backend=None, **kws)</code>","text":"<p>Executes an SQL query and returns the first row of the result.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary containing values to fill in SQL statement placeholders.</p> <code>None</code> <code>backend</code> <code>optional</code> <p>The backend to use for executing the query. If None, the default backend is used.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments to pass to the driver.</p> <code>{}</code> <p>Returns:</p> Type Description <p>DataFrame or dict: A dataframe/dictionary containing the result first row.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def query_first(self, sql, parameters=None, backend=None, **kws):\n    \"\"\"\n    Executes an SQL query and returns the first row of the result.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n        backend (optional): The backend to use for executing the query. If None, the default backend is used.\n        **kws: Additional keyword arguments to pass to the driver.\n\n    Returns:\n        DataFrame or dict: A dataframe/dictionary containing the result first row.\n    \"\"\"\n    return self._driver._query_first(self, sql, parameters, backend, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.query_first_value","title":"<code>query_first_value(sql, parameters=None, backend='tuple', **kws)</code>","text":"<p>Executes an SQL query and returns the first value from the result.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary containing values to fill in SQL statement placeholders.</p> <code>None</code> <code>backend</code> <code>str</code> <p>The backend to use for executing the query. If None, the default backend is used. Defaults to <code>tuple</code>.</p> <code>'tuple'</code> <code>**kws</code> <p>Additional keyword arguments to pass to the driver.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>The first value from the result (first row, first column).</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def query_first_value(self, sql, parameters=None, backend=\"tuple\", **kws):\n    \"\"\"\n    Executes an SQL query and returns the first value from the result.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n        backend (str, optional): The backend to use for executing the query. If None, the default backend is used. Defaults to `tuple`.\n        **kws: Additional keyword arguments to pass to the driver.\n\n    Returns:\n        Any: The first value from the result (first row, first column).\n    \"\"\"\n    return self._driver._query_first_value(self, sql, parameters, backend, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.query_group","title":"<code>query_group(sql, parameters=None, by=None, backend=None, **kws)</code>","text":"<p>Executes an SQL query and returns the result as a DataFrame grouped by one or more columns.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to execute.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary containing values to fill in SQL statement placeholders.</p> <code>None</code> <code>by</code> <code>optional</code> <p>The column(s) to group by.</p> <code>None</code> <code>backend</code> <code>optional</code> <p>The backend to use for executing the query. If None, the default backend is used.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments to pass to the driver.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>A DataFrame containing the grouped query result.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def query_group(self, sql, parameters=None, by=None, backend=None, **kws):\n    \"\"\"\n    Executes an SQL query and returns the result as a DataFrame grouped by one or more columns.\n\n    Args:\n        sql (str): The SQL query to execute.\n        parameters (dict, optional): A dictionary containing values to fill in SQL statement placeholders.\n        by (optional): The column(s) to group by.\n        backend (optional): The backend to use for executing the query. If None, the default backend is used.\n        **kws: Additional keyword arguments to pass to the driver.\n\n    Returns:\n        DataFrame: A DataFrame containing the grouped query result.\n    \"\"\"\n    return self._driver._query_group(self, sql, parameters, by, backend, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.read_table","title":"<code>read_table(table_name, backend=None, **kws)</code>","text":"<p>Reads a table from the database into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to read.</p> required <code>backend</code> <code>optional</code> <p>The backend to use for reading the table. If None, the default backend for the driver is used.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments to pass to the backend.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>A DataFrame containing the table data.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def read_table(self, table_name, backend=None, **kws):\n    \"\"\"\n    Reads a table from the database into a DataFrame.\n\n    Args:\n        table_name (str): The name of the table to read.\n        backend (optional): The backend to use for reading the table. If None, the default backend for the driver is used.\n        **kws: Additional keyword arguments to pass to the backend.\n\n    Returns:\n        DataFrame: A DataFrame containing the table data.\n    \"\"\"\n    return self._driver._read_table(self, table_name, backend, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.read_table_chunked","title":"<code>read_table_chunked(table_name, backend=None, **kws)</code>","text":"<p>Reads a table from the database in chunks.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to read.</p> required <code>backend</code> <code>optional</code> <p>The backend to use for reading the table. If None, the default backend for the driver is used.</p> <code>None</code> <code>**kws</code> <p>Additional keyword arguments to pass to the backend.</p> <code>{}</code> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def read_table_chunked(self, table_name, backend=None, **kws):\n    \"\"\"\n    Reads a table from the database in chunks.\n\n    Args:\n        table_name (str): The name of the table to read.\n        backend (optional): The backend to use for reading the table. If None, the default backend for the driver is used.\n        **kws: Additional keyword arguments to pass to the backend.\n    \"\"\"\n    return self._driver._read_table_chunked(self, table_name, backend, kws)\n</code></pre>"},{"location":"reference/plpipes/database/driver/transaction/#plpipes.database.driver.transaction.Transaction.table_exists_p","title":"<code>table_exists_p(table_name)</code>","text":"<p>Checks whether a table exists in the database.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the table exists, False otherwise.</p> Source code in <code>src/plpipes/database/driver/transaction.py</code> <pre><code>def table_exists_p(self, table_name):\n    \"\"\"\n    Checks whether a table exists in the database.\n\n    Args:\n        table_name (str): The name of the table to check.\n\n    Returns:\n        bool: True if the table exists, False otherwise.\n    \"\"\"\n    return self._driver._table_exists_p(self, table_name)\n</code></pre>"},{"location":"reference/plpipes/database/driver/plugin/duckdb/","title":"plpipes.database.driver.plugin.duckdb","text":""},{"location":"reference/plpipes/database/driver/plugin/influxdb1/","title":"plpipes.database.driver.plugin.influxdb1","text":""},{"location":"reference/plpipes/database/driver/plugin/mariadb/","title":"plpipes.database.driver.plugin.mariadb","text":""},{"location":"reference/plpipes/database/driver/plugin/mysql/","title":"plpipes.database.driver.plugin.mysql","text":""},{"location":"reference/plpipes/database/driver/plugin/postgresql/","title":"plpipes.database.driver.plugin.postgresql","text":""},{"location":"reference/plpipes/database/driver/plugin/spark/","title":"plpipes.database.driver.plugin.spark","text":""},{"location":"reference/plpipes/database/driver/plugin/spatialite/","title":"plpipes.database.driver.plugin.spatialite","text":""},{"location":"reference/plpipes/database/driver/plugin/sql_server/","title":"plpipes.database.driver.plugin.sql_server","text":""},{"location":"reference/plpipes/database/driver/plugin/sqlite/","title":"plpipes.database.driver.plugin.sqlite","text":""},{"location":"reference/plpipes/database/driver/sqlite/extension/","title":"plpipes.database.driver.sqlite.extension","text":""},{"location":"reference/plpipes/database/driver/sqlite/extension/vss/","title":"plpipes.database.driver.sqlite.extension.vss","text":""},{"location":"reference/plpipes/net/client/","title":"plpipes.net.client","text":""},{"location":"reference/plpipes/net/client/eurostat/","title":"plpipes.net.client.eurostat","text":""},{"location":"reference/plpipes/net/client/us_bls/","title":"plpipes.net.client.us_bls","text":""},{"location":"reference/plpipes/net/client/us_ecb/","title":"plpipes.net.client.us_ecb","text":""},{"location":"reference/plpipes/net/client/us_eia/","title":"plpipes.net.client.us_eia","text":""},{"location":"reference/plpipes/spark/plugin/","title":"plpipes.spark.plugin","text":""},{"location":"reference/plpipes/spark/plugin/databricks/","title":"plpipes.spark.plugin.databricks","text":""},{"location":"reference/plpipes/spark/plugin/embedded/","title":"plpipes.spark.plugin.embedded","text":""},{"location":"reference/plpipes/tool/dbeaver/","title":"plpipes.tool.dbeaver","text":""},{"location":"reference/plpipes/tool/ipython/","title":"plpipes.tool.ipython","text":""},{"location":"reference/plpipes/tool/run/","title":"plpipes.tool.run","text":""},{"location":"reference/plpipes/tool/dbeaver/__main__/","title":"plpipes.tool.dbeaver.main","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/","title":"plpipes.tool.dbeaver.conarg","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/driver/","title":"plpipes.tool.dbeaver.conarg.driver","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/mysql/","title":"plpipes.tool.dbeaver.conarg.mysql","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/sql_server/","title":"plpipes.tool.dbeaver.conarg.sql_server","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/driver/azure_sql/","title":"plpipes.tool.dbeaver.conarg.driver.azure_sql","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/driver/mariabd/","title":"plpipes.tool.dbeaver.conarg.driver.mariabd","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/driver/mysql/","title":"plpipes.tool.dbeaver.conarg.driver.mysql","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/driver/sql_server/","title":"plpipes.tool.dbeaver.conarg.driver.sql_server","text":""},{"location":"reference/plpipes/tool/dbeaver/conarg/driver/sqlite/","title":"plpipes.tool.dbeaver.conarg.driver.sqlite","text":""},{"location":"reference/plpipes/tool/ipython/__main__/","title":"plpipes.tool.ipython.main","text":""},{"location":"reference/plpipes/tool/run/__main__/","title":"plpipes.tool.run.main","text":""},{"location":"reference/plpipes/util/contextvar/","title":"plpipes.util.contextvar","text":""},{"location":"reference/plpipes/util/database/","title":"plpipes.util.database","text":""},{"location":"reference/plpipes/util/method_decorators/","title":"plpipes.util.method_decorators","text":""},{"location":"reference/plpipes/util/net/","title":"plpipes.util.net","text":""},{"location":"reference/plpipes/util/pluralsingular/","title":"plpipes.util.pluralsingular","text":""},{"location":"reference/plpipes/util/typedict/","title":"plpipes.util.typedict","text":""}]}